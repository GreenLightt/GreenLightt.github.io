<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Vbox 共享文件夹]]></title>
    <url>%2F2018%2F03%2F02%2Fvbox-share-folder%2F</url>
    <content type="text"><![CDATA[安装增强工具步骤： 找到 Locate VBoxGuestAdditions.iso 在主机上的位置 （以我为例, 在 C:\Program Files\Oracle\VirtualBox\VBoxGuestAdditions.iso） 将 VBoxGuestAdditions.iso 文件传送到虚拟机里 （以我为例，用的是 XShell 和 lszrz） 在虚拟机终端上，挂载 ISO 文件 12sudo mkdir /media/GuestAdditionsISOsudo mount -o loop path/to/VBoxGuestAdditions.iso /media/GuestAdditionsISO 此时，你可能得到一个消息：ISO 已经被挂载为只读；如果你改变目录到 /media/GuestAdditionsISO，你可以看到 VBoxLinuxAdditions.run 并且可被执行 12cd /media/GuestAdditionsISOls -l 现在执行 VBoxLinuxAdditions.run 文件: 1sudo ./VBoxLinuxAdditions.run 共享文件夹 切换到 root 用户输入挂载命令： 格式为： sudo mount -t vboxsf 共享文件夹名称（在设置页面设置的） 挂载的目录 12mkdir /opt/workspacesudo mount -t vboxsf vbox_connect_workspace /opt/workspace]]></content>
      <tags>
        <tag>VBox</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法之排序]]></title>
    <url>%2F2018%2F02%2F26%2Farithmetic-sort%2F</url>
    <content type="text"><![CDATA[简述常见算法分类： 非线性时间比较类排序：交换类排序：快速排序 和 冒泡排序插入类排序：简单插入排序 和 希尔排序选择类排序：简单选择排序 和 堆排序归并排序：二路归并排序 和 多路归并排序 线性时间非比较类排序：计数排序、基数排序 和 桶排序； 在比较类排序中，归并排序号称最快，其次是快速排序和堆排序，两者不相伯仲；但是有一点需要注意，数据初始排序状态对堆排序不会产生太大的影响，快速排序则相反； 线性时间非比较类排序一般要优于非线性时间比较类排序，但前者对待排序元素的要求比较严格，比如计数排序要求待排序数的最大值不能太大，桶排序要求元素按照 hash 分桶后桶内元素的数量要均匀。 线性时间非比较类元素特点是以空间换时间； 算法描述和实现交换类排序冒泡排序算法思想 从数组中第一个数开始，依次遍历数组中的每一个数，通过相邻比较交换，每一轮循环下来找出剩余未排序数的中的最大数并“冒泡”至数列的顶端。 算法步骤 从数组中第一个数开始，依次与下一个数比较并次交换比自己小的数，直到最后一个数。如果发生交换，则继续下面的步骤，如果未发生交换，则数组有序，排序结束，此时时间复杂度为 O(n)； 每一轮“冒泡”结束后，最大的数将出现在乱序数列的最后一位。重复步骤（1）。 稳定性稳定排序 时间复杂度 O(n) 至 O(n^2)，平均时间复杂度为 O(n^2)。 最好的情况：如果待排序数据序列为正序，则一趟冒泡就可完成排序，排序码的比较次数为 n-1 次，且没有移动，时间复杂度为 O(n)。 最坏的情况：如果待排序数据序列为逆序，则冒泡排序需要 n-1 次趟起泡，每趟进行 n-i 次排序码的比较和移动，即比较和移动次数均达到最大值： 实现代码 Python 版 12345678910111213def solve(self, nums): for i in range(len(nums) - 1): # 本趟冒泡是否存在交换 has_swap = False for j in range(len(nums) - (i + 1)): if nums[j] &gt; nums[j + 1]: nums[j] = nums[j] + nums[j + 1] nums[j + 1] = nums[j] - nums[j + 1] nums[j] = nums[j] - nums[j + 1] has_swap = True if not has_swap: break 鸡尾酒排序算法思想 鸡尾酒排序，也叫定向冒泡排序，是冒泡排序的一种改进。此算法与冒泡排序的不同处在于从低到高然后从高到低，而冒泡排序则仅从低到高去比较序列里的每个元素。他可以得到比冒泡排序稍微好一点的效能。 快速排序算法思想冒泡排序是在相邻的两个记录进行比较和交换，每次交换只能上移或下移一个位置，导致总的比较与移动次数较多。快速排序又称分区交换排序，是对冒泡排序的改进，快速排序采用的思想是分治思想。 算法步骤 从待排序的 n 个记录中任意选取一个记录（通常选取第一个记录）为分区标准; 把所有小于该排序列的记录移动到左边，把所有大于该排序码的记录移动到右边，中间放所选记录，称之为第一趟排序； 然后对前后两个子序列分别重复上述过程，直到所有记录都排好序。 稳定性不稳定排序 时间复杂度O(nlog2 n) 到 O(n^2) ，平均时间复杂度 O(nlg n) 最好的情况：是每趟结束后，每次划分使两个子文件的长度大致相等，时间复杂度为 O（nlog2 n）。 最坏的情况：是待排序记录已经排好序，第一趟经过 n-1 次比较后第一个记录保持位置不变，并得到一个 n-1 个元素的子记录；第二趟经过 n-2 次比较，将第二个记录定位在原来的位置上，并得到一个包括 n-2 个记录的子文件，依次类推，这样总的比较次数是：O(n^2) 实现代码 Python 版 12345678910111213141516171819202122def solve(self, nums): # 数组长度小于等于 1 不用再排序 if len(nums) &lt;= 1: return nums # 当前值、左数组，右数组进行申明 current_value = nums[0] left = [] right = [] # 比当前值小的放 left 当前值大的放 right for index in range(1, len(nums)): if nums[index] &lt;= current_value: left.append(nums[index]) if nums[index] &gt; current_value: right.append(nums[index]) # 将有序的 left + 当前值 + 有序的 right 进行返回 return_arr = [] return_arr.extend(self.solve(left)) return_arr.extend([current_value]) return_arr.extend(self.solve(right)) return return_arr 插入类排序简单插入排序算法思想从待排序的 n 个记录中的第二个记录开始，依次与前面的记录比较并寻找插入的位置，每次外循环结束后，将当前的数插入到合适的位置。 稳定性稳定排序 时间复杂度O(n) 至 O（n^2），平均时间复杂度是 O（n^2）。 最好情况：当待排序记录已经有序，这时需要比较的次数是 Cmin = n−1 = O(n)。 最坏情况：如果待排序记录为逆序，则最多的比较次数为 O(n^2)。 实现代码 Python 版 1234567891011121314def solve(self, nums): for index in range(1, len(nums)): # 要比较值的下标 prev = index - 1 # 当前值临时保存 tmp = nums[index] # 从后向前 比 tmp 大的值依次向后挪位 while prev &gt;= 0 and nums[prev] &gt; tmp: nums[prev + 1] = nums[prev] prev = prev - 1 # 如果 prev 指针发生变动，则把 tmp 放到合适的位置上 if prev != index - 1: nums[prev + 1] = tmp 希尔排序算法思想Shell 排序又称缩小增量排序, 由 D. L. Shell 在 1959 年提出，是对直接插入排序的改进。 步长为 1 ，就是直接插入排序。 稳定性不稳定排序 时间复杂度O(n^1.3) 到 O(n^2)。Shell 排序算法的时间复杂度分析比较复杂，实际所需的时间取决于各次排序时增量的个数和增量的取值。研究证明，若增量的取值比较合理，Shell 排序算法的时间复杂度约为 O(n^1.3)。 实现代码 Python 版 1234567891011121314151617181920def solve(self, nums): # 初始步长 step = len(nums) / 2 while step &gt; 0: for index in range(step, len(nums)): # 要比较值的下标 prev = index - step # 当前值临时保存 tmp = nums[index] # 从后向前 比 tmp 大的值依次向后挪位 while prev &gt;= 0 and nums[prev] &gt; tmp: nums[prev + step] = nums[prev] prev = prev - step # 如果 prev 指针发生变动，则把 tmp 放到合适的位置上 if prev != index - step: nums[prev + step] = tmp # 重置步长 step = step / 2 选择类排序简单选择排序算法思想 从所有记录中选出最小的一个数据元素与第一个位置的记录交换；然后在剩下的记录当中再找最小的与第二个位置的记录交换，循环到只剩下最后一个数据元素为止。 稳定性 不稳定排序 时间复杂度最坏、最好和平均复杂度均为 O(n^2)，因此，简单选择排序也是常见排序算法中性能最差的排序算法。简单选择排序的比较次数与文件的初始状态没有关系，在第i趟排序中选出最小排序码的记录，需要做 n-i 次比较； 实现代码 Python 版 1234567891011121314def solve(self, nums): for i in range(len(nums)): # 保存此趟循环的最小值的下标 min_index = i for j in range(i + 1, len(nums)): # 存在更小值， 保存更小值的下标 if nums[j] &lt; nums[min_index]: min_index = j # 交换 if min_index != i: nums[i] = nums[i] + nums[min_index] nums[min_index] = nums[i] - nums[min_index] nums[i] = nums[i] - nums[min_index] 堆排序堆的特点一般都用数组来存储堆，i 结点的父结点下标就为 (i–1)/2 。它的左右子结点下标分别为 2∗i+1 和 2∗i+2。如第 0 个结点左右子结点下标分别为1和2。 算法思想 建立： 以最小堆为例，如果以数组存储元素时，一个数组具有对应的树表示形式，但树并不满足堆的条件，需要重新排列元素，可以建立“堆化”的树。 插入：将一个新元素插入到表尾，即数组末尾时，如果新构成的二叉树不满足堆的性质，需要重新排列元素 删除：堆排序中，删除一个元素总是发生在堆顶，因为堆顶的元素是最小的（小顶堆中）。表中最后一个元素用来填补空缺位置，结果树被更新以满足堆条件。 稳定性不稳定排序 时间复杂度 实现代码 Python 版 123456789101112131415161718192021222324252627282930313233343536373839404142434445def solve(self, nums): """ 堆排序入口 """ # 建立最小堆 self.build(nums) # 从最后一个元素开始，与根结点换位置，重新调整堆 for i in range(len(nums) - 1, 0, -1): # 与根结点换位置 nums[0] = nums[0] + nums[i] nums[i] = nums[0] - nums[i] nums[0] = nums[0] - nums[i] # 重新调整堆 self.heapify(nums, 0, i)def build(self, nums): """ 建堆 """ # 第一个非叶结点到首结点 依次调整堆 for i in range(len(nums) / 2 - 1, -1, -1): self.heapify(nums, i, len(nums))def heapify(self, nums, heap_index, heap_size): """ 自 heap_index 下标开始向下调整堆 """ # 判断当前结点与左右子结点的大小，如果发生变化，则对相应的子结点作递归调整 left_child_index = 2 * heap_index + 1 right_child_index = 2 * heap_index + 2 min_index = heap_index # 比较左子结点与最小结点 if left_child_index &lt; heap_size and nums[left_child_index] &lt; nums[min_index]: min_index = left_child_index # 比较右子结点与最小结点 if right_child_index &lt; heap_size and nums[right_child_index] &lt; nums[min_index]: min_index = right_child_index # 如果最小结点非父节点 if min_index != heap_index: # 交换最小子结点与父结点 nums[heap_index] = nums[heap_index] + nums[min_index] nums[min_index] = nums[heap_index] - nums[min_index] nums[heap_index] = nums[heap_index] - nums[min_index] # 递归调整最小子结点所在的堆 self.heapify(nums, min_index, heap_size) 归并排序二路归并排序算法思想二路归并排序主要运用了“分治算法”，分治算法就是将一个大的问题划分为 n 个规模较小而结构相似的子问题。 这些子问题解决的方法都是类似的，解决掉这些小的问题之后，归并子问题的结果，就得到了“大”问题的解。 算法步骤 将一个数组分成两个数组，分别对两个数组进行排序。 循环第一步，直到划分出来的“小数组”只包含一个元素，只有一个元素的数组默认为已经排好序。 将两个有序的数组合并到一个大的数组中。 从最小的只包含一个元素的数组开始两两合并。此时，合并好的数组也是有序的。 稳定性稳定排序 时间复杂度最坏，最好和平均时间复杂度都是 O(nlgn)。 实现代码 Python 版 12345678910111213141516171819202122232425262728293031323334353637383940class Solution(object): """ 二路归并排序，指定要排序的数组，及范围 """ def sort(self, data, low, high): if low &lt; high: mid = (low + high) / 2 # 分解 self.sort(data, low, mid) self.sort(data, mid + 1, high) # 归并 self.merge(data, low, mid, high) """ 归并 data[low, mid] 和 data[mid, high] """ def merge(self, data, low, mid, high): # left_index 指向第 1 有序区的第 1 个元素 left_index = low # right_index 指向第 2 有序区的第 1 个元素，high 为第 2 有序区的最后一个元素 right_index = mid + 1 # temp数组暂存合并的有序序列 temp = [] # 顺序选取两个有序区的较小元素，存储到 temp 数组中，因为是递增排序 while left_index &lt;= mid and right_index &lt;= high: if data[left_index] &lt;= data[right_index]: temp.append(data[left_index]) left_index = left_index + 1 else: temp.append(data[right_index]) right_index = right_index + 1 # 比完之后，假如第 1 个有序区仍有剩余，则直接全部复制到 temp 数组 if left_index &lt;= mid: temp.extend(data[left_index:mid + 1]) # 比完之后，假如第 2 个有序区仍有剩余，则直接全部复制到 temp 数组 if right_index &lt;= high: temp.extend(data[right_index:high + 1]) # 将排好序的序列，重存回到 data 中 low 到 high 区间 for i in range(low, high + 1): data[i] = temp.pop(0) 多路归并排序算法思想外部排序指的是大文件的排序，即待排序的记录存储在外存储器上，待排序的文件无法一次装入内存，需要在内存和外部存储器之间进行多次数据交换，以达到排序整个文件的目的。外部排序最常用的算法是多路归并排序，即将原文件分解成多个能够一次性装人内存的部分，分别把每一部分调入内存完成排序。然后，对已经排序的子文件进行归并排序。 多路归并排序算法在常见数据结构书中都有涉及。从 2 路到多路（k 路），增大 k 可以减少外存信息读写时间，但 k 个归并段中选取最小的记录需要比较 k-1 次， 为得到 u 个记录的一个有序段共需要 (u-1)(k-1) 次，若归并趟数为 s 次，那么对 n 个记录的文件进行外排时，内部归并过程中进行的总的比较次数为 s(n-1)(k-1)，也即 (向上取整) (logkm)(k-1)(n-1)=(向上取整)(log2m/log2k)(k-1)(n-1)，而 (k- 1)/log2k 随 k 增而增因此内部归并时间随 k 增长而增长了，抵消了外存读写减少的时间，这样做不行，由此引出了“败者树” tree of loser 的使用。在内部归并过程中利用败者树将 k 个归并段中选取最小记录比较的次数降为 (向上取整)(log2k) 次使总比较次数为(向上取整) (log2m)(n-1)，与 k 无关。 败者树是完全二叉树， 因此数据结构可以采用一维数组。其元素个数为 k 个叶子结点、k-1 个比较结点、1 个冠军结点共 2k 个。ls[0]为冠军结点，ls[1]--ls[k - 1] 为比较结点，ls[k]--ls[2k-1]为叶子结点（同时用另外一个指针索引 b[0]--b[k-1] 指向）。另外 bk 为一个附加的辅助空间，不属于败者树，初始化时存着 MINKEY 的值。 算法步骤 首先将 k 个归并段中的首元素关键字依次存入 b[0]--b[k-1] 的叶子结点空间里，然后调用 CreateLoserTree 创建败者树，创建完毕之后最小的关键字下标（即所在归并段的序号）便被存入 ls[0] 中。 然后不断循环：把 ls[0] 所存最小关键字来自于哪个归并段的序号得到为 q，将该归并段的首元素输出到有序归并段里，然后把下一个元素关键字放入上一个元素本来所 在的叶子结点 b[q] 中，调用 Adjust 顺着 b[q] 这个叶子结点往上调整败者树直到新的最小的关键字被选出来，其下标同样存在 ls[0] 中。循环这个 操作过程直至所有元素被写到有序归并段里。 稳定性稳定 时间复杂度最坏，最好和平均时间复杂度都是 O(nlgn)。 实现代码 Python 版 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869class Solution(object): """ 初始化 """ def __init__(self): # 文件数量 self.file_num = 4 # 存放每个文件排序好的 top 1 值 self.b = [0 for i in range(0, self.file_num)] # 存放失败树的比较节点，ls[0] 是最小值 self.ls = [-1 for i in range(0, self.file_num)] # 是否结束文件读取 self.isend = [0 for i in range(0, self.file_num)] # 如果文件中的数值没了，则用 max 最大值 顶 self.max = 9999999 """ 归并排序 """ def sort(self): # 保存每个文件对象 file_objects = [0 for i in range(0, self.file_num)] for i in range(0, self.file_num): file_objects[i] = open(r'D:\vscode_workspace\python_flask\testdata%s.txt'%i) self.b[i] = int(file_objects[i].readline().replace('\n','')) self.createLoserTree() fileout_object = open(r'D:\vscode_workspace\python_flask\testdataout.txt','w') while self.b[self.ls[0]] != self.max: # 输出最小值 fileout_object.write('%s\n'%self.b[self.ls[0]]) # 读下一个值 tmp = file_objects[self.ls[0]].readline().replace('\n', '') if tmp != '': self.b[self.ls[0]] = int(tmp) else: self.isend[self.ls[0]] = 1 self.b[self.ls[0]] = self.max # 重新调整失败树 self.adjust(self.ls[0]) # 关闭文件 for i in range(0, self.file_num): file_objects[i].close() fileout_object.close() """ 创建失败树 """ def createLoserTree(self): for i in range(self.file_num - 1, -1, -1): self.adjust(i) """ 调整失败树 """ def adjust(self, i): t = (i + self.file_num) // 2 while t &gt; 0: if (self.ls[t] == -1 or self.b[i] &gt; self.b[self.ls[t]]) and i &gt;= 0: # b[i] 败，则更新父节点； tmp = i i = self.ls[t] self.ls[t] = tmp t = t // 2 self.ls[0] = i 参考 python实现k路归并排序，败者树 计数排序算法思想由于用来计数的数组 C 的长度取决于待排序数组中数据的范围（等于待排序数组的最大值与最小值的差加上 1），这使得计数排序对于数据范围很大的数组，需要大量时间和内存。例如：计数排序是用来排序 0 到 100 之间的数字的最好的算法，但是它不适合按字母顺序排序人名。但是，计数排序可以用在基数排序中的算法来排序数据范围很大的数组。 算法步骤 统计数组中每个值为 i 的元素出现的次数，存入数组 C 的第 i 项 反向填充目标数组 稳定性不稳定 时间复杂度O(n) 实现代码 Python 版 1234567891011121314151617181920212223242526class Solution(object): """ 排序 """ def sort(self, nums): # 字典 统计出现次数 sort_dict = &#123;&#125; # 列表 sort_data = [] # 统计次数 for i in range(len(nums)): if not sort_dict.has_key(nums[i]): sort_dict[nums[i]] = 0 sort_dict[nums[i]] += 1 # 填补 sort_dict_keys = sort_dict.keys() for i in range(len(sort_dict_keys)): value = sort_dict[sort_dict_keys[i]] while value &gt; 0: sort_data.append(sort_dict_keys[i]) value = value - 1 return sort_data 基数排序算法思想基数排序（Radix sort）是一种非比较型整数排序算法，其原理是将整数按位数切割成不同的数字，然后按每个位数分别比较。由于整数也可以表达字符串（比如名字或日期）和特定格式的浮点数，所以基数排序也不是只能使用于整数。 算法步骤 将所有待比较数值（正整数）统一为同样的数位长度，数位较短的数前面补零。 然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后，数列就变成一个有序序列。 稳定性稳定 时间复杂度基数排序的时间复杂度是 O(k·n)，其中 n 是排序元素个数，k 是数字位数。注意这不是说这个时间复杂度一定优于 O(n·log(n))，k 的大小取决于数字位的选择和待排序数据所属数据类型的全集的大小；k 决定了进行多少轮处理，而 n 是每轮处理的操作数目。 基数排序基本操作的代价较小，k 一般不大于 logn ，所以基数排序一般要快过基于比较的排序，比如快速排序。 实现代码 Python 版 12345678910111213141516171819202122232425262728293031class Solution(object): """ 排序 """ def sort(self, nums): # 找到最大数，通过其长度判断要排序的趟数 max_value = nums[0] for i in range(1, len(nums)): if max_value &lt; nums[i]: max_value = nums[i] # 要排序的趟数 times = len(str(max_value)) # 初始化 10 个列表用于分配时暂存 stash_list_array = [] for i in range(10): stash_list_array.append([]) for i in range(times): # 先分配 for nums_i in range(len(nums)): index = nums[nums_i] / pow(10, i) % 10 stash_list_array[index].append(nums[nums_i]) # 再收集 wait_sort_arr = [] for i in range(10): wait_sort_arr.extend(stash_list_array[i]) stash_list_array[i] = [] nums = wait_sort_arr return nums 桶排序算法思想 要对大小为 [1..1000] 范围内的 n 个整数 A[1..n] 排序，可以把桶设为大小为 10 的范围，具体而言，设集合 B[1] 存储 [1..10] 的整数，集合 B[2] 存储 (10..20] 的整数，……集合 B[i] 存储 ((i-1)*10, i*10]的整数，i = 1,2,..100。总共有 100 个桶。然后对 A[1..n] 从头到尾扫描一遍，把每个 A[i] 放入对应的桶 B[j] 中。 然后再对这 100 个桶中每个桶里的数字排序，这时可用冒泡，选择，乃至快排，一般来说任何排序法都可以。最后依次输出每个桶里面的数字，且每个桶中的数字从小到大输出，这样就得到所有数字排好序的一个序列了。 稳定性不稳定 时间复杂度O(m+n) ， 其中 m 为桶的个数， n 为元素的个数 实现代码 Python 版 12345678910111213141516171819def sort(self, data): # 分桶 sort_list = [] for i in range(10): sort_list.append([]) # 元素入桶 for i in range(len(data)): index = int(data[i] * 10) sort_list[index].append(data[i]) # 桶内元素排序 后合并 sort_list_arr = [] for i in range(10): if len(sort_list[i]) &gt; 1: sort_list[i].sort() sort_list_arr.extend(sort_list[i]) return sort_list_arr]]></content>
      <categories>
        <category>Arithmetic</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[练习 MongoDB 操作 —— 地理位置搜索 （六）]]></title>
    <url>%2F2018%2F02%2F07%2Fmongo-exer6%2F</url>
    <content type="text"><![CDATA[本文摘自 《Mongodb 权威指南》特殊的索引和集合一章； MongoDB 支持几种类型的地理空间索引。其中最常用的是 2dsphere 索引（用于地球表面类型的地图）和 2d 索引（用于平面地图和时间连续的数据）； 2dsphere 允许使用 GeoJSON 格式（http://geojson.org/）指定点、线和多边形。点可以形如 [longitude， latitude] ([经度，纬度])的两个元素的数组表示： 1234567&#123; "name": "New York City", "loc": &#123; "type": "Point", "coordinates": [50, 2], &#125;&#125; 线可以用一个由点组成的数组来表示： 1234567&#123; "name": "Hudson River", "loc": &#123; "type": "Line", "coordinates": [[0, 1], [0, 2], [1, 2]] &#125;&#125; 多边形的表示方式与线一样（都是一个由点组成的数组）， 但是 type 不同： 1234567&#123; "name": "New England", "loc": &#123; "type": "Polygon", "coordinates": [[0, 1], [0, 2], [1, 2]] &#125;&#125; loc 字段的名字可以是任意的，但是其中的子对象是由 GeoJson 指定的，不能改变； 在 ensureIndex 中使用 2dsphere 选项就可以创建一个地理空间索引： 1&gt; db.world.ensureIndex(&#123;"loc": "2dsphere"&#125;) 地理空间查询的类型可以使用多种不同类型的地理空间查询：交集（intersection）、包含（within）以及接近(nearness)。查询时，需要将希望找到的内容指定为形如 {&quot;$geometry&quot;: geoJsonDesc} 的 GeoJson 对象。 例如，可以使用 $geoIntersects 操作符找出与查询位置相交的文档： 1234567891011&gt; var eastVillage = &#123; "type": "Polygon", "coordinates": [[ [-73.9917900, 40.7264100], [-73.9917900, 40.7321400], [-73.9829300, 40.7321400], [-73.9829300, 40.7264100], [-73.9917900, 40.7264100] ]] &#125;&gt; db.open.street.map.find(&#123;"loc": &#123;"$geoIntersects": &#123;"$geometry": eastVillage&#125;&#125;&#125;) 可以使用 $geoWithin 查询完全包含在某个区域的文档，例如: East Village 有哪些餐馆？ 1&gt; db.open.street.map.find(&#123;"loc": &#123;"$geoWithin": &#123;"$geometry": eastVillage&#125;&#125;&#125;) 与第一个查询不同，这次不会返回那些只是经过 East Village （比如街道）或者部分重叠（比如用于表示曼哈顿的多边形）的文档。 最后，可以使用 $near 查询附近的位置： 12345&gt; db.open.street.map.find(&#123;"loc": &#123;"$near": &#123;"$geometry": &#123; "type": "Point", "coordinates": [-73.9917900, 40.7264100] &#125;&#125;&#125;&#125;) 注意， $near 是唯一一个会对查询结果进行自动排序的地理空间操作符； $near 的返回结果是按照距离由近及远排序的。 地理位置查询有一点非常有趣：不需要地理空间索引就可以使用 $geoIntersects 或者 $within （$near需要使用索引）。但是，建议在用于表示地理位置的字段上建立地理空间索引，这样可以显著提高查询速度。 复合地理空间索引如果有其他类型的索引，可以将地理空间索引与其他字段组合在一起使用，以便对更复杂的查询进行优化。上面提到过一种可能的查询： “East Village有哪些餐馆？”。如果仅仅使用地理空间索引，我们只能查找到 East Village 内的所有东西，但是如果要将 “restaurants“ 或者是 “pizza“ 单独查询出来，就需要使用其他索引中的字段了： db.open.street.map.ensureIndex({“tags”: 1, “loc”: “2dsphere”}) 然后就能够很快地找到 East Village 内的披萨店了： 1&gt; db.open.street.map.find(&#123;"loc": &#123;"$geoWithin": &#123;"$geometry": eastVillage&#125;&#125;, "tags": "pizza"&#125;) 其他索引字段可以放在 2dsphere 字段前面也可以放在后面，这取决于我们希望首先使用其他索引的字段进行过滤还是首先使用位置进行过滤。应该将那个能够尽可能多的结果的字段放在前面。 2d 索引对于非球面地图（游戏地图、时间连续的数据等），可以使用 2d 索引代替 2dsphere； db.hyrule.ensureIndex({“tile”: “2d”}) 2d索引用于扁平表面，而不是球体表面。 2d索引不应该用在球体表面上，否则极点附近会出现大量的扭曲变形； 文档中应该使用包含两个元素的数组表示 2d 索引字段。示例如下： 1234&#123; "name": "Water Temple", "tile": [32, 32]&#125; 2d 索引只能对点进行索引。可以保存一个由点组成的数组，但是它只会被保存为由点组成的数组，不会被当成线。特别是对于 $geoWithin 查询来说，这是一项重要的区别。如果将街道保存为由点组成的数组，那么如果其中的某个点位于给定的形状之内，这个文档就会与 $geoWithin 相匹配。但是，由这些点组成的线并不一定会完全包含在这个形状之内。 默认情况下，地理空间索引是假设你的值都介于 -180 ~ 180。可以根据需要在 ensureIndex 中设置更大或更小的索引边界值： 1&gt; db.star.trek.ensureIndex(&#123;"light-years": "2d"&#125;, &#123;"min": -1000, "max": 1000&#125;) 这会创建一个 2000 * 2000 大小的空间索引。 使用 2d 索引进行查询比使用 2dsphere 要简单许多。可以直接使用 $near 或者 $geoWithin， 而不必带有 $geometry 子对象。可以直接指定坐标： 1&gt; dy.hyrule.find(&#123;"tile": &#123;"$near": [20, 21]&#125;&#125;) 这样会返回 hyrule 集合内的全部文档，按照距离（20，21）这个点的距离排序。如果没有指定文档数量限制，默认最多返回 100 个文档。如果不需要这么多的结果，应该根据需要设置返回文档的数量以节省服务器资源。例如，下面的代码只会返回距离（20，21）最近的 10 个文档： 1&gt; dy.hyrule.find(&#123;"tile": &#123;"$near": [20, 21]&#125;&#125;).limit(10) $geoWithin 可以查询出某个形状（矩形、圆形或者是多边形）范围内的所有文档。如果要使用矩形，可以指定 $box 选项 1&gt; dy.hyrule.find(&#123;"tile": &#123;"$geoWithin": &#123;"$box": [[10, 20], [15, 30]]&#125;&#125;&#125;) $box 接受一个两元素的数组：第一个元素指定左下角的坐标，第二个元素指定右上角的坐标。 类似地，可以使用 $center 选项返回圆形范围内的所有文档，这个选项也是接受一个两元素数组作为参数：第一个元素是一个点，用于指定圆心；第二个参数用于指定半径： 1&gt; db.hyrule.find(&#123;"tile": &#123;"$geoWithin": &#123;"$center": [[12, 25], 5]&#125;&#125;&#125;) 还可以使用多个点组成的数组来指定多边形： 1&gt; db.hyrule.find(&#123;"tile": &#123;"$geoWithin": &#123;"$polygon": [[0, 20], [10, 0], [-10, 0]]&#125;&#125;&#125;) 这个例子会查询出包含给定三角形内的点的所有文档。列表中的最后一个点会被连接到第一个点，以便组成多边形； 参考阅读 MongoDB 官方文档 geo 操作符 地理空间数据格式——GeoJSON]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>MongoDB3.x</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Dockerfile]]></title>
    <url>%2F2018%2F02%2F06%2Fdocker-dockerfile%2F</url>
    <content type="text"><![CDATA[Dockerfile 是一个文本格式的配置文件，用户可以使用 Dockerfile 快速创建自定义的镜像。 基本结构Dockerfile 由一行行命令语句组成，并且支持 # 开头的注释行。 一般而言，Dockerfile 分为四部分：基础镜像信息、维护者信息、镜像操作指令和容器启动时执行指令。 指令指令的一般格式为 INSTRUCTION arguments，指令包括 FROM、MAINTAINER、RUN等。下面分别介绍。 FROM 格式为： FROM &lt;image&gt; 或 FROM &lt;image&gt;:&lt;tag&gt; 第一条指令必须为 FROM 指令。并且， 如果在同一个 Dockerfile 中创建多个镜像时，可以使用多个 FROM 指令（每个镜像一次）。 MAINTAINER 格式为： MAINTAINER &lt;name&gt;，指定维护者信息 ENV 格式为： ENV &lt;key&gt; &lt;value&gt; 指定一个环境变量，会被后续 RUN 指定使用，并在容器运行时保持。 例如： RUN 格式为：RUN &lt;command&gt; 或 RUN [&quot;executable&quot;， &quot;param1&quot;， &quot;param2&quot;] 前者将在 shell 终端中运行命令，即 /bin/sh -c ；后者则使用 exec 执行；指定使用其他终端可以通过第二种方式实现，例如 RUN [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;echo hello&quot;] 每条 RUN 指令将在当前镜像基础上执行指定命令，并提交为新的镜像。当命令较长时可以使用 \ 来换行。 CMD 支持三种格式 CMD [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] 使用 exec 执行，推荐方式 CMD command param1 param2 在 /bin/bash 中执行，提供给需要交互的应用 CMD [&quot;param1&quot;, &quot;param2&quot;] 提供给 ENTRYPOINT 的默认参数 指定启动容器时执行的命令。每个 Dockerfile 只能有一条 CMD 命令。如果指定了多条命令，则只有最后一条会被执行。 如果用户启动容器时候，指定了运行的命令，则会覆盖 CMD 指定的命令。 ENTRYPOINT 有两种格式 ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] ENTRYPOINT command param1 param2 配置容器启动后执行的命令，并且不可被docker run 提供的参数覆盖； 每个 Dockerfile 中只能有一个 ENTRYPOINT ，当指定多个 ENTRYPOINT 时，只有最后一个生效； EXPOSE 格式为： EXPOSE &lt;port&gt; [&lt;port&gt;...] 例如： 1EXPOSE 22 80 8443 告诉 Docker 服务端容器暴露的端口号，供互联系统使用。在启动容器时需要通过 -P 。Docker 主机会自动分配一个端口转发到指定的端口；使用 -p ，则可以具体指定哪个本地端口映射过来； ADD 格式为： ADD &lt;src&gt; &lt;dest&gt; 该命令将复制指定的 &lt;src&gt; 到容器中的 &lt;dest&gt;。其中，&lt;src&gt;可以是 Dockerfile 所在目录的一个相对路径（文件或目录）；也可以是一个 URL；还可以是一个 tar 文件（自动解压为目录）。 COPY 格式为： COPY &lt;src&gt; &lt;dest&gt; 复制本地主机的 &lt;src&gt; （为 Dockerfile 所在目录的相对路径，文件或目录）为容器中的 &lt;dest&gt;。目标路径不存在时，会自动创建。 当使用本地目录为源目录时，推荐使用 COPY。 VOLUME 格式为： VOLUME [&quot;/data&quot;] 创建一个可以从本地主机或其他容器挂载的挂载点，一般用来存放数据库和需要保持的数据等； USER 格式为： USER daemon 指定运行容器时的用户名或 UID，后续的 RUN 也会使用指定用户。 当服务不需要管理员权限时，可以通过该命令指定运行用户。并且可以在之前创建所需要的用户，使用 RUN groupadd -r postgres &amp;&amp; useradd -r -g postgres postgres。要临时获取管理员权限可以使用 gosu，而不推荐 sudo。 WORKDIR 格式为： WORKDIR /path/to/workdir 为后续的 RUN、CMD、ENTRYPOINT指令配置工作目录。 可以使用多个 WORKDIR 指令，后续命令如果参数是相对路径，则会基于之前命令指定的路径，例如 123WORKDIR /aWORKDIR bWORKDIR c 则最终路径为 /a/b/c； ONBUILD 格式为： ONBUILD [INSTRUCTION] 配置当所创建的镜像作为其他新创建镜像的基础镜像时，所执行的操作指令。例如， Dockerfile 使用如下的内容创建了镜像 image-A 1234[...]ONBUILD ADD . /app/srcONBUILD RUN /usr/local/bin/python-build --dir /app/src[...] 如果基于 image-A 创建新的镜像时，新的 Dockerfile 中使用 FROM image-A 指定基础镜像时，会自动执行 ONBUILD 指令内容，等价于在后面添加了两条指令。 1234FROM image-AADD . /app/srcRUN /usr/local/bin/python-build --dir /app/src# Automatically run the following 使用 ONBUILD 指令的镜像，推荐在标签中注明，例如 ruby:1.9-onbuild； 创建镜像编写完成 Dockerfile 之后，可以通过 docker build 命令来创建镜像。 基本的格式为 docker build [选项] 路径， 该命令将读取指定路径下（包括子目录）的 Dockerfile ，并将该路径下所有内容发送给 Docker 服务端，由服务端来创建镜像。因此一般建议放置 Dockerfile 的目录为空目录。 另外，可以通过 .dockerignore 文件（每一行添加一条匹配模式） 来让 Docker 忽略路径下的目录和文件。 要指定镜像的标签信息，可以通过 -t 选项。 例如，指定 Dockerfile 所在路径为 /tmp/docker_build/ ， 并且希望生成镜像标签为 build_repo/first_image ， 可以使用下面的命令： 1sudo docker build -t build_repo/first_image /tmp/docker_build/]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并行的 PHP RPC 框架 Yar]]></title>
    <url>%2F2018%2F02%2F06%2Fphp-rpc-yar%2F</url>
    <content type="text"><![CDATA[介绍RPC（Remote Procedure Call Protocol）远程过程调用协议，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。RPC 不依赖于具体的网络传输协议，tcp、udp 等都可以。由于存在各式各样的变换和细节差异，相应的 rpc 也派生出了各式远程过程通信协议。RPC 是跨语言的通信标准，SUN 和微软都有其实现，比如RMI 可以被看作 SUN 对 RPC 的 Java 版本( 实现)，而微软的 DCOM 就是建立在 ORPC 协议之上。一言以蔽之，RPC 是协议，而无论是 SUN 的 RMI 还是微软的 DCOM 都是对该协议的不同实现，二者都为编程人员提供了应用PRC技术的程序接口（API`）。 安装pecl 安装 yar 是一个 pecl 扩展，因此可以直接 install : 1pecl install yar 自行编译 123$/path/to/phpize$./configure --with-php-config=/path/to/php-config/$make &amp;&amp; make install Install Yar with msgpack 首先应该安装 msgpack 扩展 1pecl install msgpack 或者，也可以获取 github 源代码 https://github.com/msgpack/msgpack-php 123$phpize$configure --with-php-config=/path/to/php-config/ --enable-msgpack$make &amp;&amp; make install 配置项 yar.timeout 处理超时，默认为 5000 (ms) yar.connect_timeout 连接超时，默认为 1000 (ms) yar.packager //设置 yar 的打包工具，默认是 “php“, 当以 --enable-msgpack 构建扩展，则默认值为 msgpack, 它的值可以为 “php“, “json“, “msgpack“ yar.debug 默认是 Off， 打开的时候, Yar 会把请求过程的日志都打印出来(到 stderr) yar.expose_info 默认是 On, 如果关闭, 则当通过浏览器访问 Server 的时候, 不会出现 Server Info 信息 yar.content_type 默认是 “application/octet-stream“ yar.allow_persistent 默认是 Off 使用常量 YAR_VERSION ： YAR 的当前版本 YAR_OPT_PACKAGER YAR_OPT_PERSISTENT YAR_OPT_TIMEOUT YAR_OPT_CONNECT_TIMEOUT YAR_OPT_HEADER 简单示例Server 端服务器端提供算术服务 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?php/* 假设这个页面的访问路径是: http://example.com/operator.php */class Operator &#123; /** * Add two operands * @param interge * @return interge */ public function add($a, $b) &#123; return $this-&gt;_add($a, $b); &#125; /** * Sub */ public function sub($a, $b) &#123; return $a - $b; &#125; /** * Mul */ public function mul($a, $b) &#123; return $a * $b; &#125; /** * Protected methods will not be exposed * @param interge * @return interge */ protected function _add($a, $b) &#123; return $a + $b; &#125;&#125;$server = new Yar_Server(new Operator());$server-&gt;handle(); 通过 Get 请求， 从浏览器端访问，可以看到自动生成的 API 文档 Client 端调用 123456789101112&lt;?php$client = new yar_client("http://example.com/operator.php");/* call directly */var_dump($client-&gt;add(1, 2));/* call via call */var_dump($client-&gt;call("add", array(3, 2)));/* __add can not be called */var_dump($client-&gt;_add(1, 2)); 输出如下： 123int(3)int(5)PHP Fatal error: Uncaught exception 'Yar_Server_Exception' with message 'call to api Operator::_add() failed' in * Client 端异步调用 1234567891011121314151617&lt;?phpfunction callback($ret, $callinfo) &#123; echo $callinfo['method'] , " result: ", $ret , "\n";&#125;/* 注册一个异步调用 */Yar_Concurrent_Client::call("http://example.com/operator.php", "add", array(1, 2), "callback");Yar_Concurrent_Client::call("http://example.com/operator.php", "sub", array(2, 1), "callback");Yar_Concurrent_Client::call("http://example.com/operator.php", "mul", array(2, 2), "callback");/* 发送所有注册的调用, 等待返回, 返回后Yar会调用callback回掉函数 */Yar_Concurrent_Client::loop();/* 重置call ,否则上面的call会调用*/Yar_Concurrent_Client::reset();Yar_Concurrent_Client::call("http://example.com/operator.php", "sub", array(6, 7), "callback");Yar_Concurrent_Client::loop(); 参考阅读 PHP 官网关于 yar 的文档 Yar – 并行的RPC框架(Concurrent RPC framework) 为什么需要 RPC，而不是简单的 HTTP 接口]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>RPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP 配置管理扩展 Yaconf]]></title>
    <url>%2F2018%2F02%2F05%2Fphp-yaconf%2F</url>
    <content type="text"><![CDATA[介绍Yaconf 是一个专门用来作配置管理的扩展，由 Laurance 编写并开源； Yaconf 有以下的特性： 轻量，快速 常驻内存; 在 PHP 启动的时候, 处理所有的要处理的配置, 然后这些配置就会常驻内存, 随着 PHP 的生命周期存亡. 避免了每次请求的时候解析配置文件 支持丰富的配置类型, 包括字符串, 数组, 分节, 分节继承, 并且还可以在配置中直接写 PHP 的常量和环境变量 修改后自动 reload api 简单 安装Yaconf 是一个 PECL扩展，所以可以通过如下命令轻易安装： 1$pecl install yaconf 也可以，自行编译： 123$ /path/to/php7/bin/phpize$ ./configure --with-php-config=/path/to/php7/bin/php-config$ make &amp;&amp; make install 配置项有两个运行时参数需要在 php.ini 中配置 yaconf.directory 配置文件目录, 这个配置不能通过 ini_set 指定, 因为必须在 PHP 启动的时候就确定好. yaconf.check_delay 多久(秒)检测一次文件变动, 如果是 0 就是不检测, 也就是说如果是 0 的时候, 文件变更只能通过重启 PHP 重新加载 使用Yaconf 采用ini文件作为配置文件, 这是因为作者觉得 ini 是最适合做配置文件的, key-value 格式, 清晰可读。 简单的配置写起来如下(以下全部假设 ini 文件的名字是 test): 123foo="bar"phpversion=PHP_VERSIONenv=$&#123;HOME&#125; 如上所示, 对于一般的配置我们都用引号引起来. 而对于没有引起来的, 会尝试以 PHP 的常量做解释, 也就是说我们可以直接在配置里面写 PHP 的常量. 另外你也看到了, 我们可以直接在配置中写环境变量, 比如上面的 env : 12Yaconf::get("test.env"); //test是配置文件名字# 输出 /root 如上面所示, 你可以看到, 假设对于 foo 的值, 你可以通过如下代码访问: 1Yaconf::get("test.foo"); //test是配置文件名字 Yaconf 也支持数组类型的配置, 写法如下: 12arr[]=1arr.1=2 如上面所示你可以直接使用 foo[] 这种形式来定义数组, 也可以使用 arr.1, arr.2 来指定 key 定义.对于数组的第二个值, 你可以通过如下代码访问: 1Yaconf::get("test.arr.1"); //test是配置文件名字 或者你可以通过获取整个 arr 数组之后访问: 12$arr = Yaconf::get("test.arr"); //test是配置文件名字echo $arr[1]; Yaconf 也支持 map 类型的配置, 写法如下: 123456map.foo=barmap.bar=foo ;你可以使用分号来写注释map2.foo.name=yaconfmap2.foo.year=2015 对于 map2 的 foo 子 map 的 name 值可以通过如下形式访问: 1Yaconf::get("test.map2.foo.name"); //test是配置文件名字 并且, 配置文件还可以分节, 和分节继承: 123456[parent]parent="base"children="NULL" [children : parent]children="children" 请注意配置的分节继承的语法 children:(冒号)parent, 这的意思是 children 节继承全部 base 的配置项. 然后你在 children 节里面定义的和 parent 节中同名的配置, 会覆盖掉 parent 中定义的内容。 对于 chidlren 节的 children 配置的值可以通过如下形式访问: 1Yaconf::get("test.children.children"); //test是配置文件名字]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP-Extensions</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP 生成器及协程]]></title>
    <url>%2F2018%2F02%2F05%2Fphp-yield%2F</url>
    <content type="text"><![CDATA[生成器生成器提供了一种更容易的方法来实现简单的对象迭代，相比较定义类实现 Iterator 接口的方式，性能开销和复杂性大大降低。 生成器允许你在 foreach 代码块中写代码来迭代一组数据而不需要在内存中创建一个数组,那会使你的内存达到上限，或者会占据可观的处理时间。相反，你可以写一个生成器函数，就像一个普通的自定义函数一样,和普通函数只返回一次不同的是, 生成器可以根据需要 yield 多次，以便生成需要迭代的值。 自 PHP 5.5+ 支持生成器； 1234567891011121314151617181920Generator implements Iterator &#123; //返回当前产生的值 public mixed current ( void ) //返回当前产生的键 public mixed key ( void ) //生成器继续执行 public void next ( void ) //重置迭代器,如果迭代已经开始了，这里会抛出一个异常。 public void rewind ( void ) //向生成器中传入一个值，当前yield接收值，然后继续执行下一个yield public mixed send ( mixed $value ) //向生成器中抛入一个异常 public void throw ( Exception $exception ) //检查迭代器是否被关闭,已被关闭返回 FALSE，否则返回 TRUE public bool valid ( void ) //序列化回调 public void __wakeup ( void ) //返回generator函数的返回值，PHP version 7+ public mixed getReturn ( void )&#125; 生成器函数的核心是 yield 关键字。它最简单的调用形式看起来像一个 return 申明，不同之处在于普通 return 会返回值并终止函数的执行，而 yield 会返回一个值给循环调用此生成器的代码并且只是暂停执行生成器函数。 一个生成器不可以返回值：这样做会产生一个编译错误。然而 return 空是一个有效的语法并且它将会终止生成器继续执行。 示例 123456789function xrange($start, $end, $step = 1) &#123; for ($i = $start; $i &lt;= $end; $i += $step) &#123; yield $i; &#125; &#125; foreach (xrange(1, 1000) as $num) &#123; echo $num, "\n"; &#125; 如果了解过迭代器的朋友，就可以通过上面这一段代码看出 Generators 的运行流程 12345678910111213141516调用 `xrang()` 的时候，里面的代码并没有真正的执行，而是返回了一个生成器对象Generators::rewind() 第一次执行迭代器 隐式调用 Generators::valid() 检查迭代器是否被关闭Generators::current() 返回当前产生的值Generators::next() 生成器继续执行Generators::valid() Generators::current() ... Generators::next() Generators::valid() 直到返回 false 迭代结束 交互除了实现 Iterator 的接口之外 Generator 还添加了 send 方法，用来向生成器传入一个值，并且当做 yield 表达式的结果，然后继续执行生成器，直到遇到下一个 yield 后会再次停住。 Generator::send 如果当这个方法被调用时，生成器不在 yield 表达式，那么在传入值之前，它会先运行到第一个 yield 表达式。 通过示例，来了解 Generator::send 的用法 123456789101112131415161718192021function printer() &#123; $i = 1; while(true) &#123; echo 'this is the yield ' . (yield $i) . "\n"; $i++; &#125;&#125;$printer = printer();var_dump($printer-&gt;send('first'));var_dump($printer-&gt;send('second'));/* * output * * this is the yield first * int(2) * this is the yield second * int(3) */ $printer = printer();代码返回一个生成器对象 $printer-&gt;send(&#39;first&#39;)此时生成器还未开始运行；于是先调用 rewind,执行 yield 返回; 接着将 send 的参数赋值作为 yield 表达式的值，继续执行到 下一个 yield 返回 后停止；等待下一次输入； 不仅仅能够 send，PHP 还提供了一个 throw，允许我们返回一个异常给 Generator 123456789101112131415161718192021222324$Generatorg = call_user_func(function()&#123; $hello = (yield '[yield] say hello'.PHP_EOL); echo $hello.PHP_EOL; try&#123; $jump = (yield '[yield] I jump,you jump'.PHP_EOL); &#125;catch(Exception $e)&#123; echo '[Exception]'.$e-&gt;getMessage().PHP_EOL; &#125;&#125;);$hello = $Generatorg-&gt;current();echo $hello;$jump = $Generatorg-&gt;send('[main] say hello');echo $jump;$Generatorg-&gt;throw(new Exception('[main] No,I can\'t jump'));/* * output * * [yield] say hello * [main] say hello * [yield] I jump,you jump * [Exception][main] No,I can't jump */ 协程协程的支持是在迭代生成器的基础上， 增加了可以回送数据给生成器的功能(调用者发送数据给被调用的生成器函数)。 这就把生成器到调用者的单向通信转变为两者之间的双向通信。 上面的例子很好地进行了示范； 你也许会疑惑“为了双向通信我为什么要使用协程呢？我完全可以使用其他非协程方法实现同样的功能啊?”, 是的, 你是对的, 但上面的例子只是为了演示了基本用法, 这个例子其实并没有真正的展示出使用协程的优点。 正如上面介绍里提到的,协程是非常强大的概念,不过却应用的很稀少而且常常十分复杂。要给出一些简单而真实的例子很难。 在这篇文章里,我决定去做的是使用协程实现多任务协作。我们要解决的问题是你想并发地运行多任务(或者“程序”）。不过我们都知道 CPU 在一个时刻只能运行一个任务（不考虑多核的情况）。 因此处理器需要在不同的任务之间进行切换,而且总是让每个任务运行 “一小会儿”。 多任务协作这个术语中的“协作”很好的说明了如何进行这种切换的：它要求当前正在运行的任务自动把控制传回给调度器,这样就可以运行其他任务了. 这与“抢占”多任务相反, 抢占多任务是这样的：调度器可以中断运行了一段时间的任务, 不管它喜欢还是不喜欢. 协作多任务在 Windows 的早期版本( windows95 )和 Mac OS 中有使用, 不过它们后来都切换到使用抢先多任务了。 理由相当明确：如果你依靠程序自动交出控制的话, 那么一些恶意的程序将很容易占用整个 CPU, 不与其他任务共享。 现在你应当明白协程和任务调度之间的关系：yield 指令提供了任务中断自身的一种方法, 然后把控制交回给任务调度器. 因此协程可以运行多个其他任务. 更进一步来说, yield 还可以用来在任务和调度器之间进行通信. 此处示例详见 Laurance 在PHP中使用协程实现多任务调度]]></content>
      <categories>
        <category>PHP</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Docker 仓库、镜像与容器]]></title>
    <url>%2F2018%2F02%2F04%2Fdocker-image-container%2F</url>
    <content type="text"><![CDATA[镜像查询列出机器上的所有镜像 1docker image ls 查看镜像的详细信息docker inspect 命令返回的是一个 json 格式的消息，如果我们只要其中一项内容时，可以指定 -f 参数来指定； 123docker inspect $&#123;IMAGE_ID&#125;docker inspect -f &#123;&#123;".Config.WorkingDir"&#125;&#125; bb3ac90ec48b 从 Docker Hub 查找镜像 1docker search [OPTIONS] nginx OPTIONS 说明 --automated : 只列出 automated build 类型的镜像； --no-trunc :显示完整的镜像描述； -s :列出收藏数不小于指定值的镜像； 默认地输出结果将按照星级评价进行排序。官方的镜像说明是官方项目组创建和维护。 automated 资源允许用户验证镜像的来源和内容。 获取从 Docker Hub 中拉取或者更新指定镜像对于 docker 来说，如果不显式地指定 Tag，则会默认地选择 latest 标签，即下载仓库中最新版本的镜像； 1docker pull [-a] name[:tag] -a 参数拉取所有 tagged 镜像 增加创建镜像的方法有三种：基于已有镜像的容器创建，基于本地模板导入，基于 Dockerfile 创建； 基于已有镜像的容器创建1docker commit [OPTIONS] container_id [Repository:[tag]] OPTIONS 说明 -a， --author=&quot;&quot;: 作者信息 -m，--message=&quot;&quot;: 提交信息 -p，--pause=true: 提交时暂停容器运行 基于本地模板导入也可以直接从一个操作系统模板文件导入一个镜像。推荐使用 OpenVZ 提供的模板来创建。 比如，下载一个 ubuntu-14.04 的模板压缩后，可以使用以下命令导入： 1sudo cat ubuntu-14.04-x86_64-minimal.tar.gz | docker import - ubuntu:14.04 删除删除一个镜像 1docker rmi $&#123;IMAGE_ID&#125; 删除所有没有标签的镜像 1docker rmi $(docker images | grep “^” | awk “&#123;print $3&#125;”) 删除所有的镜像 1docker rm $(docker ps -aq) 删除未使用的镜像 1docker rmi $(docker images --quiet --filter &amp;quot;dangling=true&amp;quot;) 存出和载入可以使用 docker save 和 docker load 命令来存出和载入镜像。 如果要存出镜像到本地文件，可以使用 docker save命令。例如，存出本地的 ubuntu:14.04 镜像到 ubuntu_14.04.tar: 1sudo docker save -o ubuntu_14.04.tar ubuntu:14.04 可以使用 docker load 从存出的本地文件中再导入到本地镜像库，例如从文件 ubuntu_14.04.tar 导入镜像到本地镜像列表 12sudo docker load --input ubuntu_14.04.tar# 或 sudo docker load &lt; ubuntu_14.04.tar 容器增新建容器可以使用 docker create 命令来创建容器， 例如 1sudo docker create -it ubuntu:latest 使用 docker create 命令新建的容器处于停止状态，可以使用 docker start命令来启动。 新建并启动容器启动容器有两种方式，一种是基于镜像新建一个容器并启动，另外一个是将在终止状态（stopped）的容器重新启动。所需的命令主要为 docker run，等价于先执行 docker create 命令，再执行 docker start 命令； 当利用 docker run 来创建并启动容器时， Docker 在后台运行的标准操作包括： 检查本地是否存在指定的镜像，不存在就从公有仓库下载。 利用镜像创建并启动一个容器。 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层。 从宿主机配置的网桥接口中桥接一个虚拟接口到容器中去。 从地址池配置一个 IP 地址给容器。 执行用户指定的应用程序。 执行完毕后容器被终止。 下面的命令则启动一个 bash 终端，允许用户进行交互： 1sudo docker run -t -i ubuntu:14.04 /bin/bash 用户可以按 Ctrl + d 或输入 exit 命令来退出容器；对于创建的容器，当使用 exit 命令退出之后，该容器就自动处于终止状态。 删除删除指定容器 1docker rm $&#123;CID&#125; 删除所有退出的容器 1docker rm -f $(docker ps -a | grep Exit | awk '&#123; print $1 &#125;') 删除所有的容器 1docker rm $(docker ps -aq) 查显示指定容器的IP 1docker inspect --format '&#123;&#123; .NetworkSettings.IPAddress &#125;&#125;' $&#123;CID&#125; 查看Docker的底层信息,它会返回一个 JSON 文件记录着 Docker 容器的配置和状态信息 1docker inspect &lt;container id/name&gt; 查看容器端口的映射情况 1docker port &lt;container name/id&gt; &lt;port&gt; 显示正在运行的容器 1docker ps 显示所有的容器 1docker ps -a 显示所有退出状态为 1 的容器 1docker ps -a --filter &amp;quot;exited=1&amp;quot; 查看容器内的标准输出 12docker logs $&#123;CID&#125;# docker logs -f $&#123;CID&#125; 相当于 tailf 查看容器内的标准输出 运行进入容器进入容器 1docker exec -it $&#123;CID&#125; bash 停止容器停止指定容器 1docker stop $&#123;CID&#125; 停止所有正在运行的容器 1docker stop docker ps -q 导入与导出导出容器是指导出一个已经创建的容器到一个文件，不管此时这个容器是否处于运行状态，可以使用 docker export 命令，该命令格式为 docker export CONTAINER 。 1sudo docker export 943f73177d5c &gt; test_for_run.tar 导出的文件又可以使用 docker import 命令导入，成为镜像： 1cat test_for_run.tar | sudo docker import - test/ubuntu:v1.0 实际上，既可以使用 docker load 命令来导入镜像存储文件到本地的镜像库，又可以使用 docker import 命令来导入一个容器快照到本地镜像库。这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息（仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积也要大。此外，从容器快照文件导入时可以重新指定标签等元数据信息。 具体命令详参docker run docker run [OPTIONS] IMAGE [COMMAND] [ARG…] OPTIONS 说明： -d, --detach=false 指定容器运行于前台还是后台，默认为 false -i, --interactive=false 打开 STDIN，用于控制台交互 -t, --tty=false 分配 tty 设备，该可以支持终端登录，默认为 false - -u, --user=&quot;&quot; 指定容器的用户 -a, --attach=[] 登录容器（必须是以 docker run -d启动的容器） -w, --workdir=&quot;&quot; 指定容器的工作目录 -c, --cpu-shares=0 设置容器 CPU 权重， 在 CPU 共享场景使用 -e, --env=[] 指定环境变量，容器中可以使用该环境变量 -m, --memory=&quot;&quot; 指定容器的内存上限 -P, --publish-all=false 指定容器暴露的端口 -p, --publish=[] 指定容器暴露的端口 -h, --hostname=&quot;&quot; 指定容器的主机名 -v, --volume=[] 给容器挂载存储卷，挂载到容器的某个目录 --volumes-from=[] 给容器挂载其他容器上的卷，挂载到容器的某个目录 --cap-add=[] 添加权限，权限清单详见：http://linux.die.net/man/7/capabilities --cap-drop=[] 删除权限，权限清单详见：http://linux.die.net/man/7/capabilities --cidfile=&quot;&quot; 运行容器后，在指定文件中写入容器 PID 值，一种典型的监控系统用法 --cpuset=”” 设置容器可以使用哪些CPU，此参数可以用来容器独占CPU --device=[] 添加主机设备给容器，相当于设备直通 --dns=[] 指定容器的 dns 服务器 --dns-search=[] 指定容器的 dns 搜索域名，写入到容器的 /etc/resolv.conf 文件 --entrypoint=&quot;&quot; 覆盖 image 的入口点 --env-file=[] 指定环境变量文件，文件格式为每行一个环境变量 --expose=[] 指定容器暴露的端口，即修改镜像的暴露端口 --link=[] 指定容器间的关联，使用其他容器的 IP、env 等信息 --lxc-conf=[] 指定容器的配置文件，只有在指定 --exec-driver=lxc 时使用 --name=&quot;&quot; 指定容器名字，后续可以通过名字进行容器管理，links特性需要使用名字 --net=&quot;bridge&quot; 容器网络设置: bridge 使用 docker daemon 指定的网桥 host 容器使用主机的网络 container:NAME_or_ID 使用其他容器的网路，共享IP和PORT等网络资源 none 容器使用自己的网络（类似 --net=bridge），但是不进行配置 --privileged=false 指定容器是否为特权容器，特权容器拥有所有的capabilities --restart=&quot;no&quot; 指定容器停止后的重启策略:no：容器退出时不重启on-failure：容器故障退出（返回值非零）时重启always：容器退出时总是重启 --rm=false 指定容器停止后自动删除容器(不支持以 docker run -d 启动的容器) --sig-proxy=true 设置由代理接受并处理信号，但是 SIGCHLD、SIGSTOP 和 SIGKILL 不能被代理 仓库仓库（Repository） 是集中存放镜像的地方。 一个容易与之混淆的概念是注册服务器（Registry） 。实际上注册服务器是存放仓库的具体服务器，每个服务器上可以有多个仓库，而每个仓库下面有多个镜像。 创建私有仓库安装好 docker 后，可以通过官方提供的 registry 镜像来简单搭建一套本地私有仓库环境： 1docker run -d -p 5000:5000 registry 这将自动下载并启动一个 registry 容器，创建本地的私有仓库服务； 默认情况下，会将仓库创建在容器的 /tmp/registry 目录下。可以通过 -v 参数来将镜像文件存放在本地的指定路径上。例如下面的例子将上传的镜像放到 /opt/data/registry 目录： 1docker run -d -p 5000:5000 -v /opt/data/registry:/var/lib/registry registry 使用私有仓库假设当前私有仓库所有服务器的 IP 地址为 172.16.1.68； 在当前服务器上查看已有的镜像： 1sudo docker image ls 使用 docker tag 命令将这个镜像标记为 192.168.1.68:5000/redgo/php （格式为 docker tag IMAGE[:TAG] [REGISTORYHOST][USERNAME/]NAME[:TAG]） 1docker tag php:7.1.0-fpm 192.168.1.68:5000/redgo/php:7.1.0 使用 docker push上传标记的镜像 现在可以到任意一台能访问到 192.168.1.68 地址的机器去下载这个镜像了。]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 安装]]></title>
    <url>%2F2018%2F02%2F03%2Fdocker-install%2F</url>
    <content type="text"><![CDATA[本笔记基于 Centos 7 服务器； Docker安装Linuxyum 的仓库中有一个很旧的 Docker 包, 现在 Docker 官方已经将 Docker 更名为 docker-engine。使用下边的命令设置最新稳定版的 docker 仓库 1yum-config-manager --add-repo https://docs.docker.com/v1.13/engine/installation/linux/repo_files/centos/docker.repo 如果不存在 yum-config-manager 命令，请执行 yum -y install yum-utils； 更新 yum 源 1yum makecache fast 安装最新的 docker 1yum -y install docker-engine 注意：Docker 1.11.1 版本要求 Linux 内核要求达到 3.10.0，可以通过命令 cat /proc/version 查看当前 Linux系统版本； 服务的启动与关闭1service docker start 如果想设置开机启动，可键入命令chkconfig docker on； 对应地，如果想要关闭服务 1service docker stop 加速使用 DaoCloud 加速镜像获取，具体命令参考DaoCloud 网页 - 加速器； 卸载yum 卸载如果是通过 yum 方式安装，执行以下步骤 找到安装包 1yum list installed | grep docker 移出安装包 1yum -y remove docker.x86_64 删除镜像/容器 1rm -rf /var/lib/docker 参考阅读 CentOS7下安装docker 玩转Docker镜像]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web 常见场景问题之 单点登录]]></title>
    <url>%2F2018%2F01%2F31%2Fweb-faq-sso%2F</url>
    <content type="text"><![CDATA[单点登录 SSO（Single Sign On ）说得简单点就是在一个多系统共存的环境下，用户在一处登录后，就不用在其他系统中登录，也就是用户的一次登录能得到其他所有系统的信任。单点登录在大型网站里使用得非常频繁，例如像阿里巴巴这样的网站，在网站的背后是成百上千的子系统，用户一次操作或交易可能涉及到几十个子系统的协作，如果每个子系统都需要用户认证，不仅用户会疯掉，各子系统也会为这种重复认证授权的逻辑搞疯掉。实现单点登录说到底就是要解决如何产生和存储那个信任，再就是其他系统如何验证这个信任的有效性，因此要点也就以下两个： 存储信任 验证信任 以 Cookie 作为凭证媒介条件： 各系统要同域 各系统的cookie 的 key 值要相同 各个后台的 session 信息要放一起，共享 只能保证单点登录，不能保证单点注销； 使用独立登录系统登录相比于单系统登录，sso 需要一个独立的认证中心，只有认证中心能接受用户的用户名密码等安全信息，其他系统不提供登录入口，只接受认证中心的间接授权。间接授权通过令牌实现，sso 认证中心验证用户的用户名密码没问题，创建授权令牌，在接下来的跳转过程中，授权令牌作为参数发送给各个子系统，子系统拿到令牌，即得到了授权，可以借此创建局部会话，局部会话登录方式与单系统的登录方式相同。 用户登录成功之后，会与 sso 认证中心及各个子系统建立会话，用户与 sso 认证中心建立的会话称为全局会话，用户与各个子系统建立的会话称为局部会话，局部会话建立之后，用户访问子系统受保护资源将不再通过 sso 认证中心，全局会话与局部会话有如下约束关系: 局部会话存在，全局会话一定存在 全局会话存在，局部会话不一定存在 全局会话销毁，局部会话必须销毁 注销单点登录自然也要单点注销，在一个子系统中注销，所有子系统的会话都将被销毁，用下面的图来说明 参考阅读 JC_Huang 单点登录的三种实现方式 单点登录原理与简单实现]]></content>
      <categories>
        <category>Web FAQ</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[PHP SPL 标准库]]></title>
    <url>%2F2018%2F01%2F30%2Fphp-spl%2F</url>
    <content type="text"><![CDATA[SPL 是用于解决典型问题(standard problems)的一组接口与类的集合。 数据结构双向链表双链表 (DLL) 是一个链接到两个方向的节点列表。当底层结构是 DLL 时, 迭代器的操作、对两端的访问、节点的添加或删除都具有 O(1) 的开销。因此, 它为栈和队列提供了一个合适的实现。 双向链表的数据结构 SplDoublyLinkedList 基于双向链表实现的栈 SplStack 基于双向链表实现的队列 SplQueue 堆最大（最小）堆是一棵每一个节点的键值都不小于（大于）其孩子（如果存在）的键值的树。大顶堆是一棵完全二叉树，同时也是一棵最大树。小顶堆是一棵完全完全二叉树，同时也是一棵最小树。 堆数据结构 SplHeap 大顶堆 SplMaxHeap 小顶堆 SplMinHeap 基于堆继承，特定于队列优先级场景的SplPriorityQueue 数组数组是以连续方式存储数据的结构, 可通过索引进行访问。不要将它们与 php 数组混淆: php 数组实际上是按照有序的列表实现的。 固定大小的数组 SplFixedArray 对象集SPL 提供了从对象到数据的映射。此映射也可用作对象集。 对象集 SplObjectStorage 迭代器SPL 提供一系列迭代器以遍历不同的对象。 ArrayIterator 遍历数组和对象 RecursiveArrayIterator 可递归遍历数组和对象 EmptyIterator 空迭代器 IteratorIterator 迭代器的装饰器 AppendIterator 这个迭代器能陆续遍历几个迭代器 CachingIterator 支持对另一个迭代器的缓存迭代。 RecursiveCachingIterator 支持对另一个可递归迭代器的递归缓存迭代 FilterIterator 过滤元素的迭代器 CallbackFilterIterator 回调函数过滤元素的迭代器 RecursiveCallbackFilterIterator 可递归地回调函数过滤元素的迭代器 RecursiveFilterIterator 与 RecursiveIteratorIterator 结合使用，可以进行递归过滤 ParentIterator 筛选出有子元素的迭代器 RegexIterator 正则迭代器 RecursiveRegexIterator 可递归的正则迭代器 InfiniteIterator 无限循环遍历 LimitIterator 允许遍历一个 Iterator 的限定子集的元素. NoRewindIterator 不可再 rewind 遍历 MultiplerIterator 并列迭代多个迭代器 RecursiveIteratorIterator 可递归的迭代器 RecursiveTreeIterator 允许遍历一个递归迭代器来生成一个ASCII图形树。 DirectoryIterator 目录迭代器 FilesystemIterator 对目录迭代器的二次封装 GlobIterator 遍历一个文件系统行为类似于 glob(). 即路径名带 * RecursiveDirectoryIterator 可递归目录迭代器 接口Countable类实现 Countable 可被用于 count() 函数. 1234Countable &#123; /* 方法 */ abstract public int count ( void )&#125; OuterIterator类实现 OuterIterator 可被用于迭代迭代器； 12345678910OuterIterator extends Iterator &#123; /* 方法 */ public Iterator getInnerIterator ( void ) /* 继承的方法 */ abstract public mixed Iterator::current ( void ) abstract public scalar Iterator::key ( void ) abstract public void Iterator::next ( void ) abstract public void Iterator::rewind ( void ) abstract public boolean Iterator::valid ( void )&#125; RecursiveIterator类实现 RecursiveIterator 可被用于递归迭代迭代器； 1234567891011RecursiveIterator extends Iterator &#123; /* 方法 */ public RecursiveIterator getChildren ( void ) public bool hasChildren ( void ) /* 继承的方法 */ abstract public mixed Iterator::current ( void ) abstract public scalar Iterator::key ( void ) abstract public void Iterator::next ( void ) abstract public void Iterator::rewind ( void ) abstract public boolean Iterator::valid ( void )&#125; SeekableIterator可以根据下标搜索 12345678910SeekableIterator extends Iterator &#123; /* 方法 */ abstract public void seek ( int $position ) /* 继承的方法 */ abstract public mixed Iterator::current ( void ) abstract public scalar Iterator::key ( void ) abstract public void Iterator::next ( void ) abstract public void Iterator::rewind ( void ) abstract public boolean Iterator::valid ( void )&#125; SplSubject 与 SplObserverSplSubject 与 SplObserver 一起使用实现观察者模式； 1234567891011SplSubject &#123; /* 方法 */ abstract public void attach ( SplObserver $observer ) abstract public void detach ( SplObserver $observer ) abstract public void notify ( void )&#125;SplObserver &#123; /* 方法 */ abstract public void update ( SplSubject $subject )&#125; 异常 LogicException (extends Exception) 应用程序编写有错误时会抛出此异常 BadFunctionCallException 找不到方法 BadMethodCallException 找不到函数 DomainException 值不符合有效数据域 InvalidArgumentException 无效参数 LengthException 长度异常 OutOfRangeException 请求非法索引（重点在索引 index） RuntimeException (extends Exception) 运程过程中发现的异常 OutOfBoundsException 键值找不到（重点在 key） OverflowException 向一个装满元素的容器再添加元素时，报此异常 RangeException程序执行期间，抛出的异常表示范围错误。通常这意味着除了在溢出之外，还有一个算术错误。这是 DomainException 的运行时版本。 UnderflowException 在一个空容器执行无效操作，比如移除元素 UnexpectedValueException 不是预期值异常 SPL 函数 函数名 描述 class_implements 返回指定的类实现的所有接口 class_parents 返回指定类的父类 class_uses 返回指定类用到的 trait iterator_apply 为迭代器中每个元素调用一个用户自定义函数 iterator_count 计算迭代器中元素的个数 iterator_to_array 将迭代器中的元素拷贝到数组 spl_classes 返回所有可用的 SPL 类 spl_object_hash 返回指定对象的 hash id spl_object_id 为指定对象生成独一无二的 id， 类似于 spl_object_hash spl_autoload_functions 返回所有已注册的 __autoload() 函数 spl_autoload_register 注册给定的函数作为 __autoload 的实现 spl_autoload_unregister 注销已注册的 __autoload() 函数 spl_autoload __autoload() 函数的默认实现 spl_autoload_extensions 注册并返回 spl_autoload 函数使用的默认文件扩展名。 spl_autoload_call 尝试调用所有已注册的 __autoload() 函数来装载请求类 文件处理SplFileInfoSplFileInfo 类提供了针对单个文件的高级面向对象接口。 获取文件的基本信息；比如文件名、路径、访问时间、修改时间； SplFileObject继承了 SplFileInfo 类，同时实现迭代器相关功能； 可以对文件内容进行迭代读取，和重写，不支持 append 追加 ； SplTempFileObject继承了 SplFileObject 类；临时文件；]]></content>
      <categories>
        <category>PHP</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mysql 慢查询]]></title>
    <url>%2F2018%2F01%2F21%2Fmysql-slow-log%2F</url>
    <content type="text"><![CDATA[简介开启慢查询日志，可以让 MySQL 记录下查询超过指定时间的语句，通过定位分析性能的瓶颈，才能更好的优化数据库系统的性能。 参数说明 字段 描述 slow_query_log 慢查询开启状态 slow_query_log_file 慢查询日志存放的位置（这个目录需要 MySQL 的运行帐号的可写权限，一般设置为 MySQL 的数据存放目录） long_query_time 查询超过多少秒才记录 命令查看查看慢查询相关参数 123456789101112131415show variables like 'slow_query%';+---------------------------+----------------------------------+| Variable_name | Value |+---------------------------+----------------------------------+| slow_query_log | OFF || slow_query_log_file | /mysql/data/localhost-slow.log |+---------------------------+----------------------------------+mysql&gt; show variables like 'long_query_time';+-----------------+-----------+| Variable_name | Value |+-----------------+-----------+| long_query_time | 10.000000 |+-----------------+-----------+ 设置变量设置12345678# 将 slow_query_log 全局变量设置为“ON”状态mysql&gt; set global slow_query_log='ON';# 设置慢查询日志存放的位置mysql&gt; set global slow_query_log_file='/usr/local/mysql/data/slow.log';# 查询超过1秒就记录mysql&gt; set global long_query_time=1; 配置设置修改配置文件 my.cnf，在 [mysqld] 下的下方加入 1234[mysqld]slow_query_log = ONslow_query_log_file = /usr/local/mysql/data/slow.loglong_query_time = 1 重启 mysql 服务器 测试执行一条慢查询 SQL 语句 1mysql&gt; select sleep(2); 查看是否生成慢查询日志 1ls /usr/local/mysql/data/slow.log 本文转自 成九云笔记 - MySQL慢查询（一） - 开启慢查询]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 账号管理]]></title>
    <url>%2F2018%2F01%2F19%2Flinux-user-group%2F</url>
    <content type="text"><![CDATA[概念用户标识符 每个登录的用户至少都有两个 ID，一个是用户 ID（UID）， 另一个是用户组 ID（GID）; 用户 ID 信息存放在 /etc/passwd 文件中； 用户组 ID 信息存放在 /etc/group 文件中； 用户密码表存放在 /etc/shadow 文件中； /etc/passwd 文件结构每一行使用 “：” 来分隔开，共有七个字段，分别是 1. 账号名称就是账号，用来对应 UID； 2. 密码早期 UNIX 系统的密码就是放在这字段上，后来这个字段的密码数据改放到 /etc/shadow 中了，所以这里会显示 x; 3. UID用户标识符。 ID范围 该 ID 用户特性 0 (系统管理员) 当 uid 是 0 时，代表这个账号是 “系统管理员”！所以当你要让其他的账号名称也具有 root 的权限时，将该账号的 UID 改为 0 即可。这也就是说一个系统上的系统管理员不见得只有 root。不过，不建议有多个账户的 uid 是 0 1 ~ 499 (系统账号) 根据系统账号的由来，通常系统账号又被分为两种： 1 ~ 99： 由 distributions 自行创建的系统账号 100 ~ 499：若用户有系统账号需求时，可以使用的账号 uid 500 ~ 65535 (系统管理员) 给一般用户用的。事实上，目前的 Linux 内核（2.6.x）版已经可以支持到 （2^32 - 1）这么大的 uid 号码 4. GID这个与 /etc/group 有关。用来规定组名与 GID 对应关系。 5. 用户信息列说明这个字段基本上并没有什么重要用途，只是用来解释这个账号的意义而已。不过，如果你提供使用 finger 的功能时，这个字段可以提供很多的信息。 6. 主文件夹这是用户的主文件夹。 7. Shell当用户登录系统后就会取得一个 Shell 来与系统的内核通信以进行用户的操作任务。 /etc/group 文件结构1. 用户组名称 2. 用户组密码密码，已经移到 /etc/gshadow 文件中 3. 用户组ID 4. 此用户组支持的账号名称 命令用户新增123456# 新增普通用户, 会在/home 下创建同名文件夹，权限为 700，会创建同名的用户组useradd vbird1# 指定用户组，指定 uiduseradd -u 700 -g users vbird2# 创建系统账户，不会在/home 下创建同名文件夹，会创建同名的用户组，UID/GID 在 500 以内useradd -r vbird3 useradd 基本账号设置值参考文件在 /etc/default/useradd 文件中，但也可以由命令 useradd -D 调出； 关于 uid / gid ， 在 /etc/login.defs; 修改密码12345678910111213141516# 修改 vbird2 用户的密码passwd vbird2# 修改自己账号密码passwd# 部分 linux 版本支持非手动修改密码，参考 man passwd 确认是否支持echo "newpassword" | passwd --stdin vbird2# 查看密码相关参数信息passwd -S vbird2# 或 change -l vbird2# 锁住用户密码，让其无法登录passwd -l vbird2# 解锁passwd -u vbird2 修改用户信息12345# 修改用户 vbird2 的说明列usermod -c "Vbird 's test" vbird2# 用户 vbird2 密码在 2009/12/31 失效usermod -e "2009-12-31" vbird2 删除12345# 删除 username 用户userdel username# 删除 vbird2 用户，包含主文件夹userdel -r vbird2 查询相关 UID/GID 信息12345# 查询 vbird2 用户的 uid / gid 等信息id vbird1# 查询 root 自己的相关 id 信息id 查看当前用户支持的用户组1groups 查看登录系统的用户信息123w#或者who 查看登录系统的用户日志 123last# 或者lastlog 用户对谈 语法：write 用户账号 [用户所在终端接口] 12# 比如 `root` 用户向 `vbird1` 用户发消息write vbird1 pts/2 如果 vbird1 不想要接收任何人的消息，执行 mesg n, 当然 mesg 对 root 发来的消息没有抵抗力；如果想要解开的话 mesg y; 如果要对所有人群发信息，用 wall 命令； 1wall "I will shutdonw my linux server..." 用户组切换有效用户组1newgrp 新用户组名 新增用户组1234# 新增名为 group1 的普通用户组groupadd group1# 新增名为 group2 的系统用户组groupadd -r group2 修改用户组信息12# 将 group1 改名为 mygroupgroupmod -n mygroup group1 删除用户组12# 删除用户组 mygroupgroupdel mygroup 用户组管理员示例， 以下是 root 用户执行 12345678# 新建用户组groupadd testgroup# 给用户组一个密码gpasswd testgroup# testgroup 用户组添加 vbird1 用户为组管理员gpasswd -A vbird1 testgroup# 查询 testgroup 用户组信息grep testgroup /etc/group /etc/gshadow vbird1 用户登录 12345# 查询用户信息id# 添加 vbird1、vbird2 进 testgroup 用户组gpasswd -a vbird1 testgroupgpasswd -a vbird2 testgroup]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[认识 Redis]]></title>
    <url>%2F2018%2F01%2F14%2Fnosql-redis%2F</url>
    <content type="text"><![CDATA[搭建部署基于 centos 6.5 安装 下载安装包 1wget http://download.redis.io/redis-stable.tar.gz 解压安装包 1tar -zxvf redis-stable.tar.gz 编译、安装 123cd redis-stablemakemake install 注： make 命令时可能会报错，如果提示 gcc command 不识别，自行安装 gcc ; 启动加上 &amp; 号使 Redis 以后台程序方式运行；加参数 --protected-mode no 可以使无保护模式启动； 1redis-server ./path/to/conf-file &amp; 或者在配置文件修改 daemonize 的值为 yes，也可以使 Redis 在后台启动； 检测检测后台进程是否存在 1ps -ef |grep redis 检测 6379 端口是否在监听 1netstat -lntp | grep 6379 使用 redis-cli 客户端检测连接是否正常 1redis-cli [-h localhost -p 6379] 如果外部无法访问，检查配置文件是否开启外部访问 1# bind 127.0.0.1 持久化Redis 有两种持久化的方式：快照（RDB 文件）和追加式文件（AOF 文件）: RDB 持久化方式是在一个特定的间隔保存某个时间点的一个数据快照。 AOF（Append only file）持久化方式则会记录每一个服务器收到的写操作。数据恢复时，这些记录的操作会逐条执行从而重建出原来的数据。写操作命令记录的格式跟 Redis 协议一致，以追加的方式进行保存。 RDBRDB 就是Snapshot存储，是默认的持久化方式。按照一定的策略周期性的将数据保存到磁盘。对应产生的数据文件为 dump.rdb，通过配置文件中的save参数来定义快照的周期。Redis支持将当前数据的快照存成一个数据文件实现持久化。而一个持续写入的数据库如何生成快照呢。Redis借助了fork命令的copy on write机制。在生成快照时，将当前进程fork出一个子进程，然后在子进程中循环所有的数据，将数据写成为RDB文件。 Client 也可以使用 save 或者 bgsave 命令通知 redis 做一次快照持久化。save 操作是在主线程中保存快照的，由于 redis 是用一个主线程来处理所有 client 的请求，这种方式会阻塞所有 client 请求，所以不推荐使用。另一点需要注意的是，每次快照持久化都是将内存数据完整写入到磁盘一次，并不是增量的只同步脏数据。如果数据量大的话，而且写操作比较多，必然会引起大量的磁盘 io 操作，可能会严重影响性能。 Redis 的 RDB 文件不会坏掉，因为其写操作是在一个新进程中进行的。当生成一个新的 RDB 文件时，Redis 生成的子进程会先将数据写到一个临时文件中，然后通过原子性 rename 系统调用将临时文件重命名为 RDB 文件。这样在任何时候出现故障，Redis 的 RDB 文件都总是可用的。并且 Redis 的 RDB 文件也是 Redis 主从同步内部实现中的一环。 主从同步： 第一次 Slave 向 Master 同步的实现是：Slave 向 Master 发出同步请求，Master 先 dump 出 rdb 文件，然后将 rdb 文件全量传输给 slave，然后 Master 把缓存的命令转发给 Slave，初次同步完成。 第二次 以及以后的同步实现是：Master 将变量的快照直接实时依次发送给各个 Slave。但不管什么原因导致 Slave 和 Master 断开重连都会重复以上两个步骤 (完整 + 增量) 的过程。 Redis 的主从复制是建立在内存快照的持久化基础上的，只要有 Slave 就一定会有内存快照发生。 工作原理 Redis 调用 fork()，产生一个子进程。 父进程继续处理 client 请求，子进程把内存数据写到一个临时的 RDB 文件。由于 os 的写时复制机制（copy on write)父子进程会共享相同的物理页面，当父进程处理写请求时 os 会为父进程要修改的页面创建副本，而不是写共享的页面。所以子进程的地址空间内的数据是 fork 时刻整个数据库的一个快照。 当子进程将快照写入临时文件完毕后，用临时文件替换原来的快照文件，然后子进程退出 优缺点优点： RDB 文件是一个很简洁的单文件，它保存了某个时间点的 Redis 数据，很适合用于做备份。你可以设定一个时间点对 RDB 文件进行归档，这样就能在需要的时候很轻易的把数据恢复到不同的版本。 RDB 很适合用于灾备。单文件很方便就能传输到远程的服务器上。 RDB 的性能很好，需要进行持久化时，主进程会 fork 一个子进程出来，然后把持久化的工作交给子进程，自己不会有相关的 I/O 操作。 比起 AOF，在数据量比较大的情况下，RDB 的启动速度更快。 缺点： RDB 容易造成数据的丢失。假设每 5 分钟保存一次快照，如果 Redis 因为某些原因不能正常工作，那么从上次产生快照到 Redis 出现问题这段时间的数据就会丢失了。 RDB 使用 fork() 产生子进程进行数据的持久化，如果数据比较大的话可能就会花费点时间，造成 Redis 停止服务几毫秒。如果数据量很大且 CPU 性能不是很好的时候，停止服务的时间甚至会到 1 秒。 AOF快照并不是很可靠。如果服务器突然 Crash 了，那么最新的数据就会丢失。而 AOF 文件则提供了一种更为可靠的持久化方式。每当 Redis 接受到会修改数据集的命令时，就会把命令追加到 AOF 文件里，当你重启 Redis 时，AOF 里的命令会被重新执行一次，重建数据。 工作原理 redis 调用 fork ，现在有父子两个进程 子进程根据内存中的数据库快照，往临时文件中写入重建数据库状态的命令 父进程继续处理 client 请求，除了把写命令写入到原来的 aof 文件中。同时把收到的写命令缓存起来。这样就能保证如果子进程重写失败的话并不会出问题 当子进程把快照内容写入已命令方式写到临时文件中后，子进程发信号通知父进程。然后父进程把缓存的写命令也写入到临时文件 现在父进程可以使用临时文件替换老的 aof 文件，并重命名，后面收到的写命令也开始往新的 aof 文件中追加 优缺点优点： 比 RDB 可靠。你可以制定不同的 fsync 策略：不进行 fsync、每秒 fsync 一次和每次查询进行 fsync。默认是每秒 fsync 一次。这意味着你最多丢失一秒钟的数据。 AOF 日志文件是一个纯追加的文件。就算服务器突然 Crash，也不会出现日志的定位或者损坏问题。甚至如果因为某些原因（例如磁盘满了）命令只写了一半到日志文件里，我们也可以用 redis-check-aof 这个工具很简单的进行修复。 当 AOF 文件太大时，Redis会自动在后台进行重写。重写很安全，因为重写是在一个新的文件上进行，同时 Redis 会继续往旧的文件追加数据。新文件上会写入能重建当前数据集的最小操作命令的集合。当新文件重写完，Redis 会把新旧文件进行切换，然后开始把数据写到新文件上。 AOF 把操作命令以简单易懂的格式一条接一条的保存在文件里，很容易导出来用于恢复数据。例如我们不小心用 FLUSHALL 命令把所有数据刷掉了，只要文件没有被重写，我们可以把服务停掉，把最后那条命令删掉，然后重启服务，这样就能把被刷掉的数据恢复回来。 缺点： 在相同的数据集下，AOF 文件的大小一般会比 RDB 文件大。 在某些 fsync 策略下，AOF 的速度会比 RDB 慢。通常 fsync 设置为每秒一次就能获得比较高的性能，而在禁止 fsync 的情况下速度可以达到 RDB 的水平。 在过去曾经发现一些很罕见的 BUG 导致使用 AOF 重建的数据跟原数据不一致的问题。 日志重写随着写操作的不断增加， AOF 文件会越来越大。例如你递增一个计数器 100 次，那么最终结果就是数据集里的计数器的值为最终的递增结果，但是 AOF 文件里却会把这 100 次操作完整的记录下来。而事实上要恢复这个记录，只需要 1 个命令就行了，也就是说 AOF 文件里那 100 条命令其实可以精简为 1 条。所以 Redis 支持这样一个功能：在不中断服务的情况下在后台重建 AOF 文件。 工作原理如下： Redis 调用 fork()，产生一个子进程。 子进程把新的 AOF 写到一个临时文件里。 主进程持续把新的变动写到内存里的 buffer，同时也会把这些新的变动写到旧的 AOF 里，这样即使重写失败也能保证数据的安全。 当子进程完成文件的重写后，主进程会获得一个信号，然后把内存里的 buffer 追加到子进程生成的那个新 AOF 里。 我们可以通过配置设置日志重写的条件： 1234567891011#在日志重写时，不进行命令追加操作，而只是将其放在缓冲区里，避免与命令的追加造成DISK IO上的冲突。#设置为yes表示rewrite期间对新写操作不fsync,暂时存在内存中,等rewrite完成后再写入，默认为no，建议yesno-appendfsync-on-rewrite yes# Redis会记住自从上一次重写后AOF文件的大小（如果自Redis启动后还没重写过，则记住启动时使用的AOF文件的大小）。# 如果当前的文件大小比起记住的那个大小超过指定的百分比，则会触发重写。# 同时需要设置一个文件大小最小值，只有大于这个值文件才会重写，以防文件很小，但是已经达到百分比的情况。 auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb 要禁用自动的日志重写功能，我们可以把百分比设置为0： 1auto-aof-rewrite-percentage 0 数据损坏修复如果因为某些原因（例如服务器崩溃）AOF 文件损坏了，导致 Redis 加载不了，可以通过以下方式进行修复： 备份 AOF 文件。 使用 redis-check-aof 命令修复原始的 AOF 文件： redis-check-aof --fix 可以使用 diff -u 命令看下两个文件的差异。 使用修复过的文件重启 Redis 服务。 从 RDB 切换到 AOF这里只说 Redis &gt;= 2.2 版本的方式： 备份一个最新的 dump.rdb 的文件，并把备份文件放在一个安全的地方。 运行以下两条命令： 12$ redis-cli config set appendonly yes$ redis-cli config set save "" 第二条命令是用来禁用 RDB 的持久化方式，但是这不是必须的，因为你可以同时启用两种持久化方式。 确保数据跟切换前一致。 确保数据正确的写到 AOF 文件里。 总结从上面看出，RDB 和 AOF 操作都是顺序 IO 操作，性能都很高。而同时在通过 RDB 文件或者 AOF 日志进行数据库恢复的时候，也是顺序的读取数据加载到内存中。所以也不会造成磁盘的随机读。 到底选择什么呢？下面是来自官方的建议： 通常，如果你要想提供很高的数据保障性，那么建议你同时使用两种持久化方式。如果你可以接受灾难带来的几分钟的数据丢失，那么你可以仅使用 RDB。很多用户仅使用了 AOF，但是我们建议，既然 RDB 可以时不时的给数据做个完整的快照，并且提供更快的重启，所以最好还是也使用 RDB。 在数据恢复方面：RDB 的启动时间会更短，原因有两个 一是 RDB 文件中每一条数据只有一条记录，不会像 AOF 日志那样可能有一条数据的多次操作记录。所以每条数据只需要写一次就行了。 另一个原因是 RDB 文件的存储格式和 Redis 数据在内存中的编码格式是一致的，不需要再进行数据编码工作，所以在 CPU 消耗上要远小于 AOF 日志的加载。 注意： 上面说了 RDB 快照的持久化，需要注意：在进行快照的时候（save），fork 出来进行 dump 操作的子进程会占用与父进程一样的内存，真正的 copy-on-write ，对性能的影响和内存的耗用都是比较大的。比如机器 8G 内存， Redis 已经使用了 6G 内存，这时 save 的话会再生成 6G，变成 12G，大于系统的 8G。这时候会发生交换；要是虚拟内存不够则会崩溃，导致数据丢失。所以在用 redis 的时候一定对系统内存做好容量规划。 目前，通常的设计思路是利用 Replication 机制来弥补 aof、snapshot 性能上的不足，达到了数据可持久化。即 Master 上 Snapshot 和 AOF 都不做，来保证 Master 的读写性能，而 Slave 上则同时开启 Snapshot 和 AOF 来进行持久化，保证数据的安全性。 主从示例现在开启三个 redis 服务器，分别对应三个不同的端口: 6379、6380、6381； 三台服务器，由 端口 6379 担当主服务器 master， 端口 6380 担当从服务器 slave1， 端口 6381 担当从服务器 slave2; 配置： master 的配置： 关闭 rdb 备份； aof 备份可要可不要；如果打开，则从服务器没有必要开启；如果关闭，把 slave1 的 aof 备份开启； slave1 的配置： 1234567891011# 端口与进程文件设置port 6380pidfile /var/run/redis_6380.pid# 开启 rdb 备份dbfilename dump6380.rdb# 关闭 aof 备份appendonly no# 开启 slaveslaveof localhost 6379# 保持该从服务器只读slave-read-only yes slave2 的配置： 12345678910111213# 端口与进程文件设置port 6381pidfile /var/run/redis_6381.pid# 关闭 rdb 备份#save 900 1#save 300 10#save 60 10000# 关闭 aof 备份appendonly no# 开启 slaveslaveof localhost 6379# 保持该从服务器只读slave-read-only yes FAQ1.如果误操作 flushdb 或 flushall，怎么办？ 答： 通过 aof 恢复：立即执行 shutdown nosave ;将 aof 文件中的和 flush 操作有关的进行删除；然后，重启 Redis 服务器； 2.如何手动修改主从关系？ 答：假设 6379 这个 master 宕机了，这时想设置 6380 这个 slave 主机为 master 主机， 做以下步骤： 1) 使 6380 不继续做 master 主机；（命令：slaveof no one）。修改 readonly 参数为 no；（命令：config set slave-read-only no）2) 其它的 slave 从机再指定新的这台 6380 新 master 主机，命令该 slave 为新 master 主机的 slave；（命令：slaveof [ip] [port]） 附录官方的配置文件例子12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989910010110210310410510610710810911011111211311411511611711811912012112212312412512612712812913013113213313413513613713813914014114214314414514614714814915015115215315415515615715815916016116216316416516616716816917017117217317417517617717817918018118218318418518618718818919019119219319419519619719819920020120220320420520620720820921021121221321421521621721821922022122222322422522622722822923023123223323423523623723823924024124224324424524624724824925025125225325425525625725825926026126226326426526626726826927027127227327427527627727827928028128228328428528628728828929029129229329429529629729829930030130230330430530630730830931031131231331431531631731831932032132232332432532632732832933033133233333433533633733833934034134234334434534634734834935035135235335435535635735835936036136236336436536636736836937037137237337437537637737837938038138238338438538638738838939039139239339439539639739839940040140240340440540640740840941041141241341441541641741841942042142242342442542642742842943043143243343443543643743843944044144244344444544644744844945045145245345445545645745845946046146246346446546646746846947047147247347447547647747847948048148248348448548648748848949049149249349449549649749849950050150250350450550650750850951051151251351451551651751851952052152252352452552652752852953053153253353453553653753853954054154254354454554654754854955055155255355455555655755855956056156256356456556656756856957057157257357457557657757857958058158258358458558658758858959059159259359459559659759859960060160260360460560660760860961061161261361461561661761861962062162262362462562662762862963063163263363463563663763863964064164264364464564664764864965065165265365465565665765865966066166266366466566666766866967067167267367467567667767867968068168268368468568668768868969069169269369469569669769869970070170270370470570670770870971071171271371471571671771871972072172272372472572672772872973073173273373473573673773873974074174274374474574674774874975075175275375475575675775875976076176276376476576676776876977077177277377477577677777877978078178278378478578678778878979079179279379479579679779879980080180280380480580680780880981081181281381481581681781881982082182282382482582682782882983083183283383483583683783883984084184284384484584684784884985085185285385485585685785885986086186286386486586686786886987087187287387487587687787887988088188288388488588688788888989089189289389489589689789889990090190290390490590690790890991091191291391491591691791891992092192292392492592692792892993093193293393493593693793893994094194294394494594694794894995095195295395495595695795895996096196296396496596696796896997097197297397497597697797897998098198298398498598698798898999099199299399499599699799899910001001100210031004100510061007100810091010101110121013101410151016101710181019102010211022102310241025102610271028102910301031103210331034103510361037103810391040104110421043104410451046104710481049105010511052105310541055105610571058105910601061106210631064106510661067106810691070107110721073107410751076107710781079108010811082# Redis configuration file example.## Note that in order to read the configuration file, Redis must be# started with the file path as first argument:## ./redis-server /path/to/redis.conf# Note on units: when memory size is needed, it is possible to specify# it in the usual form of 1k 5GB 4M and so forth (sor forth: 等等):## 1k =&gt; 1000 bytes# 1kb =&gt; 1024 bytes# 1m =&gt; 1000000 bytes# 1mb =&gt; 1024*1024 bytes# 1g =&gt; 1000000000 bytes# 1gb =&gt; 1024*1024*1024 bytes## units are case insensitive (case insensitive: 大小写不敏感) so 1GB 1Gb 1gB are all the same.################################## INCLUDES #################################### Include one or more other config files here. This is useful if you# have a standard template that goes to all Redis servers but also need# to customize a few per-server settings. Include files can include# other files, so use this wisely.## Notice option "include" won't be rewritten by command "CONFIG REWRITE"# from admin or Redis Sentinel（哨兵）. Since Redis always uses the last processed（处理）# line as value of a configuration directive, you'd better put includes# at the beginning of this file to avoid overwriting config change at runtime.## If instead you are interested in using includes to override configuration# options, it is better to use include as the last line.## include /path/to/local.conf# include /path/to/other.conf################################## NETWORK ###################################### By default, if no "bind" configuration directive is specified, Redis listens# for connections from all the network interfaces available on the server.# It is possible to listen to just one or multiple selected interfaces using# the "bind" configuration directive, followed by one or more IP addresses.## Examples:## bind 192.168.1.100 10.0.0.1# bind 127.0.0.1 ::1## ~~~ WARNING ~~~ If the computer running Redis is directly exposed to the# internet, binding to all the interfaces is dangerous and will expose the# instance to everybody on the internet. So by default we uncomment（取消注释）# the following bind directive, that will force Redis to listen only into# the IPv4 lookback interface address (this means Redis will be able to# accept connections only from clients running into the same computer it# is running).## IF YOU ARE SURE YOU WANT YOUR INSTANCE TO LISTEN TO ALL THE INTERFACES# JUST COMMENT THE FOLLOWING LINE.# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~# bind 127.0.0.1# Protected mode is a layer of security protection（security protection： 安全保护）, # in order to avoid that Redis instances left open on the internet # are accessed and exploited.## When protected mode is on and if:## 1) The server is not binding explicitly to （explicitly to: 明确的） a set # of addresses using the "bind" directive.# 2) No password is configured.## The server only accepts connections from clients connecting from the# IPv4 and IPv6 loopback addresses 127.0.0.1 and ::1, and from Unix domain# sockets.## By default protected mode is enabled. You should disable it only if# you are sure you want clients from other hosts to connect to Redis# even if no authentication is configured, nor a specific set of interfaces# are explicitly listed using the "bind" directive.protected-mode no# Accept connections on the specified port, default is 6379 (IANA #815344).# If port 0 is specified Redis will not listen on a TCP socket.port 6379# TCP listen() backlog. （tcp 连接维护队列）## In high requests-per-second environments you need an high backlog in order# to avoid slow clients connections issues. Note that the Linux kernel# will silently truncate it to the value of /proc/sys/net/core/somaxconn so# make sure to raise both the value of somaxconn and tcp_max_syn_backlog# in order to get the desired effect.tcp-backlog 511# Unix socket.## Specify the path for the Unix socket that will be used to listen for# incoming connections. There is no default, so Redis will not listen# on a unix socket when not specified.## unixsocket /tmp/redis.sock# unixsocketperm 700# Close the connection after a client is idle（闲置） for N seconds (0 to disable)timeout 0# TCP keepalive. （定时发送 Ack 检测客户端是否正常）## If non-zero, use SO_KEEPALIVE to send TCP ACKs to clients in absence（缺席）# of communication. This is useful for two reasons:## 1) Detect dead peers （发现无法连接的结点）.# 2) Take the connection alive from the point of view of network# equipment in the middle.## On Linux, the specified value (in seconds) is the period used to send ACKs.# Note that to close the connection the double of the time is needed.# On other kernels the period depends on the kernel configuration.## A reasonable value for this option is 300 seconds, which is the new# Redis default starting with Redis 3.2.1.tcp-keepalive 300################################# GENERAL ###################################### By default Redis does not run as a daemon. Use 'yes' if you need it.# Note that Redis will write a pid file in /var/run/redis.pid when daemonized.daemonize no# If you run Redis from upstart or systemd, Redis can interact with your# supervision tree. Options:# supervised no - no supervision interaction# supervised upstart - signal upstart by putting Redis into SIGSTOP mode# supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET# supervised auto - detect upstart or systemd method based on# UPSTART_JOB or NOTIFY_SOCKET environment variables# Note: these supervision methods only signal "process is ready."# They do not enable continuous liveness pings back to your supervisor.supervised no# If a pid file is specified, Redis writes it where specified at startup# and removes it at exit.## When the server runs non daemonized, no pid file is created if none is# specified in the configuration. When the server is daemonized, the pid file# is used even if not specified, defaulting to "/var/run/redis.pid".## Creating a pid file is best effort: if Redis is not able to create it# nothing bad happens, the server will start and run normally.pidfile /var/run/redis_6379.pid# Specify the server verbosity level.# This can be one of:# debug (a lot of information, useful for development/testing)# verbose (many rarely useful info, but not a mess like the debug level)# notice (moderately verbose, what you want in production probably)# warning (only very important / critical messages are logged)loglevel notice# Specify the log file name. Also the empty string can be used to force# Redis to log on the standard output. Note that if you use standard# output for logging but daemonize, logs will be sent to /dev/nulllogfile ""# 是否开启 syslog 日志# To enable logging to the system logger, just set 'syslog-enabled' to yes,# and optionally update the other syslog parameters to suit your needs.# syslog-enabled no# 指定 syslog 的身份# Specify the syslog identity.# syslog-ident redis# 指定 syslog 的级别# Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7.# syslog-facility local0# 设置数据库的数量# Set the number of databases. The default database is DB 0, you can select# a different one on a per-connection basis using SELECT &lt;dbid&gt; where# dbid is a number between 0 and 'databases'-1databases 16################################ SNAPSHOTTING ################################## Save the DB on disk:## save &lt;seconds&gt; &lt;changes&gt;## Will save the DB if both the given number of seconds and the given# number of write operations against the DB occurred.## In the example below the behaviour will be to save:# after 900 sec (15 min) if at least 1 key changed# after 300 sec (5 min) if at least 10 keys changed# after 60 sec if at least 10000 keys changed## Note: you can disable saving completely by commenting out all "save" lines.## It is also possible to remove all the previously configured save# points by adding a save directive with a single empty string argument# like in the following example:## save ""save 900 1save 300 10save 60 10000# By default Redis will stop accepting writes if RDB snapshots are enabled# (at least one save point) and the latest background save failed.# This will make the user aware (in a hard way) that data is not persisting# on disk properly, otherwise chances are that no one will notice and some# disaster will happen.## If the background saving process will start working again Redis will# automatically allow writes again.## However if you have setup your proper monitoring of the Redis server# and persistence, you may want to disable this feature so that Redis will# continue to work as usual even if there are problems with disk,# permissions, and so forth.stop-writes-on-bgsave-error yes# Compress（压缩） string objects using LZF when dump .rdb databases?# For default that's set to 'yes' as it's almost always a win.# If you want to save（节省） some CPU in the saving child set it to 'no' but# the dataset will likely be bigger if you have compressible（可压缩的） values or keys.rdbcompression yes# rdb 文件较验# Since version 5 of RDB a CRC64 checksum is placed at the end of the file.# This makes the format more resistant to corruption but there is a performance# hit to pay (around 10%) when saving and loading RDB files, so you can disable it# for maximum performances.## RDB files created with checksum disabled have a checksum of zero that will# tell the loading code to skip the check.rdbchecksum yes# The filename where to dump the DBdbfilename dump.rdb# The working directory. （redis 的工作目录）## The DB will be written inside this directory, with the filename specified# above using the 'dbfilename' configuration directive.## The Append Only File will also be created inside this directory.## Note that you must specify a directory here, not a file name.dir ./################################# REPLICATION ################################## Master-Slave replication. Use slaveof to make a Redis instance a copy of# another Redis server. A few things to understand ASAP about Redis replication.## 1) Redis replication is asynchronous（异步）, but you can configure a master to# stop accepting writes if it appears to be not connected with at least# a given number of slaves.# 2) Redis slaves are able to perform a partial（局部的） resynchronization with the# master if the replication link is lost for a relatively small amount of# time. You may want to configure the replication backlog size (see the next# sections of this file) with a sensible value depending on your needs.# 3) Replication is automatic and does not need user intervention. After a# network partition slaves automatically try to reconnect to masters# and resynchronize with them.## slaveof &lt;masterip&gt; &lt;masterport&gt;# If the master is password protected (using the "requirepass" configuration# directive below) it is possible to tell the slave to authenticate before# starting the replication synchronization process, otherwise the master will# refuse the slave request.## masterauth &lt;master-password&gt;# When a slave loses its connection with the master, or when the replication# is still in progress, the slave can act in two different ways:## 1) if slave-serve-stale-data is set to 'yes' (the default) the slave will# still reply to client requests, possibly with out of date data, or the# data set may just be empty if this is the first synchronization.## 2) if slave-serve-stale-data is set to 'no' the slave will reply with# an error "SYNC with master in progress" to all the kind of commands# but to INFO and SLAVEOF.#slave-serve-stale-data yes# You can configure a slave instance to accept writes or not. Writing against# a slave instance may be useful to store some ephemeral data (because data# written on a slave will be easily deleted after resync with the master) but# may also cause problems if clients are writing to it because of a# misconfiguration.## Since Redis 2.6 by default slaves are read-only.### 只读的从redis并不适合直接暴露给不可信的客户端。为了尽量降低风险，可以使用# rename-command 指令来将一些可能有破坏力的命令重命名，避免外部直接调用。比如：## rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52### Note: read only slaves are not designed to be exposed to untrusted（不可信任的） clients# on the internet. It's just a protection layer against misuse of the instance.# Still a read only slave exports by default all the administrative commands# such as CONFIG, DEBUG, and so forth. To a limited extent you can improve# security of read only slaves using 'rename-command' to shadow（隐藏） all the# administrative / dangerous commands.slave-read-only yes# Replication SYNC strategy(策略): disk or socket.## -------------------------------------------------------# WARNING: DISKLESS REPLICATION IS EXPERIMENTAL（试验性的） CURRENTLY# -------------------------------------------------------## New slaves and reconnecting slaves that are not able to continue the replication# process just receiving differences, need to do what is called a "full# synchronization". An RDB file is transmitted from the master to the slaves.# The transmission can happen in two different ways:## 1) Disk-backed: The Redis master creates a new process that writes the RDB# file on disk. Later the file is transferred by the parent# process to the slaves incrementally.# 2) Diskless: The Redis master creates a new process that directly writes the# RDB file to slave sockets, without touching the disk at all.## With disk-backed replication, while the RDB file is generated, more slaves# can be queued and served with the RDB file as soon as the current child producing# the RDB file finishes its work. With diskless replication instead once# the transfer starts, new slaves arriving will be queued and a new transfer# will start when the current one terminates.## When diskless replication is used, the master waits a configurable amount of# time (in seconds) before starting the transfer in the hope that multiple slaves# will arrive and the transfer can be parallelized（平行）.## With slow disks and fast (large bandwidth) networks, diskless replication# works better.repl-diskless-sync no# When diskless replication is enabled, it is possible to configure the delay# the server waits in order to spawn the child that transfers the RDB via socket# to the slaves.## This is important since once the transfer starts, it is not possible to serve# new slaves arriving, that will be queued for the next RDB transfer, so the server# waits a delay in order to let more slaves arrive.## The delay is specified in seconds, and by default is 5 seconds. To disable# it entirely just set it to 0 seconds and the transfer will start ASAP.repl-diskless-sync-delay 5# Slaves send PINGs to server in a predefined（预先确定的） interval（间隔）. # It's possible to change this interval with the repl_ping_slave_period option. # The default value is 10 seconds.## repl-ping-slave-period 10# The following option sets the replication timeout for:## 1) Bulk transfer I/O （Bulk transfer I/O ： 大规模 IO 传输） during SYNC, from the point of view of slave.# 2) Master timeout from the point of view of slaves (data, pings).# 3) Slave timeout from the point of view of masters (REPLCONF ACK pings).## It is important to make sure that this value is greater than the value# specified for repl-ping-slave-period otherwise a timeout will be detected# every time there is low traffic between the master and the slave.## repl-timeout 60# Disable TCP_NODELAY on the slave socket after SYNC?## If you select "yes" Redis will use a smaller number of TCP packets and# less bandwidth（带宽） to send data to slaves. But this can add a delay for# the data to appear on the slave side, up to 40 milliseconds with# Linux kernels using a default configuration.## If you select "no" the delay for data to appear on the slave side will# be reduced but more bandwidth will be used for replication.## By default we optimize for low latency, but in very high traffic conditions# or when the master and slaves are many hops away, turning this to "yes" may# be a good idea.repl-disable-tcp-nodelay no# Set the replication backlog size. The backlog is a buffer that accumulates# slave data when slaves are disconnected for some time, so that when a slave# wants to reconnect again, often a full resync is not needed, but a partial# resync is enough, just passing the portion（部分） of data the slave missed while# disconnected.## The bigger the replication backlog, the longer the time the slave can be# disconnected and later be able to perform a partial resynchronization.## The backlog is only allocated once there is at least a slave connected.## repl-backlog-size 1mb# After a master has no longer connected slaves for some time, the backlog# will be freed（清除）. The following option configures the amount of seconds that# need to elapse（消逝）, starting from the time the last slave disconnected, for# the backlog buffer to be freed.## A value of 0 means to never release the backlog.## repl-backlog-ttl 3600# The slave priority is an integer number published by Redis in the INFO output.# It is used by Redis Sentinel in order to select a slave to promote into a# master if the master is no longer working correctly.## A slave with a low priority number is considered better for promotion, so# for instance if there are three slaves with priority 10, 100, 25 Sentinel will# pick the one with priority 10, that is the lowest.## However a special priority of 0 marks the slave as not able to perform the# role of master, so a slave with priority of 0 will never be selected by# Redis Sentinel for promotion.## By default the priority is 100.slave-priority 100# It is possible for a master to stop accepting writes if there are less than# N slaves connected, having a lag less or equal than M seconds.## The N slaves need to be in "online" state.## The lag（延迟） in seconds, that must be &lt;= the specified value, is calculated from# the last ping received from the slave, that is usually sent every second.## This option does not GUARANTEE that N replicas（复制品） will accept the write, but# will limit the window of exposure（暴露） for lost writes in case not enough slaves# are available, to the specified number of seconds.## For example to require at least 3 slaves with a lag &lt;= 10 seconds use:## min-slaves-to-write 3# min-slaves-max-lag 10## Setting one or the other to 0 disables the feature.## By default min-slaves-to-write is set to 0 (feature disabled) and# min-slaves-max-lag is set to 10.# A Redis master is able to list the address and port of the attached# slaves in different ways. For example the "INFO replication" section# offers this information, which is used, among other tools, by# Redis Sentinel in order to discover slave instances.# Another place where this info is available is in the output of the# "ROLE" command of a masteer.## The listed IP and address normally reported by a slave is obtained# in the following way:## IP: The address is auto detected by checking the peer address# of the socket used by the slave to connect with the master.## Port: The port is communicated by the slave during the replication# handshake, and is normally the port that the slave is using to# list for connections.## However when port forwarding or Network Address Translation (NAT) is# used, the slave may be actually reachable via different IP and port# pairs. The following two options can be used by a slave in order to# report to its master a specific set of IP and port, so that both INFO# and ROLE will report those values.## There is no need to use both the options if you need to override just# the port or the IP address.## slave-announce-ip 5.5.5.5# slave-announce-port 1234################################## SECURITY #################################### Require clients to issue AUTH &lt;PASSWORD&gt; before processing any other# commands. This might be useful in environments in which you do not trust# others with access to the host running redis-server.## This should stay commented out for backward compatibility and because most# people do not need auth (e.g. they run their own servers).## Warning: since Redis is pretty fast an outside user can try up to# 150k passwords per second against a good box. This means that you should# use a very strong password otherwise it will be very easy to break.## requirepass foobared# Command renaming.## It is possible to change the name of dangerous commands in a shared# environment. For instance the CONFIG command may be renamed into something# hard to guess so that it will still be available for internal-use tools# but not available for general clients.## Example:## rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52## It is also possible to completely kill a command by renaming it into# an empty string:## rename-command CONFIG ""## Please note that changing the name of commands that are logged into the# AOF file or transmitted to slaves may cause problems.################################### LIMITS ##################################### Set the max number of connected clients at the same time. By default# this limit is set to 10000 clients, however if the Redis server is not# able to configure the process file limit to allow for the specified limit# the max number of allowed clients is set to the current file limit# minus（减去） 32 (as Redis reserves（保留） a few file descriptors for internal uses).## Once the limit is reached Redis will close all the new connections sending# an error 'max number of clients reached'.## maxclients 10000# Don't use more memory than the specified amount of bytes.# When the memory limit is reached Redis will try to remove keys# according to the eviction policy selected (see maxmemory-policy).## If Redis can't remove keys according to the policy, or if the policy is# set to 'noeviction', Redis will start to reply with errors to commands# that would use more memory, like SET, LPUSH, and so on, and will continue# to reply to read-only commands like GET.## This option is usually useful when using Redis as an LRU cache, or to set# a hard memory limit for an instance (using the 'noeviction' policy).## WARNING: If you have slaves attached to an instance with maxmemory on,# the size of the output buffers needed to feed the slaves are subtracted# from the used memory count, so that network problems / resyncs will# not trigger a loop where keys are evicted, and in turn the output# buffer of slaves is full with DELs of keys evicted triggering the deletion# of more keys, and so forth until the database is completely emptied（清空）.## In short... if you have slaves attached it is suggested that you set a lower# limit for maxmemory so that there is some free RAM on the system for slave# output buffers (but this is not needed if the policy is 'noeviction（不移除）').## maxmemory &lt;bytes&gt;# MAXMEMORY POLICY: how Redis will select what to remove when maxmemory# is reached. You can select among five behaviors:## volatile-lru -&gt; remove the key with an expire set using an LRU algorithm 使用LRU算法移除过期集合中的key# allkeys-lru -&gt; remove any key according to the LRU algorithm 使用LRU算法移除key# volatile-random -&gt; remove a random key with an expire set 在过期集合中移除随机的key# allkeys-random -&gt; remove a random key, any key 移除随机的key# volatile-ttl -&gt; remove the key with the nearest expire time (minor TTL) 移除那些TTL值最小的key，即那些最近才过期的key。# noeviction -&gt; don't expire at all, just return an error on write operations 不进行移除。针对写操作，只是返回错误信息。## Note: with any of the above policies, Redis will return an error on write# operations, when there are no suitable keys for eviction.## At the date of writing these commands are: set setnx setex append# incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd# sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby# zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby# getset mset msetnx exec sort## The default is:## maxmemory-policy noeviction# LRU and minimal TTL algorithms are not precise（精确的） algorithms but approximated（估计的）# algorithms (in order to save memory), so you can tune it for speed or# accuracy. For default Redis will check five keys and pick the one that was# used less recently, you can change the sample size using the following# configuration directive.## The default of 5 produces good enough results. 10 Approximates very closely# true LRU but costs a bit more CPU. 3 is very fast but not very accurate.## maxmemory-samples 5############################## APPEND ONLY MODE ################################ By default Redis asynchronously（异步） dumps the dataset on disk. This mode is# good enough in many applications, but an issue with the Redis process or# a power outage（a power outage：停电） may result into a few minutes of writes lost (depending on# the configured save points).## The Append Only File is an alternative persistence mode that provides# much better durability（耐用性）. For instance using the default data fsync policy# (see later in the config file) Redis can lose just one second of writes in a# dramatic event like a server power outage, or a single write if something# wrong with the Redis process itself happens, but the operating system is# still running correctly.## AOF and RDB persistence can be enabled at the same time without problems.# If the AOF is enabled on startup Redis will load the AOF, that is the file# with the better durability guarantees（保证）.## Please check http://redis.io/topics/persistence for more information.appendonly no# The name of the append only file (default: "appendonly.aof")appendfilename "appendonly.aof"# The fsync() call tells the Operating System to actually write data on disk# instead of waiting for more data in the output buffer. Some OS will really flush# data on disk, some other OS will just try to do it ASAP（ASAP： 尽快）.## Redis supports three different modes:## no: don't fsync, just let the OS flush the data when it wants. Faster.# always: fsync after every write to the append only log. Slow, Safest.# everysec: fsync only one time every second. Compromise（妥协）.## The default is "everysec", as that's usually the right compromise between# speed and data safety. It's up to you to understand if you can relax this to# "no" that will let the operating system flush the output buffer when# it wants, for better performances (but if you can live with（live with: 容忍） the idea of# some data loss consider the default persistence mode that's snapshotting),# or on the contrary（on the contrary：正相反）, use "always" that's very slow but a bit safer than# everysec.## More details please check the following article:# http://antirez.com/post/redis-persistence-demystified.html## If unsure, use "everysec".# appendfsync alwaysappendfsync everysec# appendfsync no# 在日志重写时，不进行命令追加操作，而只是将其放在缓冲区里，避免与命令的追加造成 DISK IO 上的冲突。# 设置为 yes 表示 rewrite 期间对新写操作不 fsync, 暂时存在内存中,等 rewrite 完成后再写入## When the AOF fsync policy is set to always or everysec, and a background# saving process (a background save or AOF log background rewriting) is# performing a lot of I/O against the disk, in some Linux configurations# Redis may block too long on the fsync() call. Note that there is no fix for# this currently, as even performing fsync in a different thread will block# our synchronous write(2) call.## In order to mitigate（减轻） this problem it's possible to use the following option# that will prevent（防止） fsync() from being called in the main process while a# BGSAVE or BGREWRITEAOF is in progress.## This means that while another child is saving, the durability of Redis is# the same as "appendfsync none". In practical terms, this means that it is# possible to lose up to 30 seconds of log in the worst scenario (with the# default Linux settings).## If you have latency（潜在） problems turn this to "yes". Otherwise leave it as# "no" that is the safest pick from the point of view of durability.no-appendfsync-on-rewrite no# Automatic rewrite of the append only file.# Redis is able to automatically rewrite the log file implicitly（含蓄地） calling# BGREWRITEAOF when the AOF log size grows by the specified percentage.## This is how it works: Redis remembers the size of the AOF file after the# latest rewrite (if no rewrite has happened since the restart, the size of# the AOF at startup is used).## This base size is compared to the current size. If the current size is# bigger than the specified percentage, the rewrite is triggered. Also# you need to specify a minimal size for the AOF file to be rewritten, this# is useful to avoid rewriting the AOF file even if the percentage increase# is reached but it is still pretty small.## Specify a percentage of zero in order to disable the automatic AOF# rewrite feature.auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb# An AOF file may be found to be truncated（截断） at the end during the Redis# startup process, when the AOF data gets loaded back into memory.# This may happen when the system where Redis is running# crashes（崩溃）, especially when an ext4 filesystem is mounted without the# data=ordered option (however this can't happen when Redis itself# crashes or aborts but the operating system still works correctly).## Redis can either exit with an error when this happens, or load as much# data as possible (the default now) and start if the AOF file is found# to be truncated at the end. The following option controls this behavior.## If aof-load-truncated is set to yes, a truncated AOF file is loaded and# the Redis server starts emitting a log to inform the user of the event.# Otherwise if the option is set to no, the server aborts with an error# and refuses to start. When the option is set to no, the user requires# to fix the AOF file using the "redis-check-aof" utility before to restart# the server.## Note that if the AOF file will be found to be corrupted in the middle# the server will still exit with an error. This option only applies when# Redis will try to read more data from the AOF file but not enough bytes# will be found.aof-load-truncated yes################################ LUA SCRIPTING ################################ Max execution time of a Lua script in milliseconds.# lua脚本的最大运行时间是需要被严格限制的，要注意单位是毫秒## If the maximum execution time is reached Redis will log that a script is# still in execution after the maximum allowed time and will start to# reply to queries with an error.## When a long running script exceeds the maximum execution time only the# SCRIPT KILL and SHUTDOWN NOSAVE commands are available. The first can be# used to stop a script that did not yet called write commands. The second# is the only way to shut down the server in the case a write command was# already issued by the script but the user doesn't want to wait for the natural# termination of the script.## Set it to 0 or a negative value for unlimited execution without warnings.lua-time-limit 5000################################ REDIS CLUSTER ################################# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++# WARNING EXPERIMENTAL: Redis Cluster is considered to be stable code, however# in order to mark it as "mature" we need to wait for a non trivial percentage# of users to deploy it in production.# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++## 如果配置yes则开启集群功能，此redis实例作为集群的一个节点，否则，它是一个普通的单一的redis实例。# Normal Redis instances can't be part of a Redis Cluster; only nodes that are# started as cluster nodes can. In order to start a Redis instance as a# cluster node enable the cluster support uncommenting the following:## cluster-enabled yes# 虽然此配置的名字叫"集群配置文件"，但是此配置文件不能人工编辑，它是集群节点自动维护的文件，# 主要用于记录集群中有哪些节点、他们的状态以及一些持久化参数等，方便在重启时恢复这些状态。# 通常是在收到请求之后这个文件就会被更新。# Every cluster node has a cluster configuration file. This file is not# intended to be edited by hand. It is created and updated by Redis nodes.# Every Redis Cluster node requires a different cluster configuration file.# Make sure that instances running in the same system do not have# overlapping cluster configuration file names.## cluster-config-file nodes-6379.conf# 这是集群中的节点能够失联的最大时间，超过这个时间，该节点就会被认为故障。# 如果主节点超过这个时间还是不可达，则用它的从节点将启动故障迁移，升级成主节点。# 注意，任何一个节点在这个时间之内如果还是没有连上大部分的主节点，则此节点将停止接收任何请求。一般设置为15秒即可。# Cluster node timeout is the amount of milliseconds a node must be unreachable# for it to be considered in failure state.# Most other internal time limits are multiple of the node timeout.## cluster-node-timeout 15000# A slave of a failing master will avoid to start a failover if its data# looks too old.## There is no simple way for a slave to actually have a exact measure of# its "data age", so the following two checks are performed:## 1) If there are multiple slaves able to failover, they exchange messages# in order to try to give an advantage to the slave with the best# replication offset (more data from the master processed).# Slaves will try to get their rank by offset, and apply to the start# of the failover a delay proportional to their rank.## 2) Every single slave computes the time of the last interaction with# its master. This can be the last ping or command received (if the master# is still in the "connected" state), or the time that elapsed since the# disconnection with the master (if the replication link is currently down).# If the last interaction is too old, the slave will not try to failover# at all.## The point "2" can be tuned by user. Specifically a slave will not perform# the failover if, since the last interaction with the master, the time# elapsed is greater than:## (node-timeout * slave-validity-factor) + repl-ping-slave-period## So for example if node-timeout is 30 seconds, and the slave-validity-factor# is 10, and assuming a default repl-ping-slave-period of 10 seconds, the# slave will not try to failover if it was not able to talk with the master# for longer than 310 seconds.## A large slave-validity-factor may allow slaves with too old data to failover# a master, while a too small value may prevent the cluster from being able to# elect a slave at all.## For maximum availability, it is possible to set the slave-validity-factor# to a value of 0, which means, that slaves will always try to failover the# master regardless of the last time they interacted with the master.# (However they'll always try to apply a delay proportional to their# offset rank).## Zero is the only value able to guarantee that when all the partitions heal# the cluster will always be able to continue.## cluster-slave-validity-factor 10# 一个master可以拥有的最小slave数量。该项的作用是，当一个master没有任何slave的时候，# 某些有富余slave的master节点，可以自动的分一个slave给它。# Cluster slaves are able to migrate to orphaned（孤儿） masters, that are masters# that are left without working slaves. This improves the cluster ability# to resist to failures as otherwise an orphaned master can't be failed over# in case of failure if it has no working slaves.## Slaves migrate to orphaned masters only if there are still at least a# given number of other working slaves for their old master. This number# is the "migration barrier". A migration barrier of 1 means that a slave# will migrate only if there is at least 1 other working slave for its master# and so forth. It usually reflects the number of slaves you want for every# master in your cluster.## Default is 1 (slaves migrate only if their masters remain with at least# one slave). To disable migration just set it to a very large value.# A value of 0 can be set but is useful only for debugging and dangerous# in production.## cluster-migration-barrier 1# 如果该项设置为yes（默认就是yes） 当一定比例的键空间没有被覆盖到# （就是某一部分的哈希槽没了，有可能是暂时挂了）集群就停止处理任何查询炒作。# 如果该项设置为no，那么就算请求中只有一部分的键可以被查到，一样可以查询（但是有可能会查不全）# By default Redis Cluster nodes stop accepting queries if they detect there# is at least an hash slot uncovered (no available node is serving it).# This way if the cluster is partially down (for example a range of hash slots# are no longer covered) all the cluster becomes, eventually, unavailable.# It automatically returns available as soon as all the slots are covered again.## However sometimes you want the subset of the cluster which is working,# to continue to accept queries for the part of the key space that is still# covered. In order to do so, just set the cluster-require-full-coverage# option to no.## cluster-require-full-coverage yes# In order to setup your cluster make sure to read the documentation# available at http://redis.io web site.################################## SLOW LOG #################################### The Redis Slow Log is a system to log queries that exceeded a specified# execution time. The execution time does not include the I/O operations# like talking with the client, sending the reply and so forth,# but just the time needed to actually execute the command (this is the only# stage of command execution where the thread is blocked and can not serve# other requests in the meantime).## You can configure the slow log with two parameters: one tells Redis# what is the execution time, in microseconds, to exceed in order for the# command to get logged, and the other parameter is the length of the# slow log. When a new command is logged the oldest one is removed from the# queue of logged commands.# The following time is expressed in microseconds, so 1000000 is equivalent# to one second. Note that a negative number disables the slow log, while# a value of zero forces the logging of every command.slowlog-log-slower-than 10000# There is no limit to this length. Just be aware that it will consume memory.# You can reclaim memory used by the slow log with SLOWLOG RESET.slowlog-max-len 128################################ LATENCY MONITOR ############################### The Redis latency monitoring(latency monitoring: 延迟监控) subsystem samples different operations# at runtime in order to collect data related to possible sources of# latency of a Redis instance.## Via the LATENCY command this information is available to the user that can# print graphs and obtain reports.## The system only logs operations that were performed in a time equal or# greater than the amount of milliseconds specified via the# latency-monitor-threshold configuration directive. When its value is set# to zero, the latency monitor is turned off.## By default latency monitoring is disabled since it is mostly not needed# if you don't have latency issues, and collecting data has a performance# impact, that while very small, can be measured under big load. Latency# monitoring can easily be enabled at runtime using the command# "CONFIG SET latency-monitor-threshold &lt;milliseconds&gt;" if needed.latency-monitor-threshold 0############################# EVENT NOTIFICATION ############################### Redis can notify Pub/Sub clients about events happening in the key space.# This feature is documented at http://redis.io/topics/notifications## For instance if keyspace events notification is enabled, and a client# performs a DEL operation on key "foo" stored in the Database 0, two# messages will be published via Pub/Sub:## PUBLISH __keyspace@0__:foo del# PUBLISH __keyevent@0__:del foo## It is possible to select the events that Redis will notify among a set# of classes. Every class is identified by a single character:## K Keyspace events, published with __keyspace@&lt;db&gt;__ prefix.# E Keyevent events, published with __keyevent@&lt;db&gt;__ prefix.# g Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...# $ String commands# l List commands# s Set commands# h Hash commands# z Sorted set commands# x Expired events (events generated every time a key expires)# e Evicted events (events generated when a key is evicted for maxmemory)# A Alias for g$lshzxe, so that the "AKE" string means all the events.## The "notify-keyspace-events" takes as argument a string that is composed# of zero or multiple characters. The empty string means that notifications# are disabled.## Example: to enable list and generic events, from the point of view of the# event name, use:## notify-keyspace-events Elg## Example 2: to get the stream of the expired keys subscribing to channel# name __keyevent@0__:expired use:## notify-keyspace-events Ex## By default all notifications are disabled because most users don't need# this feature and the feature has some overhead. Note that if you don't# specify at least one of K or E, no events will be delivered.notify-keyspace-events ""############################### ADVANCED CONFIG ################################ Hashes are encoded using a memory efficient data structure when they have a# small number of entries, and the biggest entry does not exceed a given# threshold. These thresholds can be configured using the following directives.hash-max-ziplist-entries 512hash-max-ziplist-value 64# Lists are also encoded in a special way to save a lot of space.# The number of entries allowed per internal list node can be specified# as a fixed maximum size or a maximum number of elements.# For a fixed maximum size, use -5 through -1, meaning:# -5: max size: 64 Kb &lt;-- not recommended for normal workloads# -4: max size: 32 Kb &lt;-- not recommended# -3: max size: 16 Kb &lt;-- probably not recommended# -2: max size: 8 Kb &lt;-- good# -1: max size: 4 Kb &lt;-- good# Positive numbers mean store up to _exactly_ that number of elements# per list node.# The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size),# but if your use case is unique, adjust the settings as necessary.list-max-ziplist-size -2# Lists may also be compressed.# Compress depth is the number of quicklist ziplist nodes from *each* side of# the list to *exclude* from compression. The head and tail of the list# are always uncompressed for fast push/pop operations. Settings are:# 0: disable all list compression# 1: depth 1 means "don't start compressing until after 1 node into the list,# going from either the head or tail"# So: [head]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[tail]# [head], [tail] will always be uncompressed; inner nodes will compress.# 2: [head]-&gt;[next]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[prev]-&gt;[tail]# 2 here means: don't compress head or head-&gt;next or tail-&gt;prev or tail,# but compress all nodes between them.# 3: [head]-&gt;[next]-&gt;[next]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[prev]-&gt;[prev]-&gt;[tail]# etc.list-compress-depth 0# Sets have a special encoding in just one case: when a set is composed# of just strings that happen to be integers in radix 10 in the range# of 64 bit signed integers.# The following configuration setting sets the limit in the size of the# set in order to use this special memory saving encoding.set-max-intset-entries 512# Similarly to hashes and lists, sorted sets are also specially encoded in# order to save a lot of space. This encoding is only used when the length and# elements of a sorted set are below the following limits:zset-max-ziplist-entries 128zset-max-ziplist-value 64# HyperLogLog sparse representation bytes limit. The limit includes the# 16 bytes header. When an HyperLogLog using the sparse representation crosses# this limit, it is converted into the dense representation.## A value greater than 16000 is totally useless, since at that point the# dense representation is more memory efficient.## The suggested value is ~ 3000 in order to have the benefits of# the space efficient encoding without slowing down too much PFADD,# which is O(N) with the sparse encoding. The value can be raised to# ~ 10000 when CPU is not a concern, but space is, and the data set is# composed of many HyperLogLogs with cardinality in the 0 - 15000 range.hll-sparse-max-bytes 3000# Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in# order to help rehashing the main Redis hash table (the one mapping top-level# keys to values). The hash table implementation Redis uses (see dict.c)# performs a lazy rehashing: the more operation you run into a hash table# that is rehashing, the more rehashing "steps" are performed, so if the# server is idle the rehashing is never complete and some more memory is used# by the hash table.## The default is to use this millisecond 10 times every second in order to# actively rehash the main dictionaries, freeing memory when possible.## If unsure:# use "activerehashing no" if you have hard latency requirements and it is# not a good thing in your environment that Redis can reply from time to time# to queries with 2 milliseconds delay.## use "activerehashing yes" if you don't have such hard requirements but# want to free memory asap when possible.activerehashing yes# The client output buffer limits can be used to force disconnection of clients# that are not reading data from the server fast enough for some reason (a# common reason is that a Pub/Sub client can't consume messages as fast as the# publisher can produce them).## The limit can be set differently for the three different classes of clients:## normal -&gt; normal clients including MONITOR clients# slave -&gt; slave clients# pubsub -&gt; clients subscribed to at least one pubsub channel or pattern## The syntax of every client-output-buffer-limit directive is the following:## client-output-buffer-limit &lt;class&gt; &lt;hard limit&gt; &lt;soft limit&gt; &lt;soft seconds&gt;## A client is immediately disconnected once the hard limit is reached, or if# the soft limit is reached and remains reached for the specified number of# seconds (continuously).# So for instance if the hard limit is 32 megabytes and the soft limit is# 16 megabytes / 10 seconds, the client will get disconnected immediately# if the size of the output buffers reach 32 megabytes, but will also get# disconnected if the client reaches 16 megabytes and continuously overcomes# the limit for 10 seconds.## By default normal clients are not limited because they don't receive data# without asking (in a push way), but just after a request, so only# asynchronous clients may create a scenario where data is requested faster# than it can read.## Instead there is a default limit for pubsub and slave clients, since# subscribers and slaves receive data in a push fashion.## Both the hard or the soft limit can be disabled by setting them to zero.client-output-buffer-limit normal 0 0 0client-output-buffer-limit slave 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60# Redis calls an internal function to perform many background tasks, like# closing connections of clients in timeout, purging expired keys that are# never requested, and so forth.## Not all tasks are performed with the same frequency, but Redis checks for# tasks to perform according to the specified "hz" value.## By default "hz" is set to 10. Raising the value will use more CPU when# Redis is idle, but at the same time will make Redis more responsive when# there are many keys expiring at the same time, and timeouts may be# handled with more precision.## The range is between 1 and 500, however a value over 100 is usually not# a good idea. Most users should use the default of 10 and raise this up to# 100 only in environments where very low latency is required.hz 10# When a child rewrites the AOF file, if the following option is enabled# the file will be fsync-ed every 32 MB of data generated. This is useful# in order to commit the file to the disk more incrementally and avoid# big latency spikes.aof-rewrite-incremental-fsync yes]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jquery 文本自动补全插件 Bootstrap-Typehead]]></title>
    <url>%2F2018%2F01%2F12%2Fjquery-plugin-bootstrap-typehead%2F</url>
    <content type="text"><![CDATA[github 仓库地址： https://github.com/tcrosen/twitter-bootstrap-typeahead 介绍文本输入框，根据已经键入的文本，模糊搜索，给出自动补全提示。 FAQ光标聚焦，自动弹出123456789101112131415$(function () &#123; // 指定文本输入框 初始化 自动补全 var typeahead_ele = $('input[name="xx"]').typeahead(&#123;..option..&#125;); // 光标聚焦注册事件 $('input[name="xx"]').focus(function() &#123; var typeahead = typeahead_ele.data('typeahead'); typeahead.query = ''; typeahead.ajaxExecute(''); &#125;); // 光标聚焦 $('input[name="xx"]')[0].focus();&#125;);]]></content>
      <tags>
        <tag>Jquery-Plugin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vscode 日常操作]]></title>
    <url>%2F2018%2F01%2F11%2Fvscode-operate%2F</url>
    <content type="text"><![CDATA[PythonPython 文件首行编码1# -*- coding: UTF-8 -*- 安装自动格式化代码在命令行上键入:1python -m pip install yapf VSCode “自动格式化代码”的快捷键是“Alt + Shift + F”。 安装静态代码检查工具 Flake8在命令行上键入:1python -m pip install flake8 插件Ctrl + Shift + x 打开扩展页面； 文件图标主题: vscode-icons激活位置: 文件 - 首选项 - 文件图标主题 缩进线插件: Guides 快捷键打开 按键 描述 Ctrl+K + Ctrl+S 打开快捷键面板 Ctrl+K + Ctrl+O 打开文件夹 屏幕移动 按键 描述 Home / End 转到 行首 / 行尾 Ctrl+Home / Ctrl+End 转到 文件开始 / 文件末尾 Alt+PgUp / Alt+PgDown 向 上/下 滚动页面 光标移动 按键 描述 UpArrow / DownArrow / LeftArrow / RightArrow 向 上/下/左/右 移动 Ctrl+Shift+\ 跳到匹配的括号 多光标和选择 按键 描述 Ctrl+F2 选择当前字的所有出现 Ctrl+Shift+L 选择当前选择的所有出现 Shift+Alt+（拖动鼠标） 列（框）选择 Ctrl+Shift+Alt+（箭头键） 列（框）选择 行移动 按键 描述 Alt+UpArrow / Alt+DownArrow 向 上/下 移动行 Shift+Alt+UpArrow / Shift+Alt+DownArrow 向 上/下 复制行 Ctrl+Enter / Ctrl+Shift+Enter 在下面/上面 插入行 Ctrl+Shift+K 删除行 展开折叠 按键 描述 Ctrl+K + Ctrl+[ / Ctrl+K + Ctrl+] 局部折叠/展开 Ctrl+K + Ctrl+0 / Ctrl+K + Ctrl+J 全部折叠/展开 注释 按键 描述 Ctrl+/ 切换行注释 Ctrl+K + Ctrl+C / Ctrl+K + Ctrl+U 选中区域 添加/删除 行注释符号 Shift+Alt+A 切换块注释 搜索与替换 按键 描述 Ctrl+F 查找 Ctrl+H 替换 F3 / Shift+F3 查找 下一个/上一个 复制 粘贴 撤销 按键 描述 Ctrl+C / Ctrl+X 复制 / 剪切 Ctrl+V 粘贴 Ctrl+Z / Ctrl+Shift+Z 撤销 / 反撤销 格式化 按键 描述 Shift+Alt+F 格式化文档 Ctrl+K + Ctrl+F 格式化选定区域 Ctrl+K + Ctrl+X 修剪尾随空格 引用 按键 描述 F12 转到定义 Shift+F12 显示引用 调试 按键 描述 Ctrl+Shift+D 显示调试 FAQ系统上禁止运行脚本执行命令1set-executionpolicy remotesigned 详细阅读参考PowerShell因为在此系统中禁止执行脚本解决方法]]></content>
      <categories>
        <category>Develop Tool</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[算法之图搜索]]></title>
    <url>%2F2018%2F01%2F11%2Farithmetic-bfs-dfs%2F</url>
    <content type="text"><![CDATA[图是一种灵活的数据结构，一般作为一种模型用来定义对象之间的关系或联系。对象由顶点（V）表示，而对象之间的关系或者关联则通过图的边（E）来表示。图可以分为有向图和无向图，一般用 G=(V,E) 来表示图。经常用邻接矩阵或者邻接表来描述一副图。在图的基本算法中，最初需要接触的就是图的遍历算法，根据访问节点的顺序，可分为广度优先搜索（BFS）和深度优先搜索（DFS）。 深度优先算法深度优先搜索在搜索过程中访问某个顶点后，需要递归地访问此顶点的所有未访问过的相邻顶点。 N 皇后问题实例，以 Leetcode 51题 题目， 在 N * N的棋盘上摆放 N 个皇后，使得任意两个皇后都不能处于同一行、同一列或同一斜线上； 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# -*- coding: UTF-8 -*-class Solution(object): def solveNQueens(self, n): """ 算法的入口 :type n: int :rtype: List[List[str]] """ # 存放最后的可能性结果，每一个元素都是一个结果，每一个结果都是一个列表 self.answer = [] # 保存每一列皇后所在的行号, 此处进行初始化 self.path = [] for index in range(n): self.path.append(-1) self.dns(0, n) return self.answer def dns(self, col, n): """ 深度优先遍历算法 : col: 当前列 ： n: 总列 """ # 超过边界，记录这个结果 if col &gt;= n: # 遍历整个棋盘并输出 result_record = [] for i in range(n): row_record = [] for j in range(n): # 如果该行该列是皇后，标记为 Q if self.path[i] == j: row_record.append('Q') else: row_record.append('.') result_record.append("".join(row_record)) self.answer.append(result_record) return for row in range(n): # 对于当前列，每一行都是可能性 if self.__check(row, col, n): self.path[col] = row self.dns(col + 1, n) # 复原 self.path[col] = -1 def __check(self, row, col, n): """ 私有方法：检查当前行与列是否有 行冲突及斜线冲突 : row: 行 : col: 列 """ # 和前 col - 1 列存在的数据作比较 for search_col in range(col): if self.path[search_col] == row or abs(self.path[search_col] - row) == abs(search_col - col): return False return True 广度优先算法广度优先遍历是连通图的一种遍历策略。因为它的思想是从一个顶点 V0 开始，辐射状地优先遍历其周围较广的区域，故得名。 岛的数量实例，以 Leetcode 200题 题目， 在一个 2 维数组中， 1 表示岛，0 表示水，求被水环绕的岛的数量； 123411110110101100000000 上面的例子中，被水（0） 环绕的岛（1）的整体只有 1 个，所以结果就是 1 啦； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# -*- coding: UTF-8 -*-class Solution(object): def numIslands(self, grid): """ 算法的入口 :type grid: List[List[str]] :rtype: int """ # 如果二维数组中有一维不存在，则返回 0 if len(grid) == 0 or len(grid[0]) == 0: return 0 lands_num = 0 # 遍历是岛的点，将其周围的岛全部挖掉，则一个整体确定消失,也叫 洪水填充法 for row in range(len(grid)): for col in range(len(grid[row])): if grid[row][col] == '1': self.__flood_fill(row, col, grid) lands_num += 1 return lands_num def __flood_fill(self, row, col, grid): """ 处理 grid 二维数组中处于 row 行 col 列的岛周围连结的岛 """ # 队列，存放与当前 row 行 col 列的岛周围连结的岛 connect_land = [[row, col]] while len(connect_land) != 0: # 对队列的头结点上下左右的岛 处理 current_land = connect_land[0] grid[current_land[0]][current_land[1]] = '0' self.__deal(current_land[0] + 1, current_land[1], connect_land, grid) self.__deal(current_land[0] - 1, current_land[1], connect_land, grid) self.__deal(current_land[0], current_land[1] - 1, connect_land, grid) self.__deal(current_land[0], current_land[1] + 1, connect_land, grid) # 移出队列头结点 del connect_land[0] def __deal(self, row, col, connect_land, grid): """ 对于 grid 二维数组中处于 row 行 col 列的岛进行判断，如果也是岛，则加入到待处理的队列中 """ total_rows = len(grid) total_cols = len(grid[0]) if row &gt;= 0 and row &lt; total_rows and col &gt;= 0 and col &lt; total_cols and grid[row][col] == '1': grid[row][col] = '0' connect_land.append([row, col])]]></content>
      <categories>
        <category>Arithmetic</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ThinkPHP 框架搭建]]></title>
    <url>%2F2018%2F01%2F10%2Fthinkphp-init%2F</url>
    <content type="text"><![CDATA[本地部署及运行严格来说，ThinkPHP 无需安装过程，这里所说的安装其实就是把 ThinkPHP 框架放入 WEB 运行环境； 所以只要将代码下载到本地，并配置服务器即可； 笔者此处采用 Composer 安装； 12# tp5 即项目文件夹名称composer create-project topthink/think=5.0.* tp5 --prefer-dist 在 Nginx 上配置： 1234567891011121314151617181920212223242526272829303132333435363738server &#123; listen 9052; server_name localhost; proxy_buffer_size 128k; proxy_buffers 8 256k; proxy_busy_buffers_size 256k; set $root_path '/opt/tp5-cms'; root $root_path; index index.php index.html index.htm; location / &#123; if (!-e $request_filename) &#123; rewrite ^/(.*)$ /index.php/$1 last; break; &#125; &#125; location ~ \.php &#123; fastcgi_pass unix:/opt/bksite/php/var/run/www.sock; fastcgi_split_path_info ^(.+\.php)(/.*)$; include fastcgi_params; fastcgi_param SCRIPT_FILENAME $root_path$fastcgi_script_name; fastcgi_param DOCUMENT_ROOT $root_path; fastcgi_param SCRIPT_NAME $fastcgi_script_name; fastcgi_param PATH_INFO $fastcgi_path_info; &#125; location ~ (css|img|js|flv|swf|download)/(.+)$ &#123; root $root_path; &#125; location ~ /\.ht &#123; deny all; &#125;&#125; 成功页面如下： 目录结构最初的目录结构如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546project 应用部署目录├─application 应用目录（可设置） │ ├─common 公共模块目录（可更改）│ ├─index 模块目录(可更改) │ │ ├─config.php 模块配置文件 │ │ ├─common.php 模块函数文件 │ │ ├─controller 控制器目录 │ │ ├─model 模型目录 │ │ ├─view 视图目录 │ │ └─ ... 更多类库目录 │ ├─command.php 命令行工具配置文件 │ ├─common.php 应用公共（函数）文件 │ ├─config.php 应用（公共）配置文件 │ ├─database.php 数据库配置文件 │ ├─tags.php 应用行为扩展定义文件 │ └─route.php 路由配置文件 ├─extend 扩展类库目录（可定义） ├─public WEB 部署目录（对外访问目录）│ ├─static 静态资源存放目录(css,js,image) │ ├─index.php 应用入口文件 │ ├─router.php 快速测试文件 │ └─.htaccess 用于 apache 的重写 ├─runtime 应用的运行时目录（可写，可设置） ├─vendor 第三方类库目录（Composer） ├─thinkphp 框架系统目录 │ ├─lang 语言包目录 │ ├─library 框架核心类库目录 │ │ ├─think Think 类库包目录 │ │ └─traits 系统 Traits 目录 │ ├─tpl 系统模板目录 │ ├─.htaccess 用于 apache 的重写 │ ├─.travis.yml CI 定义文件 │ ├─base.php 基础定义文件 │ ├─composer.json composer 定义文件 │ ├─console.php 控制台入口文件 │ ├─convention.php 惯例配置文件 │ ├─helper.php 助手函数文件（可选） │ ├─LICENSE.txt 授权说明文件 │ ├─phpunit.xml 单元测试配置文件 │ ├─README.md README 文件 │ └─start.php 框架引导文件 ├─build.php 自动生成定义文件（参考） ├─composer.json composer 定义文件 ├─LICENSE.txt 授权说明文件 ├─README.md README 文件 ├─think 命令行入口文件]]></content>
      <tags>
        <tag>ThinkPHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP 框架之争]]></title>
    <url>%2F2018%2F01%2F10%2Fphp-framework%2F</url>
    <content type="text"><![CDATA[CodeIgniter优点： 轻量简便 （2018.1.10） 开发文档很全面 （2018.1.10） 缺点： 官方不再支持维护，目前由社区、github 上有大牛维护，进展很慢； （2018.1.10） 默认是不开启命名空间支持，通过配置也可以支持，但感觉不友好；（2018.1.10） 在IDE 中无法进行代码跟踪，点击类名无法跳转过去；（2018.1.10） 适用场景： 适用于功能不复杂的项目; Yii2ThinkPHP优点： 缺点： CakePHPSwooleSymfonyLaravel优点： PHP7 的适用，Composer 包依赖，测试覆盖率 100%，优雅的架构设计;（2018.1.10） 合理的版本发布计划;（2018.1.10） 文档丰富，但不够细致；（2018.1.10） 缺点： 性能与资源消耗挺严重的；对于一般的后台管理系统，不是问题；（2018.1.10） 适用场景： 适用于功能复杂，需要不断迭代测试，对性能要求不是特别重要的项目；]]></content>
      <categories>
        <category>PHP</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CodeIgniter 框架搭建]]></title>
    <url>%2F2018%2F01%2F10%2Fcodeigniter-init%2F</url>
    <content type="text"><![CDATA[本地部署及运行下载代码CodeIgniter 中国 下载页面罗列了各个版本的 CI 源代码； 找到最新的版本并下载； 执行 composer install 初始化安装依赖； 在 Nginx 上配置： 123456789101112131415161718192021222324252627282930313233server &#123; listen 9050; server_name localhost; proxy_buffer_size 128k; proxy_buffers 8 256k; proxy_busy_buffers_size 256k; client_max_body_size 50M; root /opt/ci; location / &#123; if (-f $request_filename/index.html)&#123; rewrite (.*) $1/index.html break; &#125; if (-f $request_filename/index.php)&#123; rewrite (.*) $1/index.php; &#125; if (!-f $request_filename)&#123; rewrite (.*) /index.php; &#125; index index.php index.html index.htm; try_files $uri $uri/index.php; &#125; location ~* \.(eot|otf|ttf|woff|woff2)$ &#123; add_header Access-Control-Allow-Origin *; &#125; rewrite ^/(.*\.php)(/)(.*)$ /$1?file=/$3 last; include "/opt/bksite/nginx/conf/bitnami/phpfastcgi.conf"; include "/opt/bksite/nginx/conf/bitnami/bitnami-apps-prefix.conf";&#125; 成功页面如下： 配置设置网站 base_url 在文件 application/config/config.php 上；如果不设置，默认是服务器的 IP 地址，没有端口信息； 1$config['base_url'] = 'http://172.16.0.43:9050'; 开启 Composer 自动加载 在文件 application/config/config.php 上； 1$config['composer_autoload'] = TRUE;]]></content>
      <tags>
        <tag>CodeIgniter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql 用在 select 和 where 子句中的函数]]></title>
    <url>%2F2018%2F01%2F08%2Fmysql-select-where-func%2F</url>
    <content type="text"><![CDATA[转自 MySQL中文参考手册 7.4 节 用在SELECT和WHERE子句中的函数 算术函数加法 1select 3+5; // 输出 8 减法 1select 3-5; // 输出 -2 乘法12345select 3*5; // 输出 15select 18014398509481984*18014398509481984.0; // 输出 324518553658426726783156020576256.0select 18014398509481984*18014398509481984; // 输出 0 因为 整数乘积的结果超过用BIGINT计算的 64 位范围 除法 123select 3/5; // 输出 0.6select 102/(1-1); // 输出 NULL 位函数位与 1select 29 &amp; 15; // 输出 13 位或 1select 29 | 15; // 输出 31 左移位一个长(BIGINT)数字。 1select 1 &lt;&lt; 2; // 输出 4 右移位一个长(BIGINT)数字。 1select 4 &gt;&gt; 2; // 输出 1 颠倒所有的位。 1select 5 &amp; ~1; // 输出 4 二进制数中包含1的个数 1select BIT_COUNT(29); // 输出 4 逻辑运算逻辑与如果任何一个参数是 0 或 NULL，返回0，否则返回1。12select 1 &amp;&amp; NULL; // 输出 0select 1 &amp;&amp; 0; // 输出 0 逻辑或如果任何一个参数不是 0 并且不 NULL，返回 1。123select 1 || 0; // 输出 1select 1 || NULL; // 输出 1select 0 || 0; // 输出 0 逻辑非如果参数是 0，返回 1，否则返回 0。例外： NOT NULL 返回 NULL。1234select NOT 1; // 输出 0select NOT NULL; // 输出 NULLselect ! (1+1); // 输出 0select ! 1+1; // 输出 1 比较运算MySQL 使用下列规则执行比较： 如果一个或两个参数是 NULL，比较的结果是 NULL，除了 &lt;=&gt; 操作符。 如果在比较中操作的两个参数是字符串，他们作为字符串被比较。 如果两个参数是整数，他们作为整数被比较。 十六进制的值如果不与一个数字比较，则被当作二进制字符串。 如果参数之一是一个 TIMESTAMP 或 DATETIME 列而其他参数是一个常数，在比较执行前，常数被转换为一个时间标记。这样做是为了对 ODBC 更友好。 在所有其他的情况下，参数作为浮点(实数)数字被比较。 等于 123456select 1 = 0; // 输出 0select '0' = 0; // 输出 1select '0.0' = 0; // 输出 1select '0.01' = 0; // 输出 0select '.01' = 0.01; // 输出 1select 1 = null; // 输出 null 安全等于 和 = 不一样， null 会被纳入可比较； 1select 1 = null; // 输出 0 不等于 123select '.01' &lt;&gt; '0.01'; // 输出 1select .01 &lt;&gt; '0.01'; // 输出 0select 'zapp' &lt;&gt; 'zappp'; // 输出 1 小于或等于 1select 0.1 &lt;= 2; // 输出 1 小于 1select 2 &lt; 2; // 输出 0 大于或等于 1select 2 &gt;= 2; // 输出 1 大于 1select 2 &gt; 2; // 输出 0 NULL 和 非 NULL 12345678select 1 IS NULL, 0 IS NULL, NULL IS NULL:// 输出 0 0 1select 1 IS NOT NULL, 0 IS NOT NULL, NULL IS NOT NULL;// 输出 1 1 0select ISNULL(1+1); // 输出 0select ISNULL(1/0); // 输出 1 BETWEEN AND 这等价于表达式(min &lt;= expr AND expr &lt;= max)。 1234select 1 BETWEEN 2 AND 3; // 输出 0select 'b' BETWEEN 'a' AND 'c'; // 输出 1select 2 BETWEEN 2 AND '3'; // 输出 1select 2 BETWEEN 2 AND 'x-3'; // 输出 0 IN 和 NOT IN 12select 2 IN (0,3,5,'wefwf'); // 输出 0select 'wefwf' IN (0,3,5,'wefwf'); // 输出 1 COALESCE(list) 返回 list 中第一个非 NULL 的单元。 12select COALESCE(NULL,1); // 输出 1select COALESCE(NULL,NULL,NULL); // 输出 NULL INTERVAL(N,N1,N2,N3,…) 如果 N&lt; N1，返回 0，如果 N&lt; N2，返回 1 等等。所有的参数被当作整数。为了函数能正确地工作，它要求 N1&lt;N2&lt;N3&lt; ...&lt;Nn。这是因为使用二进制搜索(很快)。 123select INTERVAL(23, 1, 15, 17, 30, 44, 200); // 输出 3select INTERVAL(10, 1, 10, 100, 1000); // 输出 2select INTERVAL(22, 23, 30, 44, 200); // 输出 0 字符串比较函数LIKE 与 NOT LIKE %: 匹配任何数目的字符，甚至零个字符 _: 精确匹配一个字符 12select 'David!' LIKE 'David_'; // 输出 1select 'David!' LIKE '%D%v%'; // 输出 1 转义字符 \ 123select 'David!' LIKE 'David\_'; // 输出 0select 'David_' LIKE 'David\_'; // 输出 1 或者指定不同的转义字符 1select 'David_' LIKE 'David|_' ESCAPE '|'; // 输出 1 REGEXP 和 NOT REGEXP 1234select 'Monty!' REGEXP 'm%y%%'; // 输出 0select 'Monty!' REGEXP '.*'; // 输出 1select 'new*\n*line' REGEXP 'new\\*.\\*line'; // 输出 1select "a" REGEXP "A", "a" REGEXP BINARY "A"; // 输出 1 0 STRCMP(expr1,expr2) 如果字符串相同，STRCMP() 返回 0，如果第一参数根据当前的排序次序小于第二个，返回 -1，否则返回 1。 123select STRCMP('text', 'text2'); // 输出 -1select STRCMP('text2', 'text'); // 输出 1select STRCMP('text', 'text'); // 输出 0 类型转换运算符BINARY 操作符强制跟随它后面的字符串为一个二进制字符串。即使列没被定义为 BINARY 或 BLOB，这是一个强制列比较区分大小写的简易方法。 12select "a" = "A"; // 输出 1select BINARY "a" = "A"; // 输出 0 控制流函数IFNULL(expr1,expr2)如果 expr1 不是 NULL，IFNULL() 返回 expr1，否则它返回 expr2。IFNULL() 返回一个数字或字符串值，取决于它被使用的上下文环境。 1234select IFNULL(1,0); // 输出 1select IFNULL(0,10); // 输出 0select IFNULL(1/0,10); // 输出 10select IFNULL(1/0,'yes'); // 输出 'yes' IF(expr1,expr2,expr3) 如果 expr1 是 TRUE (expr1 &lt;&gt;0且expr1&lt;&gt;NULL)，那么IF()返回expr2，否则它返回expr3。IF()返回一个数字或字符串值，取决于它被使用的上下文。 12345select IF(1&gt;2,2,3); // 输出 3select IF(1&lt;2,'yes','no'); // 输出 'yes'select IF(strcmp('test','test1'),'yes','no'); // 输出 'yes' CASE value WHEN [compare-value] THEN result [WHEN [compare-value] THEN result …] [ELSE result] END 1SELECT CASE 1 WHEN 1 THEN "one" WHEN 2 THEN "two" ELSE "more" END; // 输出 "one" CASE WHEN [condition] THEN result [WHEN [condition] THEN result …] [ELSE result] END 123SELECT CASE WHEN 1&gt;0 THEN "true" ELSE "false" END; // 输出 "true"SELECT CASE BINARY "B" when "a" then 1 when "b" then 2 END; // 输出 NULL 数学函数所有的数学函数在一个出错的情况下返回 NULL。 -单目减。改变参数的符号。 1select - 2; // 输出 -2 ABS(X)返回X的绝对值。 12select ABS(2); // 输出 2select ABS(-32); // 输出 32 SIGN(X)返回参数的符号，为 -1、0 或 1，取决于 X 是否是负数、零或正数。 123select SIGN(-32); // 输出 -1select SIGN(0); // 输出 0select SIGN(234); // 输出 1 MOD(N,M) 或 %模 (类似 C 中的%操作符)。返回 N 被 M 除的余数。 123select MOD(234, 10); // 输出 4select 253 % 7; // 输出 1select MOD(29,9); // 输出 2 FLOOR(X)返回不大于 X 的最大整数值。 12select FLOOR(1.23); // 输出 1select FLOOR(-1.23); // 输出 -2 CEILING(X)返回不小于 X 的最小整数值。 12select CEILING(1.23); // 输出 2select CEILING(-1.23); // 输出 -1 ROUND(X) 和 ROUND(X,D) 返回参数 X 的四舍五入的一个整数。 123456select ROUND(-1.23);// 输出 -1select ROUND(-1.58);// 输出 -2select ROUND(1.58); // 输出 2select ROUND(1.298, 1); // 输出 1.3select ROUND(1.298, 0); // 输出 1 EXP(X)返回值 e（自然对数的底）的 X 次方。 12select EXP(2); // 输出 7.389056select EXP(-2); // 输出 0.135335 LOG(X)返回 X 的自然对数。 12select LOG(2); // 输出 0.693147select LOG(-2); // 输出 NULL LOG10(X)返回 X 的以10为底的对数。 123select LOG10(2); // 输出 0.301030select LOG10(100); // 输出 2.000000select LOG10(-100); // 输出 NULL POW(X,Y)和 POWER(X,Y) 等价12select POW(2,2); // 输出 4.000000select POW(2,-2); // 输出 0.250000 SQRT(X)返回非负数 X 的平方根。 12select SQRT(4); // 输出 2.000000select SQRT(20); // 输出 4.472136 PI()返回 PI 的值（圆周率）。 1select PI(); // 输出 3.141593 COS(X)返回 X 的余弦, 在这里 X 以弧度给出。 1select COS(PI()); // 输出 -1.000000 SIN(X)返回 X 的正弦值，在此 X 以弧度给出。 1select SIN(PI()); // 输出 0.000000 TAN(X)返回 X 的正切值，在此 X 以弧度给出。 1select TAN(PI()+1); // 输出 1.557408 ACOS(X)返回 X 反余弦，即其余弦值是 X。如果 X 不在-1到1的范围，返回 NULL。 123select ACOS(1); // 输出 0.000000select ACOS(1.0001); // 输出 NULLselect ACOS(0); // 输出 1.570796 ASIN(X)返回 X 反正弦值，即其正弦值是 X。L如果 X 不在-1到1的范围，返回 NULL。 12select ASIN(0.2); // 输出 0.201358select ASIN('foo'); // 输出 0.000000 ATAN(X)返回 X 的反正切值，即其正切值是X。 12select ATAN(2); // 输出 1.107149select ATAN(-2); // 输出 -1.107149 ATAN2(X,Y)返回 2 个变量 X 和 Y 的反正切。它类似于计算 Y/X 的反正切，除了两个参数的符号被用来决定结果的象限。 12select ATAN(-2,2); // 输出 -0.785398select ATAN(PI(),0); // 输出 1.570796 COT(X)返回 X 的余切。 12select COT(12); // 输出 -1.57267341select COT(0); // 输出 NULL RAND() 和 RAND(N)返回在范围 0 到 1.0 内的随机浮点值。如果一个整数参数 N 被指定，它被用作种子值。 12345select RAND(); // 输出 0.5925select RAND(20); // 输出 0.1811select RAND(20); // 输出 0.1811select RAND(); // 输出 0.2079select RAND(); // 输出 0.7888 LEAST(X,Y,…) 有 2 和 2 个以上的参数，返回最小(最小值)的参数。 123select LEAST(2,0); // 输出 0select LEAST(34.0,3.0,5.0,767.0); // 输出 3.0select LEAST("B","A","C"); // 输出 "A" GREATEST(X,Y,…)返回最大(最大值)的参数。 123select GREATEST(2,0); // 输出 2select GREATEST(34.0,3.0,5.0,767.0); // 输出 767.0select GREATEST("B","A","C"); // 输出 "C" DEGREES(X)返回参数 X，从弧度变换为角度。 1select DEGREES(PI()); // 输出 180.000000 RADIANS(X)返回参数 X，从角度变换为弧度。 1select RADIANS(90); // 输出 1.570796 TRUNCATE(X,D)返回数字 X，截断为 D 位小数。如果 D 为 0，结果将没有小数点或小数部分。 123select TRUNCATE(1.223,1); // 输出 1.2select TRUNCATE(1.999,1); // 输出 1.9select TRUNCATE(1.999,0); // 输出 1 字符串函数对于针对字符串位置的操作，第一个位置被标记为 1。 ASCII(str)返回字符串 str 的最左面字符的 ASCII 代码值。如果 str 是空字符串，返回 0。如果 str 是 NULL，返回 NULL。 123select ASCII('2'); // 输出 50select ASCII(2); // 输出 50select ASCII('dx'); // 输出 100 ORD(str)如果字符串 str 最左面字符是一个多字节字符，通过以格式((first byte ASCII code)*256+(second byte ASCII code))[*256+third byte ASCII code...]返回字符的 ASCII 代码值来返回多字节字符代码。如果最左面的字符不是一个多字节字符。返回与 ASCII() 函数返回的相同值。 1select ORD('2'); // 输出 50 CONV(N,from_base,to_base)在不同的数字基之间变换数字。返回数字 N 的字符串数字，从 from_base 基变换为 to_base 基，如果任何参数是NULL，返回 NULL。 1234select CONV("a",16,2); // 输出 '1010'select CONV("6E",18,8); // 输出 '172'select CONV(-17,10,-18); // 输出 '-H'select CONV(10+"10"+'10'+0xa,10,10); // 输出 '40' BIN(N)返回二进制值 N 的一个字符串表示，在此 N 是一个长整数(BIGINT)数字，这等价于CONV(N,10,2)。如果 N 是 NULL，返回 NULL。 1select BIN(12); // 输出 '1100' OCT(N)返回八进制值 N 的一个字符串的表示，在此N是一个长整型数字，这等价于 CONV(N,10,8)。如果 N 是 NULL，返回 NULL。 1select OCT(12); // 输出 '14' HEX(N)返回十六进制值 N 一个字符串的表示，在此 N 是一个长整型(BIGINT)数字，这等价于 CONV(N,10,16) 。如果 N 是 NULL，返回 NULL。 1select HEX(255); // 输出 'FF' CHAR(N,…)CHAR() 将参数解释为整数并且返回由这些整数的 ASCII 代码字符组成的一个字符串。NULL 值被跳过。 12select CHAR(77,121,83,81,'76'); // 输出 'MySQL'select CHAR(77,77.3,'77.3'); // 输出 'MMM' CONCAT(str1,str2,…)返回来自于参数连结的字符串。如果任何参数是 NULL，返回 NULL。 123select CONCAT('My', 'S', 'QL'); // 输出 'MySQL'select CONCAT('My', NULL, 'QL');// 输出 NULLselect CONCAT(14.3); // 输出 '14.3' LENGTH(str)等同于 OCTET_LENGTH(str) CHAR_LENGTH(str) CHARACTER_LENGTH(str) 返回字符串str的长度。 12select LENGTH('text'); // 输出 4select OCTET_LENGTH('text'); // 输出 4 LOCATE(substr,str)等同于 POSITION(substr IN str) 返回子串 substr 在字符串 str 第一个出现的位置，如果 substr 不是在 str 里面，返回 0. 12select LOCATE('bar', 'foobarbar'); // 输出 4select LOCATE('xbar', 'foobar'); // 输出 0 LOCATE(substr,str,pos)返回子串 substr 在字符串 str 第一个出现的位置，从位置 pos 开始。如果 substr 不是在 str 里面，返回 0。 1select LOCATE('bar', 'foobarbar',5); // 输出 7 INSTR(str,substr)返回子串 substr 在字符串 str 中的第一个出现的位置。这与有 2 个参数形式的 LOCATE() 相同，除了参数被颠倒。 12select INSTR('foobarbar', 'bar'); // 输出 4select INSTR('xbar', 'foobar'); // 输出 0 LPAD(str,len,padstr)返回字符串 str，左面用字符串 padstr 填补直到 str 是 len 个字符长。 1select LPAD('hi',4,'??'); // 输出 '??hi' RPAD(str,len,padstr)返回字符串str，右面用字符串 padstr 填补直到 str 是 len 个字符长。 1select RPAD('hi',5,'??'); // 输出 'hi???' LEFT(str,len)返回字符串 str 的最左面 len 个字符。 1select LEFT('foobarbar', 5); // 输出 'fooba' RIGHT(str,len)返回字符串 str 的最右面 len 个字符。 1select RIGHT('foobarbar', 4); // 输出 'rbar' SUBSTRING(str,pos,len)等同于 SUBSTRING(str FROM pos FOR len) MID(str,pos,len) 从字符串 str 返回一个 len 个字符的子串，从位置 pos 开始。 1select SUBSTRING('Quadratically',5,6); // 输出 'ratica' SUBSTRING(str,pos)等同于 SUBSTRING(str FROM pos) 从字符串 str 的起始位置 pos 返回一个子串。 12select SUBSTRING('Quadratically',5); // 输出 'ratically'select SUBSTRING('foobarbar' FROM 4); // 输出 'barbar' SUBSTRING_INDEX(str,delim,count)返回从字符串 str 的第 count 个出现的分隔符 delim 之后的子串。如果 count 是正数，返回最后的分隔符到左边(从左边数) 的所有字符。如果 count 是负数，返回最后的分隔符到右边的所有字符(从右边数)。 12select SUBSTRING_INDEX('www.mysql.com', '.', 2); // 输出 'www.mysql'select SUBSTRING_INDEX('www.mysql.com', '.', -2); // 输出 'mysql.com' LTRIM(str)返回删除了其前置空格字符的字符串 str。 1select LTRIM(' barbar'); // 输出 'barbar' RTRIM(str)返回删除了其拖后空格字符的字符串 str。 1select RTRIM('barbar '); // 输出 'barbar' TRIM([[BOTH | LEADING | TRAILING] [remstr] FROM] str)返回字符串 str，其所有 remstr 前缀或后缀被删除了。如果没有修饰符 BOTH、LEADING 或 TRAILING 给出，BOTH 被假定。如果 remstr 没被指定，空格被删除。 1234select TRIM(' bar '); // 输出 'bar'select TRIM(LEADING 'x' FROM 'xxxbarxxx'); // 输出 'barxxx'select TRIM(BOTH 'x' FROM 'xxxbarxxx'); // 输出 'bar'select TRIM(TRAILING 'xyz' FROM 'barxxyz'); // 输出 'barx' SOUNDEX(str)返回 str 的一个同音字符串。听起来“大致相同”的 2 个字符串应该有相同的同音字符串。一个“标准”的同音字符串长是 4 个字符，但是 SOUNDEX() 函数返回一个任意长的字符串。你可以在结果上使用 SUBSTRING() 得到一个“标准”的 同音串。所有非数字字母字符在给定的字符串中被忽略。所有在 A-Z 之外的字符国际字母被当作元音。 12select SOUNDEX('Hello'); // 输出 'H400'select SOUNDEX('Quadratically'); // 输出 'Q36324' SPACE(N)返回由 N 个空格字符组成的一个字符串。 1select SPACE(6); // 输出 ' ' REPLACE(str,from_str,to_str)返回字符串 str，其字符串 from_str 的所有出现由字符串 to_str 代替。 1select REPLACE('www.mysql.com', 'w', 'Ww'); // 输出 'WwWwWw.mysql.com' REPEAT(str,count)返回由重复 countTimes 次的字符串 str 组成的一个字符串。如果 count &lt;= 0，返回一个空字符串。如果 str 或 count 是 NULL，返回 NULL。 1select REPEAT('MySQL', 3); // 输出 'MySQLMySQLMySQL' REVERSE(str)返回颠倒字符顺序的字符串 str 1select REVERSE('abc'); // 输出 'cba INSERT(str,pos,len,newstr)返回字符串 str，在位置 pos 起始的子串且 len 个字符长得子串由字符串 newstr 代替。 1select INSERT('Quadratic', 3, 4, 'What'); // 输出 'QuWhattic' ELT(N,str1,str2,str3,…)如果 N= 1，返回 str1，如果 N= 2，返回 str2，等等。如果 N小于 1 或大于参数个数，返回 NULL。ELT() 是 FIELD() 反运算。 12select ELT(1, 'ej', 'Heja', 'hej', 'foo'); // 输出 'ej'select ELT(4, 'ej', 'Heja', 'hej', 'foo'); // 输出 'foo' FIELD(str,str1,str2,str3,…)返回 str 在 str1 , str2, str3, …清单的索引。如果 str 没找到，返回 0。FIELD() 是 ELT() 反运算。 12select FIELD('ej', 'Hej', 'ej', 'Heja', 'hej', 'foo'); // 输出 2select FIELD('fo', 'Hej', 'ej', 'Heja', 'hej', 'foo'); // 输出 0 FIND_IN_SET(str,strlist)如果字符串 str 在由 N 子串组成的表 strlist 之中，返回一个 1 到 N 的值。一个字符串表是被“,”分隔的子串组成的一个字符串。 1SELECT FIND_IN_SET('b','a,b,c,d'); // 输出 2 MAKE_SET(bits,str1,str2,…)返回一个集合 (包含由“,”字符分隔的子串组成的一个字符串)，由相应的位在 bits 集合中的的字符串组成。str1 对应于位 0，str2 对应位 1，等等。在 str1, str2, …中的 NULL 串不添加到结果中。 123SELECT MAKE_SET(1,'a','b','c'); // 输出 'a'SELECT MAKE_SET(1 | 4,'hello','nice','world'); // 输出 'hello,world'SELECT MAKE_SET(0,'a','b','c'); // 输出 '' EXPORT_SET(bits,on,off,[separator,[number_of_bits]])返回一个字符串，在这里对于在“ bits ”中设定每一位，你得到一个“on”字符串，并且对于每个复位(reset)的位，你得到一个“ off ”字符串。每个字符串用“ separator ”分隔(缺省“,”)，并且只有“ bits ”的“number_of_bits ” (缺省64)位被使用。 1select EXPORT_SET(5,'Y','N',',',4) // 输出 Y,N,Y,N LCASE(str)等同于 LOWER(str) 返回字符串 str，根据当前字符集映射(缺省是ISO-8859-1 Latin1)把所有的字符改变成小写。 1select LCASE('QUADRATICALLY'); // 输出 'quadratically' UCASE(str)等同于 UPPER(str) 返回字符串 str，根据当前字符集映射(缺省是 ISO-8859-1 Latin1 )把所有的字符改变成大写。 1select UCASE('Hej'); // 输出 'HEJ' LOAD_FILE(file_name)读入文件并且作为一个字符串返回文件内容。文件必须在服务器上，你必须指定到文件的完整路径名，而且你必须有 file 权限。文件必须所有内容都是可读的并且小于 max_allowed_packet 。如果文件不存在或由于上面原因之一不能被读出，函数返回 NULL。 123UPDATE table_nameSET blob_column=LOAD_FILE("/tmp/picture")WHERE id=1; 日期和时间函数DAYOFWEEK(date)返回日期 date 的星期索引(1=星期天，2=星期一, ……7=星期六)。 1select DAYOFWEEK('1998-02-03'); // 输出 3 WEEKDAY(date)返回 date 的星期索引(0=星期一，1=星期二, ……6= 星期天)。 12select WEEKDAY('1997-10-04 22:23:00'); // 输出 5select WEEKDAY('1997-11-05'); // 输出 2 DAYOFMONTH(date)返回date的月份中日期，在1到31范围内。 1select DAYOFMONTH('1998-02-03'); // 输出 3 DAYOFYEAR(date)返回 date 在一年中的日数, 在 1 到 366 范围内。 1select DAYOFYEAR('1998-02-03'); // 输出 34 MONTH(date)返回 date 的月份，范围1到12。 1select MONTH('1998-02-03'); // 输出 2 DAYNAME(date)返回 date 的星期名字。 1select DAYNAME("1998-02-05"); // 输出 'Thursday' MONTHNAME(date)返回 date 的月份名字。 1select MONTHNAME("1998-02-05"); // 输出 'February' QUARTER(date)返回 date 一年中的季度，范围 1 到 4。 1select QUARTER('98-04-01'); // 输出 2 WEEK(date) 和 WEEK(date,first)对于星期天是一周的第一天的地方，有一个单个参数，返回 date 的周数，范围在 0 到 52。2 个参数形式 WEEK() 允许你指定星期是否开始于星期天或星期一。如果第二个参数是 0，星期从星期天开始，如果第二个参数是 1，从星期一开始。 123select WEEK('1998-02-20'); // 输出 7select WEEK('1998-02-20',0); // 输出 7select WEEK('1998-02-20',1); // 输出 8 YEAR(date)返回 date 的年份，范围在 1000 到 9999。 1select YEAR('98-02-03'); // 输出 1998 HOUR(time)返回 time 的小时，范围是 0 到 23。 1select HOUR('10:05:03'); // 输出 10 MINUTE(time)返回 time 的分钟，范围是 0 到 59。 1select MINUTE('98-02-03 10:05:03'); // 输出 5 SECOND(time)回来 time 的秒数，范围是0到59。 1select SECOND('10:05:03'); // 输出 3 PERIOD_ADD(P,N)增加 N 个月到阶段 P（以格式 YYMM 或 YYYYMM)。以格式 YYYYMM 返回值。注意阶段参数 P 不是日期值。 1select PERIOD_ADD(9801,2); // 输出 199803 PERIOD_DIFF(P1,P2)返回在时期 P1 和 P2 之间月数，P1 和 P2 应该以格式 YYMM 或 YYYYMM 。注意，时期参数 P1 和 P2 不是日期值。 1select PERIOD_DIFF(9802,199703); // 输出 11 DATE_ADD(date,INTERVAL expr type) 和 DATE_SUB(date,INTERVAL expr type)等同于 ADDDATE(date,INTERVAL expr type) 和 SUBDATE(date,INTERVAL expr type) 你可以使用 + 和 - 而不是 DATE_ADD() 和 DATE_SUB()。（见例子） date 是一个指定开始日期的 DATETIME 或 DATE 值，expr 是指定加到开始日期或从开始日期减去的间隔值一个表达式， expr 是一个字符串；它可以以一个“-”开始表示负间隔。type 是一个关键词，指明表达式应该如何被解释。 下表显示了type和expr参数怎样被关联： type 值 含义 期望的 expr 格式 SECOND 秒 SECONDS MINUTE 分钟 MINUTES HOUR 时间 HOURS DAY 天 DAYS MONTH 月 MONTHS YEAR 年 YEARS MINUTE_SECOND 分钟和秒 MINUTES:SECONDS HOUR_MINUTE 小时和分钟 HOURS:MINUTES DAY_HOUR 天和小时 DAYS HOURS YEAR_MONTH 年和月 YEARS-MONTHS HOUR_SECOND 小时, 分钟， HOURS:MINUTES:SECONDS DAY_MINUTE 天, 小时, 分钟 DAYS HOURS:MINUTES DAY_SECOND 天, 小时, 分钟, 秒 DAYS HOURS:MINUTES:SECONDS 123456789101112SELECT "1997-12-31 23:59:59" + INTERVAL 1 SECOND; // 输出 1998-01-01 00:00:00SELECT INTERVAL 1 DAY + "1997-12-31"; // 输出 1998-01-01SELECT "1998-01-01" - INTERVAL 1 SECOND; // 输出 1997-12-31 23:59:59 SELECT DATE_ADD("1997-12-31 23:59:59", INTERVAL 1 SECOND); // 输出 1998-01-01 00:00:00SELECT DATE_ADD("1997-12-31 23:59:59", INTERVAL 1 DAY); // 输出 1998-01-01 23:59:59SELECT DATE_ADD("1997-12-31 23:59:59", INTERVAL "1:1" MINUTE_SECOND); // 输出 1998-01-01 00:01:00SELECT DATE_SUB("1998-01-01 00:00:00", INTERVAL "1 1:1:1" DAY_SECOND); // 输出 1997-12-30 22:58:59SELECT DATE_ADD("1998-01-01 00:00:00", INTERVAL "-1 10" DAY_HOUR); // 输出 1997-12-30 14:00:00SELECT DATE_SUB("1998-01-02", INTERVAL 31 DAY); // 输出 1997-12-02SELECT EXTRACT(YEAR FROM "1999-07-02"); // 输出 1999SELECT EXTRACT(YEAR_MONTH FROM "1999-07-02 01:02:03"); // 输出 199907SELECT EXTRACT(DAY_MINUTE FROM "1999-07-02 01:02:03"); // 输出 20102 如果你指定太短的间隔值(不包括 type 关键词期望的间隔部分)，MySQL 假设你省掉了间隔值的最左面部分。例如，如果你指定一个 type 是 DAY_SECOND，值 expr 被希望有天、小时、分钟和秒部分。如果你象”1:10”这样指定值，MySQL 假设日子和小时部分是丢失的并且值代表分钟和秒。换句话说，”1:10” DAY_SECOND 以它等价于”1:10” MINUTE_SECOND 的方式解释， TO_DAYS(date)给出一个日期 date，返回一个天数(从 0 年的天数)。 12select TO_DAYS(950501); // 输出 728779mysql&gt; select TO_DAYS('1997-10-07'); // 输出 729669 FROM_DAYS(N)给出一个天数 N，返回一个 DATE 值。 1select FROM_DAYS(729669); // 输出 '1997-10-07' DATE_FORMAT(date,format)根据 format 字符串格式化 date 值。下列修饰符可以被用在 format 字符串中： 修饰符 描述 %M 月名字(January……December) %W 星期名字(Sunday……Saturday) %D 有英语前缀的月份的日期(1st, 2nd, 3rd, 等等。） %Y 年, 数字, 4 位 %y 年, 数字, 2 位 %a 缩写的星期名字(Sun……Sat) %d 月份中的天数, 数字(00……31) %e 月份中的天数, 数字(0……31) %m 月, 数字(01……12) %c 月, 数字(1……12) %b 缩写的月份名字(Jan……Dec) %j 一年中的天数(001……366) %H 小时(00……23) %k 小时(0……23) %h 小时(01……12) %I 小时(01……12) %l 小时(1……12) %i 分钟, 数字(00……59) %r 时间, 12 小时(hh:mm:ss [AP]M) %T 时间, 24 小时(hh:mm:ss) %S 秒(00……59) %s 秒(00……59) %p AM 或 PM %w 一个星期中的天数(0=Sunday ……6=Saturday ） %U 星期(0……52), 这里星期天是星期的第一天 %u 星期(0……52), 这里星期一是星期的第一天 %% 一个文字“%”。 1234select DATE_FORMAT('1997-10-04 22:23:00', '%W %M %Y'); // 输出 'Saturday October 1997'mysql&gt; select DATE_FORMAT('1997-10-04 22:23:00', '%H:%i:%s'); // 输出 '22:23:00'mysql&gt; select DATE_FORMAT('1997-10-04 22:23:00', '%D %y %a %d %m %b %j'); // 输出 '4th 97 Sat 04 10 Oct 277'mysql&gt; select DATE_FORMAT('1997-10-04 22:23:00', '%H %k %I %r %T %S %w'); // 输出 '22 22 10 10:23:00 PM 22:23:00 00 6' TIME_FORMAT(time,format)这象上面的 DATE_FORMAT() 函数一样使用，但是 format 字符串只能包含处理小时、分钟和秒的那些格式修饰符。其他修饰符产生一个 NULL 值或0。 CURDATE() 和 CURRENT_DATE以’YYYY-MM-DD‘或 YYYYMMDD 格式返回今天日期值，取决于函数是在一个字符串还是数字上下文被使用。 12select CURDATE(); // 输出 '1997-12-15'select CURDATE() + 0; // 输出 19971215 CURTIME() 和 CURRENT_TIME以’HH:MM:SS‘或 HHMMSS 格式返回当前时间值 12select CURTIME(); // 输出 '23:50:26'select CURTIME() + 0; // 输出 235026 NOW()等同于 SYSDATE() CURRENT_TIMESTAMP 以’YYYY-MM-DD HH:MM:SS‘或 YYYYMMDDHHMMSS 格式返回当前的日期和时间，取决于函数是在一个字符串还是在数字的上下文被使用。 12select NOW(); // 输出 '1997-12-15 23:50:26'select NOW() + 0; // 输出 19971215235026 UNIX_TIMESTAMP() 和 UNIX_TIMESTAMP(date)如果没有参数调用，返回一个 Unix 时间戳记(从’1970-01-01 00:00:00‘ GMT 开始的秒数)。如果 UNIX_TIMESTAMP() 用一个 date 参数被调用，它返回从’1970-01-01 00:00:00‘ GMT 开始的秒数值。date 可以是一个 DATE 字符串、一个 DATETIME 字符串、一个 TIMESTAMP 或以 YYMMDD 或 YYYYMMDD 格式的本地时间的一个数字。 12select UNIX_TIMESTAMP(); // 输出 882226357select UNIX_TIMESTAMP('1997-10-04 22:23:00'); // 输出 875996580 FROM_UNIXTIME(unix_timestamp)以’YYYY-MM-DD HH:MM:SS‘或 YYYYMMDDHHMMSS 格式返回 unix_timestamp 参数所表示的值 12select FROM_UNIXTIME(875996580); // 输出 '1997-10-04 22:23:00'select FROM_UNIXTIME(875996580) + 0; // 输出 19971004222300 FROM_UNIXTIME(unix_timestamp,format)返回表示 Unix 时间标记的一个字符串，根据 format 字符串格式化。 1select FROM_UNIXTIME(UNIX_TIMESTAMP(), '%Y %D %M %h:%i:%s %x'); // 输出 '1997 23rd December 03:43:30 x' SEC_TO_TIME(seconds)返回 seconds 参数，变换成小时、分钟和秒，值以’HH:MM:SS‘或 HHMMSS 格式化 12select SEC_TO_TIME(2378); // 输出 '00:39:38'select SEC_TO_TIME(2378) + 0; // 输出 3938 TIME_TO_SEC(time)返回 time 参数，转换成秒。 12select TIME_TO_SEC('22:23:00'); // 输出 80580select TIME_TO_SEC('00:39:38'); // 输出 2378 其他函数DATABASE()返回当前的数据库名字。 1select DATABASE(); // 输出 'test' USER()同 SYSTEM_USER() SESSION_USER() 返回当前 MySQL 用户名。 123select USER(); // 输出 'davida@localhost'select substring_index(USER(),"@",1); // 输出 'davida' PASSWORD(str)从纯文本口令 str 计算一个口令字符串。该函数被用于为了在 user 授权表的 Password 列中存储口令而加密 MySQL 口令。 PASSWORD() 加密是非可逆的。PASSWORD() 不以与 Unix 口令加密的相同的方法执行口令加密。 1select PASSWORD('badpwd'); // 输出 '7f84554057dd964b' ENCRYPT(str[,salt])使用 Unix crypt() 系统调用加密 str。salt 参数应该是一个有 2 个字符的字符串 1select ENCRYPT("hello"); // 输出 'VxuFAJXVARROc' 如果 crypt() 在你的系统上不可用，ENCRYPT() 总是返回 NULL。ENCRYPT() 只保留 str 起始 8 个字符而忽略所有其他，至少在某些系统上是这样。这将由底层的 crypt() 系统调用的行为决定。 ENCODE(str,pass_str)使用 pass_str 作为口令加密 str。为了解密结果，使用 DECODE()。结果是一个二进制字符串，如果你想要在列中保存它，使用一个 BLOB 列类型。 DECODE(crypt_str,pass_str)使用 pass_str 作为口令解密加密的字符串 crypt_str。crypt_str 应该是一个由 ENCODE() 返回的字符串。 MD5(string)对字符串计算 MD5 校验和。值作为一个 32 长的十六进制数字被返回可以，例如用作哈希(hash)键。 1select MD5("testing"); // 输出 'ae2b1fca515949e5d54fb22b8ed95575' LAST_INSERT_ID([expr])返回被插入一个 AUTO_INCREMENT 列的最后一个自动产生的值。 1select LAST_INSERT_ID(); // 输出 195 FORMAT(X,D)格式化数字 X 为类似于格式’#,###,###.##‘，四舍五入到 D 为小数。如果 D 为 0，结果将没有小数点和小数部分。 123select FORMAT(12332.123456, 4); // 输出 '12,332.1235'select FORMAT(12332.1,4); // 输出 '12,332.1000'select FORMAT(12332.2,0); // 输出 '12,332' VERSION()返回表明 MySQL 服务器版本的一个字符串。 1select VERSION(); // 输出 '3.22.19b-log' GET_LOCK(str,timeout)试图获得由字符串 str 给定的一个名字的锁定，第二个 timeout 为超时。如果锁定成功获得，返回 1，如果尝试超时了，返回 0，或如果发生一个错误，返回 NULL (例如从存储器溢出或线程用 mysqladmin kill 被杀死)。当你执行 RELEASE_LOCK() 时、执行一个新的 GET_LOCK() 或线程终止时，一个锁定被释放。该函数可以用来实现应用锁或模拟记录锁，它阻止其他客户用同样名字的锁定请求；赞成一个给定的锁定字符串名字的客户可以使用字符串执行子协作建议的锁定。 1234select GET_LOCK("lock1",10); // 输出 1select GET_LOCK("lock2",10); // 输出 1select RELEASE_LOCK("lock2"); // 输出 1select RELEASE_LOCK("lock1"); // 输出 NULL 注意，第二个 RELEASE_LOCK() 调用返回 NULL，因为锁” lock1 “自动地被第二个 GET_LOCK() 调用释放。 RELEASE_LOCK(str)释放字符串 str 命名的通过 GET_LOCK() 获得的锁。如果锁被释放，返回 1，如果锁没被这个线程锁定(在此情况下锁没被释放)返回 0，并且如果命名的锁不存在，返回 NULL。如果锁从来没有通过调用 GET_LOCK() 获得或如果它已经被释放了，锁将不存在。 BENCHMARK(count,expr) BENCHMARK() 函数重复 countTimes 次执行表达式 expr，它可以用于计时 MySQL 处理表达式有多快。结果值总是 0。意欲用于 mysql 客户，它报告查询的执行时间。 1select BENCHMARK(1000000,encode("hello","goodbye")); 报告的时间是客户端的经过时间，不是在服务器端的 CPU 时间。执行 BENCHMARK() 若干次可能是明智的，并且注意服务器机器的负载有多重来解释结果。 与 GROUP BY 子句一起使用的函数如果你在不包含 GROUP BY 子句的一个语句中使用聚合函数，它等价于聚合所有行。 COUNT(expr)返回由一个 SELECT 语句检索出来的行的非 NULL 值的数目。 1234select student.student_name,COUNT(*)from student,coursewhere student.student_id=course.student_idGROUP BY student_name; COUNT(DISTINCT expr,[expr…])返回一个不同值的数目。 1select COUNT(DISTINCT results) from student; AVG(expr)返回 expr 的平均值。 123select student_name, AVG(test_score)from studentGROUP BY student_name; MIN(expr) 和 MAX(expr)返回 expr 的最小或最大值。MIN() 和 MAX() 可以有一个字符串参数；在这种的情况下，他们返回最小或最大的字符串值。 123select student_name, MIN(test_score), MAX(test_score)from studentGROUP BY student_name; SUM(expr)返回 expr 的和。注意，如果返回的集合没有行，它返回 NULL！ STD(expr) 和 STDDEV(expr)返回 expr 标准差(deviation)。这是对 ANSI SQL 的扩展。该函数的形式STDDEV() 是提供与 Oracle 的兼容性。 BIT_OR(expr)返回 expr 里所有位的位或。计算用 64 位(BIGINT)精度进行。 BIT_AND(expr) 返回 expr 里所有位的位与。计算用 64 位(BIGINT)精度进行。]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法之动态规划]]></title>
    <url>%2F2018%2F01%2F04%2Farithmetic-dynamic-programming%2F</url>
    <content type="text"><![CDATA[基本思想动态规划算法通常用于求解具有某种最优性质的问题。在这类问题中，可能会有许多可行解。每一个解都对应于一个值，我们希望找到具有最优值的解。动态规划算法与分治法类似，其基本思想也是将待求解问题分解成若干个子问题，先求解子问题，然后从这些子问题的解得到原问题的解。与分治法不同的是，适合于用动态规划求解的问题，经分解得到子问题往往不是互相独立的。若用分治法来解这类问题，则分解得到的子问题数目太多，有些子问题被重复计算了很多次。如果我们能够保存已解决的子问题的答案，而在需要时再找出已求得的答案，这样就可以避免大量的重复计算，节省时间。我们可以用一个表来记录所有已解的子问题的答案。不管该子问题以后是否被用到，只要它被计算过，就将其结果填入表中。这就是动态规划法的基本思路。具体的动态规划算法多种多样，但它们具有相同的填表格式。 实例以 Leetcode 198 题为例， 题目，作为一名职业强盗，要抢劫一条街上的户主；每户都有一定数量的金钱，唯一的约束在于如果抢劫连续的两家，则会触发警报； 如果采用自顶向下的解法： 12345678910111213141516171819202122232425262728# -*- coding: UTF-8 -*-class Solution(object): def rob(self, nums): """ :type nums: List[int] :rtype: int """ self.result = [] for index in range(len(nums)): self.result.append(-1) return self.solve(len(nums) - 1, nums) def solve(self, range, nums): """ :range: 范围 :nums: 数据列表 """ if range &lt; 0: return 0 if self.result[range] &gt;= 0: return self.result[range] self.result[range] = max(nums[range] + self.solve(range - 2, nums), self.solve(range - 1, nums)) return self.result[range] 如果采用自下向上的解法： 123456789101112131415161718192021# -*- coding: UTF-8 -*-class Solution(object): def rob(self, nums): """ :type nums: List[int] :rtype: int """ if len(nums) == 0: return 0; if len(nums) == 1: return nums[0]; self.result = [0] * len(nums) self.result[0] = nums[0] self.result[1] = max(nums[0], nums[1]) for index in range(2, len(nums)): self.result[index] = max(nums[index] + self.result[index - 2], self.result[index -1]) return self.result[len(nums) - 1] 运行测试 12345678data = [ 155,44,52,58,250,225,109,118,211,73,137,96,137,89,174,66,134,26, 25,205,239,85,146,73,55,6,122,196,128,50,61,230,94,208,46,243, 105,81,157,89,205,78,249,203,238,239,217,212,241,242,157,79,133,66,36,165]s = Solution()print s.rob(data)]]></content>
      <categories>
        <category>Arithmetic</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Laravel 用法之 验证 模块]]></title>
    <url>%2F2018%2F01%2F02%2Flaravel-validation%2F</url>
    <content type="text"><![CDATA[本文转载[ Laravel 5.1 文档 ] 服务 —— 验证 官方API https://laravel.com/api/5.1/Illuminate/Validation.html Laravel 提供了多种方法来验证应用输入数据。默认情况下，Laravel 的控制器基类使用 ValidatesRequests trait，该 trait 提供了便利的方法通过各种功能强大的验证规则来验证输入的 HTTP 请求。 快速入门编写验证逻辑现在我们准备用验证新博客文章输入的逻辑填充 store 方法。如果你检查应用的控制器基类（App\Http\Controllers\Controller），你会发现该类使用了 ValidatesRequests trait，这个 trait 在所有控制器中提供了一个便利的 validate 方法。 validate 方法接收一个 HTTP 请求输入数据和验证规则，如果验证规则通过，代码将会继续往下执行；然而，如果验证失败，将会抛出一个异常，相应的错误响应也会自动发送给用户。在一个传统的 HTTP 请求案例中，将会生成一个重定向响应，如果是 AJAX 请求则会返回一个 JSON 响应。 要更好的理解 validate 方法，让我们回到 store 方法： 1234567891011121314/** * 存储博客文章 * * @param Request $request * @return Response */public function store(Request $request)&#123; $this-&gt;validate($request, [ 'title' =&gt; 'required|unique:posts|max:255', 'body' =&gt; 'required', ]); // 验证通过，存储到数据库...&#125; 正如你所看到的，我们只是传递输入的 HTTP 请求和期望的验证规则到 validate 方法，在强调一次，如果验证失败，相应的响应会自动生成。如果验证通过，控制器将会继续正常执行。 显示错误信息那么，如果请求输入参数没有通过给定验证规则怎么办？正如前面所提到的，Laravel 将会自动将用户重定向回上一个位置。此外，所有验证错误信息会自动一次性存放到 session。 注意我们并没有在 GET 路由中明确绑定错误信息到视图。这是因为 Laravel 总是从 session 数据中检查错误信息，而且如果有的话会自动将其绑定到视图。所以，值得注意的是每次请求的所有视图中总是存在一个 $errors 变量，从而允许你在视图中方便而又安全地使用。$errors 变量是的一个 Illuminate\Support\MessageBag 实例。 所以，在我们的例子中，验证失败的话用户将会被重定向到控制器的 create 方法，从而允许我们在视图中显示错误信息： 123456789101112131415&lt;!-- /resources/views/post/create.blade.php --&gt;&lt;h1&gt;Create Post&lt;/h1&gt;@if (count($errors) &gt; 0) &lt;div class="alert alert-danger"&gt; &lt;ul&gt; @foreach ($errors-&gt;all() as $error) &lt;li&gt;&#123;&#123; $error &#125;&#125;&lt;/li&gt; @endforeach &lt;/ul&gt; &lt;/div&gt;@endif&lt;!-- Create Post Form --&gt; AJAX请求&amp;验证在这个例子中，我们使用传统的表单来发送数据到应用。然而，很多应用使用 AJAX 请求。在 AJAX 请求中使用 validate 方法时，Laravel 不会生成重定向响应。取而代之的，Laravel 生成一个包含验证错误信息的 JSON 响应。该 JSON 响应会带上一个 HTTP 状态码 422。 其它验证方法手动创建验证器如果你不想使用 ValidatesRequests trait 的 validate 方法，可以使用 Validator 门面手动创建一个验证器实例，该门面上的 make 方法用于生成一个新的验证器实例： 12345678910111213141516171819use Validator;class PostController extends Controller&#123; // 存储新的博客文章 public function store(Request $request) &#123; $validator = Validator::make($request-&gt;all(), [ 'title' =&gt; 'required|unique:posts|max:255', 'body' =&gt; 'required', ]); if ($validator-&gt;fails()) &#123; return redirect('post/create') -&gt;withErrors($validator) -&gt;withInput(); &#125; // 存储博客文章... &#125;&#125; 传递给 make 方法的第一个参数是需要验证的数据，第二个参数是要应用到数据上的验证规则。 检查请求是够通过验证后，可以使用 withErrors 方法将错误数据一次性存放到 session，使用该方法时，$errors 变量重定向后自动在视图间共享，从而允许你轻松将其显示给用户，withErrors 方法接收一个验证器、或者一个MessageBag，又或者一个 PHP 数组。 命令错误包如果你在单个页面上有多个表单，可能需要命名 MessageBag，从而允许你为指定表单获取错误信息。只需要传递名称作为第二个参数给 withErrors 即可： 1return redirect('register')-&gt;withErrors($validator, 'login'); 然后你就可以从 $errors 变量中访问命名的 MessageBag 实例： 1&#123;&#123; $errors-&gt;login-&gt;first('email') &#125;&#125; 验证钩子之后验证器允许你在验证完成后添加回调，这种机制允许你轻松执行更多验证，甚至添加更多错误信息到消息集合。使用验证器实例上的 after 方法即可： 1234567891011$validator = Validator::make(...);$validator-&gt;after(function($validator) &#123; if ($this-&gt;somethingElseIsInvalid()) &#123; $validator-&gt;errors()-&gt;add('field', 'Something is wrong with this field!'); &#125;&#125;);if ($validator-&gt;fails()) &#123; //&#125; 处理错误信息调用 Validator 实例上的 errors 方法之后，将会获取一个 Illuminate\Support\MessageBag 实例，该实例中包含了多种处理错误信息的便利方法。 获取某字段的第一条错误信息 12$messages = $validator-&gt;errors();echo $messages-&gt;first('email'); 获取指定字段的所有错误信息 123foreach ($messages-&gt;get('email') as $message) &#123; //&#125; 获取所有字段的所有错误信息 123foreach ($messages-&gt;all() as $message) &#123; //&#125; 判断消息中是否存在某字段的错误信息 123if ($messages-&gt;has('email')) &#123; //&#125; 获取指定格式的错误信息 1echo $messages-&gt;first('email', '&lt;p&gt;:message&lt;/p&gt;'); 获取指定格式的所有错误信息 123foreach ($messages-&gt;all('&lt;li&gt;:message&lt;/li&gt;') as $message) &#123; //&#125; 自定义错误消息如果需要的话，你可以使用自定义错误信息替代默认的，有多种方法来指定自定义信息。首先，你可以传递自定义信息作为第三方参数给 Validator::make 方法： 12345$messages = [ 'required' =&gt; 'The :attribute field is required.',];$validator = Validator::make($input, $rules, $messages); 在本例中，:attribute 占位符将会被验证时实际的字段名替换，你还可以在验证消息中使用其他占位符，例如： 123456$messages = [ 'same' =&gt; 'The :attribute and :other must match.', 'size' =&gt; 'The :attribute must be exactly :size.', 'between' =&gt; 'The :attribute must be between :min - :max.', 'in' =&gt; 'The :attribute must be one of the following types: :values',]; 为给定属性指定自定义信息有时候你可能只想为特定字段指定自定义错误信息，可以通过”.”来实现，首先指定属性名，然后是规则： 123$messages = [ 'email.required' =&gt; 'We need to know your e-mail address!',]; 在语言文件中指定自定义消息在很多案例中，你可能想要在语言文件中指定属性特定自定义消息而不是将它们直接传递给 Validator。要实现这个，添加消息到 resources/lang/xx/validation.php 语言文件的 custom 数组： 12345'custom' =&gt; [ 'email' =&gt; [ 'required' =&gt; 'We need to know your e-mail address!', ],],]]></content>
      <categories>
        <category>Laravel</category>
      </categories>
      <tags>
        <tag>Laravel-5.1</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel 用法之 测试 模块]]></title>
    <url>%2F2018%2F01%2F02%2Flaravel-test%2F</url>
    <content type="text"><![CDATA[本文转载[ Laravel 5.1 文档 ] 服务 —— 测试 简介Laravel 植根于测试，实际上，内置使用 PHPUnit 对测试提供支持是即开即用的，并且 phpunit.xml 文件已经为应用设置好了。框架还提供了方便的帮助方法允许你对应用进行富有表现力的测试。 tests 目录中提供了一个 ExampleTest.php 文件，安装完新的 Laravel 应用后，只需简单在命令行运行 phpunit 来运行测试。 测试环境运行测试的时候，Laravel 自动设置配置环境为 testing。Laravel 在测试时自动配置 session 和 cache 驱动为数组驱动，这意味着测试时不会持久化存储 session 和 cache。 如果需要的话你可以自由创建其它测试环境配置。testing 环境变量可以在 phpunit.xml 文件中配置。 定义&amp;运行测试要创建一个测试用例，只需简单在 tests 目录创建一个新的测试文件，测试类应该继承 TestCase，然后你可以使用 PHPUnit 定义测试方法。要运行测试，简单从终端执行 phpunit 命令即可： 12345class FooTest extends TestCase &#123; public function testSomethingIsTrue() &#123; $this-&gt;assertTrue(true); &#125;&#125; 说明： 如果你在测试类中定义自己的 setUp 方法，确保在其中调用 parent::setUp。 应用测试Laravel 为生成 HTTP 请求、测试输出、以及填充表单提供了平滑的 API。举个例子，我们看下 tests 目录下包含的 ExampleTest.php 文件： 123456789use Illuminate\Foundation\Testing\WithoutMiddleware;use Illuminate\Foundation\Testing\DatabaseTransactions;class ExampleTest extends TestCase&#123; // 基本功能测试示例 public function testBasicExample() &#123; $this-&gt;visit('/')-&gt;see('Laravel 5')-&gt;dontSee('Rails'); &#125;&#125; visit 方法生成了一个 GET 请求，see 方法对我们从应用返回响应中应该看到的给定文本进行断言。dontSee 方法对给定文本没有从应用响应中返回进行断言。在 Laravel 中这是最基本的有效应用测试。 与应用交互点击链接在本测试中，我们将为应用生成请求，在返回的响应中“点击”链接，然后对访问URI进行断言。例如，假定响应中有一个“关于我们”的链接： 1&lt;a href="/about-us"&gt;About Us&lt;/a&gt; 现在，让我们编写一个测试点击链接并断言用户访问页面是否正确： 12345public function testBasicExample()&#123; $this-&gt;visit('/') -&gt;click('About Us') -&gt;seePageIs('/about-us');&#125; 处理表单Laravel还为处理表单提供了多个方法。type, select, check, attach, 和 press 方法允许你与所有表单输入进行交互。例如，我们假设这个表单存在于应用注册页面： 123456789101112131415&lt;form action="/register" method="POST"&gt; &#123;!! csrf_field() !!&#125; &lt;div&gt; Name: &lt;input type="text" name="name"&gt; &lt;/div&gt; &lt;div&gt; &lt;input type="checkbox" value="yes" name="terms"&gt; Accept Terms &lt;/div&gt; &lt;div&gt; &lt;input type="submit" value="Register"&gt; &lt;/div&gt;&lt;/form&gt; 我们可以编写测试完成表单并检查结果： 1234567public function testNewUserRegistration()&#123; $this-&gt;visit('/register') -&gt;type('Taylor', 'name') -&gt;check('terms') -&gt;press('Register') -&gt;seePageIs('/dashboard');&#125; 当然，如果你的表单包含其他输入比如单选按钮或下拉列表，也可以轻松填写这些字段类型。这里是所有表单操作方法列表： 方法 描述 $this-&gt;type($text, $elementName) “Type” 文本到给定字段 $this-&gt;select($value, $elementName) “Select” 单选框或下拉列表 $this-&gt;check($elementName) “Check” 复选框 $this-&gt;attach($pathToFile, $elementName) “Attach” 文件到表单 $this-&gt;press($buttonTextOrElementName) “Press” 给定文本或name的按钮 处理附件如果表单包含 file 输入类型，可以使用 attach 方法添加文件到表单： 1234567public function testPhotoCanBeUploaded()&#123; $this-&gt;visit('/upload') -&gt;name('File Name', 'name') -&gt;attach($absolutePathToFile, 'photo') -&gt;press('Upload') -&gt;see('Upload Successful!');&#125; 测试 JSON ApiLaravel 还提供多个帮助函数用于测试 JSON API 及其响应。例如，get, post, put, patch, 和 delete 方法用于通过多种 HTTP 请求方式发出请求。你还可以轻松传递数据和头到这些方法。作为开始，我们编写测试来生成 POST 请求到 /user 并断言返回的数据是否是 JSON 格式： 12345678910class ExampleTest extends TestCase&#123; // 基本功能测试示例 public function testBasicExample() &#123; $this-&gt;post('/user', ['name' =&gt; 'Sally']) -&gt;seeJson([ 'created' =&gt; true, ]); &#125;&#125; seeJson 方法将给定数组转化为 JSON，然后验证应用返回的整个 JSON 响应中的 JSON 片段。因此，如果在 JSON 响应中有其他属性，只要给定片段存在的话测试依然会通过。 如果你想要验证给定数组和应用返回的 JSON 能够精确匹配，使用 seeJsonEquals 方法： 123456public function testBasicExample() &#123; $this-&gt;post('/user', ['name' =&gt; 'Sally']) -&gt;seeJsonEquals([ 'created' =&gt; true, ]);&#125; Session 认证Laravel 提供个多个帮助函数在测试期间处理 session，首先，可以使用 withSession 方法设置 session 值到给定数组。这通常在测试请求前获取 session 数据时很有用： 12345class ExampleTest extends TestCase&#123; public function testApplication() &#123; $this-&gt;withSession(['foo' =&gt; 'bar'])-&gt;visit('/'); &#125;&#125; 当然，session 的通常用于操作用户状态，例如认证用户。帮助函数 actingAs 提供了认证给定用户为当前用户的简单方法，例如，我们使用模型工厂生成和认证用户： 12345678910111213&lt;?phpclass ExampleTest extends TestCase&#123; public function testApplication() &#123; $user = factory('App\User')-&gt;create(); $this-&gt;actingAs($user) -&gt;withSession(['foo' =&gt; 'bar']) -&gt;visit('/') -&gt;see('Hello, '.$user-&gt;name); &#125;&#125; 禁止中间件测试应用时，为某些测试禁止中间件很方便。这种机制允许你将路由和控制器与中间件孤立开来做测试，Laravel 包含了一个简单的 WithoutMiddleware trait，可以使用该 trait 自动在测试类中禁止所有中间件： 123456use Illuminate\Foundation\Testing\WithoutMiddleware;class ExampleTest extends TestCase&#123; use WithoutMiddleware; //&#125; 如果你只想在某些方法中禁止中间件，可以在测试方法中调用 withoutMiddleware 方法： 12345678class ExampleTest extends TestCase&#123; // 基本功能测试示例 public function testBasicExample() &#123; $this-&gt;withoutMiddleware(); $this-&gt;visit('/')-&gt;see('Laravel 5'); &#125;&#125; 自定义 Http 请求如果你想要在应用中生成自定义 HTTP 请求并获取完整的 Illuminate\Http\Response 对象，可以使用 call 方法： 1234public function testApplication()&#123; $response = $this-&gt;call('GET', '/'); $this-&gt;assertEquals(200, $response-&gt;status());&#125; 如果你要生成 POST, PUT, 或者 PATCH 请求可以在请求中传入输入数据数组，在路由或控制器中可以通过 Request 实例访问请求数据： 1$response = $this-&gt;call('POST', '/user', ['name' =&gt; 'Taylor']); 处理数据库Laravel 还提供了多种有用的工具让测试数据库驱动的应用更加简单。首先，你可以使用帮助函数 seeInDatabase 来断言数据库中的数据是否和给定数据集合匹配。例如，如果你想要通过 email 值为 `sally@example.com的条件去数据表users` 查询是否存在该记录 ，我们可以这样做： 1234public function testDatabase()&#123; // 调用应用... $this-&gt;seeInDatabase('users', ['email' =&gt; 'sally@foo.com']);&#125; 每次测试后重置数据库每次测试后重置数据库通常很有用，这样的话上次测试的数据不会影响下一次测试。 使用迁移一种方式是每次测试后回滚数据库并在下次测试前重新迁移。Laravel 提供了一个简单的 DatabaseMigrations trait 来自动为你处理。在测试类上简单使用该 trait 如下： 1234567891011121314&lt;?phpuse Illuminate\Foundation\Testing\WithoutMiddleware;use Illuminate\Foundation\Testing\DatabaseMigrations;use Illuminate\Foundation\Testing\DatabaseTransactions;class ExampleTest extends TestCase&#123; use DatabaseMigrations; // 基本功能测试示例 public function testBasicExample() &#123; $this-&gt;visit('/')-&gt;see('Laravel 5'); &#125;&#125; 使用事务另一种方式是将每一个测试用例包裹到一个数据库事务中，Laravel 提供了方便的 DatabaseTransactions trait自动为你处理： 1234567891011121314&lt;?phpuse Illuminate\Foundation\Testing\WithoutMiddleware;use Illuminate\Foundation\Testing\DatabaseMigrations;use Illuminate\Foundation\Testing\DatabaseTransactions;class ExampleTest extends TestCase&#123; use DatabaseTransactions; // 基本功能测试示例 public function testBasicExample() &#123; $this-&gt;visit('/')-&gt;see('Laravel 5'); &#125;&#125; 模型工厂测试时，通常需要在执行测试前插入新数据到数据库。在创建测试数据时，Laravel 允许你使用”factories ”为每个 Eloquent 模型定义默认的属性值集合，而不用手动为每一列指定值。作为开始，我们看一下 database/factories/ModelFactory.php 文件，该文件包含了一个工厂定义： 12345678$factory-&gt;define(App\User::class, function (Faker\Generator $faker) &#123; return [ 'name' =&gt; $faker-&gt;name, 'email' =&gt; $faker-&gt;email, 'password' =&gt; bcrypt(str_random(10)), 'remember_token' =&gt; str_random(10), ];&#125;); 在闭包中，作为工厂定义，我们返回该模型上所有属性默认测试值。该闭包接收PHP 库 Faker 实例，从而允许你方便地为测试生成多种类型的随机数据。 当然，你可以添加更多工厂到 ModelFactory.php 文件。 多个工厂类型有时候你可能想要为同一个 Eloquent 模型类生成多个工厂，例如，除了正常用户外可能你想要为“管理员”用户生成一个工厂，你可以使用 defineAs方法定义这些工厂： 123456789$factory-&gt;defineAs(App\User::class, 'admin', function ($faker) &#123; return [ 'name' =&gt; $faker-&gt;name, 'email' =&gt; $faker-&gt;email, 'password' =&gt; str_random(10), 'remember_token' =&gt; str_random(10), 'admin' =&gt; true, ];&#125;); 你可以使用 raw 方法获取基本属性而不用重复基本用户工厂中的所有属性，获取这些属性后，只需将你要求的额外值增补进去即可： 1234$factory-&gt;defineAs(App\User::class, 'admin', function ($faker) use ($factory) &#123; $user = $factory-&gt;raw(App\User::class); return array_merge($user, ['admin' =&gt; true]);&#125;); 在测试中使用工厂定义好工厂后，可以在测试或数据库填充文件中通过全局的 factory 方法使用它们来生成模型实例，所以，让我们看一些生成模型的例子，首先，我们使用 make 方法，该方法创建模型但不将其保存到数据库： 1234public function testDatabase()&#123; $user = factory(App\User::class)-&gt;make(); // 用户模型测试...&#125; 如果你想要覆盖模型的一些默认值，可以传递数组值到 make 方法。只有指定值被替换，其他数据保持不变： 123$user = factory(App\User::class)-&gt;make([ 'name' =&gt; 'Abigail',]); 还可以创建多个模型集合或者创建给定类型的集合： 123456// 创建3个 App\User 实例...$users = factory(App\User::class, 3)-&gt;make();// 创建1个 App\User "admin" 实例...$user = factory(App\User::class, 'admin')-&gt;make();// 创建3个 App\User "admin" 实例...$users = factory(App\User::class, 'admin', 3)-&gt;make(); 持久化工厂模型create 方法不仅能创建模型实例，还可以使用 Eloquent 的 save 方法将它们保存到数据库： 1234public function testDatabase()&#123; $user = factory(App\User::class)-&gt;create(); //用户模型测试...&#125; 你仍然可以通过传递数组到 create 方法覆盖模型上的属性： 123$user = factory(App\User::class)-&gt;create([ 'name' =&gt; 'Abigail',]); 添加关联关系到模型你甚至可以持久化多个模型到数据库。在本例中，我们添加一个关联到创建的模型，使用create方法创建多个模型的时候，会返回一个 Eloquent 集合实例，从而允许你使用集合提供的所有便利方法，例如 each： 12345$users = factory(App\User::class, 3) -&gt;create() -&gt;each(function($u) &#123; $u-&gt;posts()-&gt;save(factory(App\Post::class)-&gt;make()); &#125;); 模拟模拟事件如果你在重度使用 Laravel 的时间系统，可能想要在测试时模拟特定事件。例如，如果你在测试用户注册，你可能不想所有 UserRegistered 的时间处理器都被触发，因为这可能会发送欢迎邮件，等等。 Laravel 提供可一个方便的 expectsEvents 方法来验证期望的事件被触发，但同时阻止该事件的其它处理器运行： 12345678910class ExampleTest extends TestCase &#123; public function testUserRegistration() &#123; $this-&gt;expectsEvents(App\Events\UserRegistered::class); // 测试用户注册代码... &#125; &#125; 如果你想要阻止所有事件运行，可以使用 withoutEvents 方法： 12345678910class ExampleTest extends TestCase &#123; public function testUserRegistration() &#123; $this-&gt;withoutEvents(); // 测试用户注册代码... &#125; &#125; 模拟队列任务有时候，你可能想要在请求时简单测试控制器分发的指定任务，这允许你孤立的测试路由/控制器——将其从任务逻辑中分离出去，当然，接下来你可以在一个独立测试类中测试任务本身。 Laravel 提供了一个方便的 expectsJobs 方法来验证期望的任务被分发，但该任务本身不会被测试： 1234567class ExampleTest extends TestCase &#123; public function testPurchasePodcast() &#123; $this-&gt;expectsJobs(App\Jobs\PurchasePodcast::class); // 测试购买播客代码... &#125;&#125; 注意：这个方法只检查通过 DispatchesJobs trait 分发方法分发的任务，并不检查直接通过 Queue::push 分发的任务。 模拟门面测试的时候，你可能经常想要模拟 Laravel 门面的调用，例如，看看下面的控制器动作： 123456class UserController extends Controller&#123; // 显示应用用户列表 public function index() &#123; $value = Cache::get('key'); &#125;&#125; 我们可以通过使用 shouldReceive 方法模拟 Cache 门面的调用，该方法返回一个 Mockery 模拟的实例，由于门面通过 Laravel 服务容器解析和管理，它们比通常的静态类更具有可测试性。例如，我们来模拟 Cache 门面的调用： 123456789101112&lt;?phpclass FooTest extends TestCase &#123; public function testGetIndex() &#123; Cache::shouldReceive('get') -&gt;once() -&gt;with('key') -&gt;andReturn('value'); $this-&gt;visit('/users')-&gt;see('value'); &#125;&#125; 注意：不要模拟 Request 门面，取而代之地，在测试时传递输入到 HTTP 帮助函数如 call 和 post。]]></content>
      <categories>
        <category>Laravel</category>
      </categories>
      <tags>
        <tag>Laravel-5.1</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel 用法之 Artisan 控制台 模块]]></title>
    <url>%2F2017%2F12%2F29%2Flaravel-console%2F</url>
    <content type="text"><![CDATA[本文转载[ Laravel 5.1 文档 ] 服务 —— Artisan 控制台 官方 API 地址 https://laravel.com/api/5.1/Illuminate/Console/Command.html; Artisan 是 Laravel 自带的命令行接口名称，它为你在开发过程中提供了很多有用的命令。通过强大的 Symfony Console 组件驱动。想要查看所有可用的 Artisan 命令，可使用 list 命令： 1php artisan list 编写命令示例1234567891011121314151617181920212223namespace App\Console\Commands;use App\User;use App\DripEmailer;use Illuminate\Console\Command;use Illuminate\Foundation\Inspiring;class Inspire extends Command &#123; // 控制台命令名称 protected $signature = 'email:send &#123;user&#125;'; // 控制台命令描述 protected $description = 'Send drip e-mails to a user'; // 创建新的命令实例， 可以依赖注入实例 public function __construct() &#123; parent::__construct(); &#125; // 执行控制台命令 public function handle() &#123; &#125;&#125; 命令IO定义期望输入编写控制台命令的时候，通常通过参数和选项收集用户输入，Laravel 使这项操作变得很方便：在命令中使用 signature 属性来定义我们期望的用户输入。signature 属性通过一个优雅的、路由风格的语法允许你定义命令的名称、参数以及选项。所有用户提供的参数和选项都包含在大括号里： 123456789101112131415// 控制台命令名称protected $signature = 'email:send &#123;user&#125;';/** * // 选项参数... * email:send &#123;user?&#125; * // 带默认值的选项参数... * email:send &#123;user=foo&#125; * // 选项， 如果 `--queue` 开关被传递，其值是 `true`，否则其值是 `false`： * email:send &#123;user&#125; &#123;--queue&#125; * // 选项值由用户来分配 * email:send &#123;user&#125; &#123;--queue=&#125; * // 选项值有默认值 * email:send &#123;user&#125; &#123;--queue=default&#125; */ 你可以通过：分隔参数和描述来分配描述给输入参数和选项 1234// 控制台命令名称protected $signature = 'email:send &#123;user : The ID of the user&#125; &#123;--queue= : Whether the job should be queued&#125;'; 获取输入在命令被执行的时候，很明显，你需要访问命令获取的参数和选项的值。使用 argument 和 option 方法即可实现： 要获取参数的值，通过 argument 方法： 1234$userId = $this-&gt;argument('user');// 获取所有参数值$arguments = $this-&gt;argument(); 选项值和参数值的获取一样简单，使用 option 方法，同 argument 一样如果要获取所有选项值，可以调用不带参数的 option 方法： 1234// 获取指定选项...$queueName = $this-&gt;option('queue');// 获取所有选项...$options = $this-&gt;option(); 如果参数或选项不存在，返回 null。 输入提示secret 和 ask命令除了显示输出之外，你可能还要在命令执行期间要用户提供输入。 ask 方法将会使用给定问题提示用户，接收输入，然后返回用户输入到命令： 1$name = $this-&gt;ask('What is your name?'); secret 方法和 ask 方法类似，但用户输入在终端对他们而言是不可见的，这个方法在问用户一些敏感信息如密码时很有用： 1$password = $this-&gt;secret('What is the password?'); confirm命令如果你需要让用户确认信息，可以使用 confirm 方法，默认情况下，该方法返回 false，如果用户输入 y，则该方法返回true： 12if ($this-&gt;confirm('Do you wish to continue? [y|N]')) &#123;&#125; anticipate 和 choice命令 anticipate 方法可用于为可能的选项提供自动完成功能，用户仍然可以选择答案，而不管这些选择： 1$name = $this-&gt;anticipate('What is your name?', ['Taylor', 'Dayle']); 如果你需要给用户预定义的选择，可以使用 choice 方法。用户选择答案的索引，但是返回给你的是答案的值。如果用户什么都没选的话你可以设置默认返回的值： 1$name = $this-&gt;choice('What is your name?', ['Taylor', 'Dayle'], false); 编写输出信息要将输出发送到控制台，使用 info, comment, question 和 error 方法，每个方法都会使用相应的 ANSI 颜色以作标识。 要显示一条信息消息给用户，使用 info 方法。通常，在终端显示为绿色： 1$this-&gt;info('Display this on the screen'); 要显示一条错误消息，使用 error 方法。错误消息文本通常是红色： 1$this-&gt;error('Something went wrong!'); 表格布局table 方法使输出多行/列格式的数据变得简单，只需要将头和行传递给该方法，宽度和高度将基于给定数据自动计算： 123$headers = ['Name', 'Email'];$users = App\User::all(['name', 'email'])-&gt;toArray();$this-&gt;table($headers, $users); 进度条对需要较长时间运行的任务，显示进度指示器很有用，使用该输出对象，我们可以开始、前进以及停止该进度条。在开始进度时你必须定义步数，然后每走一步进度条前进一格： 12345678910$users = App\User::all();$this-&gt;output-&gt;progressStart(count($users));foreach ($users as $user) &#123; $this-&gt;performTask($user); $this-&gt;output-&gt;progressAdvance();&#125;$this-&gt;output-&gt;progressFinish(); 注册命令在 Kernel 中注册命令编写完成后，需要注册到 Artisan 才可以使用，这可以在 app/Console/Kernel.php 文件中完成。 在该文件中，你会在 commands 属性中看到一个命令列表，要注册你的命令，只需将其加到该列表中即可。当 Artisan 启动的时候，该属性中列出的命令将会被服务容器解析被注册到 Artisan： 123protected $commands = [ 'App\Console\Commands\SendEmails']; 在 ServiceProvider 中注册1234567protected $commands = [ ClearInvalidProcurementOrder::class,]public function register() &#123; $this-&gt;commands($this-&gt;commands);&#125; 通过代码调用命令有时候你可能希望在 CLI 之外执行 Artisan 命令，比如，你可能希望在路由或控制器中触发 Artisan 命令，你可以使用 Artisan 门面上的 call 方法来完成这个。call 方法接收被执行的命令名称作为第一个参数，命令参数数组作为第二个参数，退出代码被返回： 12345Route::get('/foo', function () &#123; $exitCode = Artisan::call('email:send', [ 'user' =&gt; 1, '--queue' =&gt; 'default' ]);&#125;); 使用 Artisan 上的 queue 方法，你甚至可以将 Artisan 命令放到队列中，这样它们就可以通过后台的队列工作者来处理： 12345Route::get('/foo', function () &#123; Artisan::queue('email:send', [ 'user' =&gt; 1, '--queue' =&gt; 'default' ]);&#125;); 如果你需要指定不接收字符串的选项值，例如 migrate:refresh 命令上的 --force 标识，可以传递布尔值true 或 false： 123$exitCode = Artisan::call('migrate:refresh', [ '--force' =&gt; true,]); 有时候你希望从一个已存在的 Artisan 命令中调用其它命令。你可以通过使用 call 方法开实现这一目的。call 方法接收命令名称和数组形式的命令参数： 123456// 执行控制台命令public function handle()&#123; $this-&gt;call('email:send', [ 'user' =&gt; 1, '--queue' =&gt; 'default' ]);&#125; 如果你想要调用其它控制台命令并阻止其所有输出，可以使用 callSilent 方法。callSilent 方法和 call 方法用法一致： 123$this-&gt;callSilent('email:send', [ 'user' =&gt; 1, '--queue' =&gt; 'default']);]]></content>
      <categories>
        <category>Laravel</category>
      </categories>
      <tags>
        <tag>Laravel-5.1</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel 用法之 任务调度 模块]]></title>
    <url>%2F2017%2F12%2F27%2Flaravel-schedule%2F</url>
    <content type="text"><![CDATA[本文转载[ Laravel 5.1 文档 ] 服务 —— 任务调度 官方 API 地址 https://laravel.com/api/5.1/Illuminate/Console/Scheduling.html 在以前，开发者需要为每一个需要调度的任务编写一个 Cron 条目，这是很让人头疼的事。你的任务调度不在源码控制中，你必须使用 SSH 登录到服务器然后添加这些 Cron 条目。Laravel 命令调度器允许你平滑而又富有表现力地在 Laravel 中定义命令调度，并且服务器上只需要一个 Cron 条目即可。 任务调度定义在 app/Console/Kernel.php 文件的 schedule 方法中，该方法中已经包含了一个示例。你可以自由地添加你需要的调度任务到 Schedule 对象。 1234567891011121314use DB;use Illuminate\Console\Scheduling\Schedule;use Illuminate\Foundation\Console\Kernel as ConsoleKernel;class Kernel extends ConsoleKernel&#123; // 定义应用的命令调度 protected function schedule(Schedule $schedule) &#123; $schedule-&gt;call(function () &#123; DB::table('recent_users')-&gt;delete(); &#125;)-&gt;daily(); &#125;&#125; 除了调度闭包调用外，还可以调度 Artisan 命令和操作系统命令。例如，可以使用 command 方法来调度一个 Artisan 命令： 1$schedule-&gt;command('emails:send --force')-&gt;daily(); exec 命令可用于发送命令到操作系统： 1$schedule-&gt;exec('node /home/forge/script.js')-&gt;daily(); 调度常用方法 方法 描述 -&gt;cron(&#39;* * * * *&#39;); 在自定义Cron调度上运行任务 -&gt;everyMinute(); 每分钟运行一次任务 -&gt;everyFiveMinutes(); 每五分钟运行一次任务 -&gt;everyTenMinutes(); 每十分钟运行一次任务 -&gt;everyThirtyMinutes(); 每三十分钟运行一次任务 -&gt;hourly(); 每小时运行一次任务 -&gt;daily(); 每天凌晨零点运行任务 -&gt;dailyAt(&#39;13:00&#39;); 每天13:00运行任务 -&gt;twiceDaily(1, 13); 每天1:00 &amp; 13:00运行任务 -&gt;weekly(); 每周运行一次任务 -&gt;monthly(); 每月运行一次任务 这些方法可以和额外的约束一起联合起来创建一周特定时间运行的更加细粒度的调度，例如，要每周一调度一个命令： 123$schedule-&gt;call(function () &#123; // 每周星期一13:00运行一次...&#125;)-&gt;weekly()-&gt;mondays()-&gt;at('13:00'); 方法 描述 -&gt;weekdays(); 只在工作日运行任务 -&gt;sundays(); 每个星期天运行任务 -&gt;mondays(); 每个星期一运行任务 -&gt;tuesdays(); 每个星期二运行任务 -&gt;wednesdays(); 每个星期三运行任务 -&gt;thursdays(); 每个星期四运行任务 -&gt;fridays(); 每个星期五运行任务 -&gt;saturdays(); 每个星期六运行任务 -&gt;when(Closure); 基于特定测试运行任务 基于测试的约束条件when 方法用于限制任务在通过给定测试之后运行。换句话说，如果给定闭包返回 true，只要没有其它约束条件阻止任务运行，该任务就会执行： 123$schedule-&gt;command('emails:send')-&gt;daily()-&gt;when(function () &#123; return true;&#125;); 避免任务重叠默认情况下，即使前一个任务仍然在运行调度任务也会运行，要避免这样的情况，可使用 withoutOverlapping 方法： 1$schedule-&gt;command('emails:send')-&gt;withoutOverlapping(); 在本例中，Artisan 命令 emails:send 每分钟都会运行，如果该命令没有在运行的话。如果你的任务在执行时经常大幅度的变化，那么 withoutOverlapping 方法就非常有用，你不必再去预测给定任务到底要消耗多长时间。 任务输出Laravel 调度器为处理调度任务输出提供了多个方便的方法。首先，使用 sendOutputTo 方法，你可以发送输出到文件以便稍后检查： 1$schedule-&gt;command('emails:send')-&gt;daily()-&gt;sendOutputTo($filePath); 使用 emailOutputTo 方法，你可以将输出发送到电子邮件，注意输出必须首先通过 sendOutputTo 方法发送到文件。还有，使用电子邮件发送任务输出之前，应该配置 Laravel 的电子邮件服务： 1$schedule-&gt;command('foo')-&gt;daily()-&gt;sendOutputTo($filePath)-&gt;emailOutputTo('foo@example.com'); 注意：emailOutputTo 和 sendOutputTo 方法只对 command 方法有效，不支持 call 方法。 任务钩子使用 before 和 after 方法，你可以指定在调度任务完成之前和之后要执行的代码： 1234567$schedule-&gt;command('emails:send')-&gt;daily() -&gt;before(function () &#123; // Task is about to start... &#125;) -&gt;after(function () &#123; // Task is complete... &#125;); ping Url 使用pingBefore 和 thenPing 方法，调度器可以在任务完成之前和之后自动 ping 给定的 URL。该方法在通知外部服务时很有用，例如Laravel Envoyer，在调度任务开始或完成的时候： 1$schedule-&gt;command('emails:send')-&gt;daily()-&gt;pingBefore($url)-&gt;thenPing($url); 使用 pingBefore($url) 或 thenPing($url) 特性需要安装 HTTP 库 Guzzle，可以在 composer.json 文件中添加如下行来安装 Guzzle 到项目： 1"guzzlehttp/guzzle": "~5.3|~6.0" ServiceProvider 中注册如果想在 ServiceProvider 中注册任务调度命令，需要利用 ServiceProvider 的 boot 回调函数执行注册； 12345678910111213use Illuminate\Foundation\Support\Providers\RouteServiceProviderclass ShelfServiceProvider extends RouteServiceProvider &#123; public function boot() &#123; $this-&gt;app-&gt;booted(function () &#123; $schedule = $this-&gt;app-&gt;make(Schedule::class); $schedule-&gt;command('schedule:check_advertising_position_status')-&gt;dailyAt('04:00'); &#125;); &#125;&#125;]]></content>
      <categories>
        <category>Laravel</category>
      </categories>
      <tags>
        <tag>Laravel-5.1</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel 用法之 Queue 模块]]></title>
    <url>%2F2017%2F12%2F27%2Flaravel-queue%2F</url>
    <content type="text"><![CDATA[本文转载[ Laravel 5.1 文档 ] 服务 —— 队列 官方 API 地址 https://laravel.com/api/5.1/Illuminate/Queue.html Laravel队列服务为各种不同的后台队列提供了统一的 API。队列允许你推迟耗时任务（例如发送邮件）的执行，从而大幅提高web请求速度。 队列配置文件存放在 config/queue.php。在该文件中你将会找到框架自带的每一个队列驱动的连接配置，包括数据库、Beanstalkd、 IronMQ、 Amazon SQS、 Redis 以及同步（本地使用）驱动。其中还包含了一个 null 队列驱动以拒绝队列任务。 任务类任务类非常简单，正常情况下只包含一个当队列处理该任务时被执行的 handle 方法，让我们看一个任务类的例子： 12345678910111213141516171819202122use App\Jobs\Job;use Illuminate\Queue\SerializesModels;use Illuminate\Queue\InteractsWithQueue;use Illuminate\Contracts\Bus\SelfHandling;use Illuminate\Contracts\Queue\ShouldQueue;class SendReminderEmail extends Job implements SelfHandling, ShouldQueue&#123; use InteractsWithQueue, SerializesModels; protected $user; // 创建一个新的任务实例 public function __construct(User $user) &#123; $this-&gt;user = $user; &#125; // 执行任务 public function handle() &#123; &#125;&#125; 在本例中，注意我们能够直接将 Eloquent 模型传递到对列任务的构造函数中。由于该任务使用了SerializesModels trait，Eloquent 模型将会在任务被执行是优雅地序列化和反序列化。如果你的队列任务在构造函数中接收 Eloquent 模型，只有模型的主键会被序列化到队列，当任务真正被执行的时候，队列系统会自动从数据库中获取整个模型实例。这对应用而言是完全透明的，从而避免序列化整个 Eloquent 模型实例引起的问题。 handle 方法在任务被队列处理的时候被调用，注意我们可以在任务的 handle 方法中对依赖进行类型提示。Laravel 服务容器会自动注入这些依赖。 出错 如果任务被处理的时候抛出异常，则该任务将会被自动释放回队列以便再次尝试执行。任务会持续被释放直到尝试次数达到应用允许的最大次数。最大尝试次数通过 Artisan 任务 queue:listen 或 queue:work 上的 --tries 开关来定义。 手动释放任务如果你想要手动释放任务，生成的任务类中自带的 InteractsWithQueue trait 提供了释放队列任务的 release 方法，该方法接收一个参数——同一个任务两次运行之间的等待时间： 12345public function handle(Mailer $mailer) &#123; if (condition) &#123; $this-&gt;release(10); &#125;&#125; 检查尝试运行次数正如上面提到的，如果在任务处理期间发生异常，任务会自动释放回队列中，你可以通过attempts方法来检查该任务已经尝试运行次数： 1234public function handle(Mailer $mailer) &#123; if ($this-&gt;attempts() &gt; 3) &#123; &#125;&#125; 推送任务到队列基本使用默认的 Laravel 控制器位于 app/Http/Controllers/Controller.php 并使用了 DispatchesJobs trait。该 trait 提供了一些允许你方便推送任务到队列的方法，例如 dispatch 方法： 1234567891011121314151617use App\Jobs\SendReminderEmail;use App\Http\Controllers\Controller;class UserController extends Controller &#123; // 发送提醒邮件到指定用户 public function sendReminderEmail(Request $request, $id) &#123; $user = User::findOrFail($id); $this-&gt;dispatch(new SendReminderEmail($user)); &#125; // 处理失败任务 public function failed() &#123; parent::failed(); // Called when the job is failing... &#125;&#125; 当然，有时候你想要从应用中路由或控制器之外的某些地方分发任务，因为这个原因，你可以在应用的任何类中包含DispatchesJobs trait，从而获取对分发方法的访问，举个例子，下面是使用该trait的示例类： 12345use Illuminate\Foundation\Bus\DispatchesJobs;class ExampleClass&#123; use DispatchesJobs;&#125; 为任务指定队列 1234567891011use App\Jobs\SendReminderEmail;use App\Http\Controllers\Controller;class UserController extends Controller &#123; // 发送提醒邮件到指定用户 public function sendReminderEmail(Request $request, $id) &#123; $user = User::findOrFail($id); $this-&gt;dispatch((new SendReminderEmail($user))-&gt;onQueue('emails')); &#125;&#125; 延迟任务有时候你可能想要延迟队列任务的执行。例如，你可能想要将一个注册15分钟后给消费者发送提醒邮件的任务放到队列中，可以通过使用任务类上的 delay 方法来实现，该方法由 Illuminate\Bus\Queueable trait 提供： 1234567891011use App\Jobs\SendReminderEmail;use App\Http\Controllers\Controller;class UserController extends Controller &#123; // 发送提醒邮件到指定用户 public function sendReminderEmail(Request $request, $id) &#123; $user = User::findOrFail($id); $this-&gt;dispatch((new SendReminderEmail($user))-&gt;delay(15 * 60)); &#125;&#125; 从请求中分发任务映射HTTP请求变量到任务中很常见，Laravel提供了一些帮助函数让这种实现变得简单，而不用每次请求时手动执行映射。让我们看一下 DispatchesJobs trait上的dispatchFrom方法。默认情况下，该trait包含在Laravel控制器基类中： 1234public function processOrder(Request $request, $id) &#123; // 处理请求... $this-&gt;dispatchFrom('App\Jobs\ProcessOrder', $request);&#125; 该方法检查给定任务类的构造函数并从HTTP请求（或者其它ArrayAccess对象）中解析变量来填充任务需要的构造函数参数。所以，如果我们的任务类在构造函数中接收一个productId变量，该任务将会尝试从HTTP请求中获取productId参数。 你还可以传递一个数组作为 dispatchFrom 方法的第三个参数。该数组用于填充所有请求中不存在的构造函数参数： 123$this-&gt;dispatchFrom('App\Jobs\ProcessOrder', $request, [ 'taxPercentage' =&gt; 20,]); 任务完成事件Queue::after 方法允许你在队列任务执行成功后注册一个要执行的回调函数。在该回调中我们可以添加日志、统计数据。例如，我们可以在Laravel内置的AppServiceProvider中添加事件回调: 12345678910use Queue;class AppServiceProvider extends ServiceProvider &#123; public function boot() &#123; Queue::after(function ($connection, $job, $data) &#123; &#125;); &#125;&#125; 运行队列监听器开启任务监听器Laravel 包含了一个 Artisan 命令用来运行被推送到队列的新任务。你可以使用 queue:listen 命令运行监听器， 还可以指定监听器使用哪个队列连接： 123php artisan queue:listen// php artisan queue:listen connection 注意一旦任务开始后，将会持续运行直到手动停止。你可以使用一个过程监视器如 Supervisor 来确保队列监听器没有停止运行。 队列优先级你可以传递逗号分隔的队列连接列表到 listen 任务来设置队列优先级；在本例中，high 队列上的任务总是在从 low 队列移动任务之前被处理。 1php artisan queue:listen --queue=high,low 指定任务超时参数设置每个任务允许运行的最大时间（以秒为单位）： 1php artisan queue:listen --timeout=60 指定队列睡眠时间需要注意的是队列只会在队列上没有任务时“睡眠”，如果存在多个有效任务，该队列会持续运行，从不睡眠。可以指定轮询新任务之前的等待时间（以秒为单位）： 1php artisan queue:listen --sleep=5 Supervisor 配置Supervisor为Linux操作系统提供的进程监视器，将会在失败时自动重启queue:listen或queue:work命令，要在Ubuntu上安装Supervisor，使用如下命令： 1sudo apt-get install supervisor Supervisor配置文件通常存放在/etc/supervisor/conf.d目录，在该目录中，可以创建多个配置文件指示Supervisor如何监视进程，例如，让我们创建一个开启并监视queue:work进程的laravel-worker.conf文件： 123456789[program:laravel-worker]process_name=%(program_name)s_%(process_num)02dcommand=php /home/forge/app.com/artisan queue:work sqs --sleep=3 --tries=3 --daemonautostart=trueautorestart=trueuser=forgenumprocs=8redirect_stderr=truestdout_logfile=/home/forge/app.com/worker.log 在本例中，numprocs指令让Supervisor运行8个queue:work进程并监视它们，如果失败的话自动重启。配置文件创建好了之后，可以使用如下命令更新Supervisor配置并开启进程： 123sudo supervisorctl rereadsudo supervisorctl updatesudo supervisorctl start laravel-worker:* 后台队列监听器Artisan 命令 queue:work 包含一个 --daemon 选项来强制队列 worker 持续处理任务而不必重新启动框架。相较于 queue:listen 命令该命令对 CPU 的使用有明显降低： 123php artisan queue:work connection --daemonphp artisan queue:work connection --daemon --sleep=3php artisan queue:work connection --daemon --sleep=3 --tries=3 由于后台队列 worker 是常驻进程，不重启的话不会应用代码中的更改，所以，最简单的部署后台队列 worker 的方式是使用部署脚本重启所有 worker，你可以通过在部署脚本中包含如下命令重启所有 worker： 1php artisan queue:restart 该命令会告诉所有队列 worker 在完成当前任务处理后重启以便没有任务被遗漏。 处理失败任务由于事情并不总是按照计划发展，有时候你的队列任务会失败。别担心，它发生在我们大多数人身上！Laravel 包含了一个方便的方式来指定任务最大尝试执行次数，任务执行次数达到最大限制后，会被插入到 failed_jobs 表，失败任务的名字可以通过配置文件 config/queue.php 来配置。 要创建一个 failed_jobs 表的迁移，可以使用 queue:failed-table 命令： 1php artisan queue:failed-table 运行队列监听器的时候，可以在 queue:listen 命令上使用 --tries 开关来指定任务最大可尝试执行次数： 1php artisan queue:listen connection-name --tries=3 失败任务事件如果你想要注册一个队列任务失败时被调用的事件，可以使用 Queue::failing 方法，该事件通过邮件或 HipChat 通知团队。举个例子，我么可以在 Laravel 自带的 AppServiceProvider 中附件一个回调到该事件： 12345678class AppServiceProvider extends ServiceProvider &#123; public function boot() &#123; Queue::failing(function ($connection, $job, $data) &#123; // Notify team of failing job... &#125;); &#125;&#125; 重试失败任务要查看已插入到 failed_jobs 数据表中的所有失败任务，可以使用 Artisan 命令 queue:failed： 1php artisan queue:failed 该命令将会列出任务ID，连接，对列和失败时间，任务ID可用于重试失败任务，例如，要重试一个ID为5的失败任务，要用到下面的命令： 1php artisan queue:retry 5 如果你要删除一个失败任务，可以使用 queue:forget 命令： 1php artisan queue:forget 5 要删除所有失败任务，可以使用 queue:flush 命令： 1php artisan queue:flush]]></content>
      <categories>
        <category>Laravel</category>
      </categories>
      <tags>
        <tag>Laravel-5.1</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel 用法之 Event 模块]]></title>
    <url>%2F2017%2F12%2F26%2Flaravel-event%2F</url>
    <content type="text"><![CDATA[本文转载 [ Laravel 5.1 文档 ] 服务 —— 事件 Laravel 事件提供了简单的观察者模式实现，允许你订阅和监听应用中的事件。事件类通常存放在 app/Events 目录，监听器存放在 app/Listeners。 定义事件事件类是一个处理与事件相关的简单数据容器，例如，假设我们生成的 PodcastWasPurchased 事件接收一个 Eloquent ORM 对象： 123456789101112131415161718&lt;?phpnamespace App\Events;use App\Podcast;use App\Events\Event;use Illuminate\Queue\SerializesModels;class PodcastWasPurchased extends Event&#123; use SerializesModels; public $podcast; // 创建新的事件实例 public function __construct(Podcast $podcast) &#123; $this-&gt;podcast = $podcast; &#125;&#125; 正如你所看到的，该事件类不包含任何特定逻辑，只是一个存放被购买的 Podcast 对象的容器，如果事件对象被序列化的话，事件使用的 SerializesModels trait 将会使用 PHP 的 serialize 函数序列化所有 Eloquent 模型。 定义监听器1234567891011121314151617181920&lt;?phpnamespace App\Listeners;use App\Events\PodcastWasPurchased;use Illuminate\Queue\InteractsWithQueue;use Illuminate\Contracts\Queue\ShouldQueue;use Illuminate\Contracts\Mail\Mailer;class EmailPurchaseConfirmation &#123; // 创建事件监听器 public function __construct(Mailer $mailer) &#123; $this-&gt;mailer = $mailer; &#125; // 处理事件 public function handle(PodcastWasPurchased $event) &#123; // Access the podcast using $event-&gt;podcast... &#125;&#125; 停止事件继续往下传播 ： 有时候，你希望停止事件被传播到其它监听器，你可以通过从监听器的 handle 方法中返回 false 来实现。 事件监听器队列需要将事件监听器放到队列中？没有比这更简单的了，只需要让监听器类实现 ShouldQueue 接口即可; 1class EmailPurchaseConfirmation implements ShouldQueue 手动访问队列 如果你需要手动访问底层队列任务的 delete 、 release 和 attempts方法，在生成的监听器中默认导入的 Illuminate\Queue\InteractsWithQueue trait 提供了访问这三个方法的权限： 123456789class EmailPurchaseConfirmation implements ShouldQueue&#123; use InteractsWithQueue; public function handle(PodcastWasPurchased $event) &#123; if (true) &#123; $this-&gt;release(30); &#125; &#125;&#125; 注册事件监听Laravel 自带的 EventServiceProvider 为事件注册提供了方便之所。其中的 listen 属性包含了事件（键）和对应监听器（值）数组。如果应用需要，你可以添加多个事件到该数组。例如，让我们添加 PodcastWasPurchased 事件： 123456// 事件监听器映射protected $listen = [ 'App\Events\PodcastWasPurchased' =&gt; [ 'App\Listeners\EmailPurchaseConfirmation', ],]; 触发事件要触发一个事件，可以使用 Event 门面，传递一个事件实例到 fire 方法，fire 方法会分发事件到所有监听器： 1Event::fire(new PodcastWasPurchased($podcast)); 此外，你还可以使用全局的帮助函数 event 来触发事件： 1event(new PodcastWasPurchased($podcast)); 广播事件在很多现代 web 应用中，web 套接字被用于实现实时更新的用户接口。当一些数据在服务器上被更新，通常一条消息通过 websocket 连接被发送给客户端处理。 为帮助你构建这样的应用，Laravel 让通过 websocket 连接广播事件变得简单。广播 Laravel 事件允许你在服务端和客户端 JavaScript 框架之间共享同一事件名。 所有事件广播都通过队列任务来完成以便应用的响应时间不受影响。 将事件标记为广播要告诉 Laravel 给定事件应该被广播，需要在事件类上实现 Illuminate\Contracts\Broadcasting\ShouldBroadcast 接口。ShouldBroadcast 接口要求你实现一个方法：broadcastOn。该方法应该返回事件广播”频道“名称数组： 12345678910111213141516171819use App\Events\Event;use Illuminate\Queue\SerializesModels;use Illuminate\Contracts\Broadcasting\ShouldBroadcast;class ServerCreated extends Event implements ShouldBroadcast&#123; use SerializesModels; public $user; // 创建新的事件实例 public function __construct(User $user) &#123; $this-&gt;user = $user; &#125; // 获取事件广播频道 public function broadcastOn() &#123; return ['user.'.$this-&gt;user-&gt;id]; &#125;&#125; 然后，你只需要和正常一样触发该事件，事件被触发后，一个队列任务将通过指定广播驱动自动广播该事件。 广播数据如果某个事件被广播，其所有的 public 属性都会按照事件负载自动序列化和广播，从而允许你从 JavaScript 中访问所有 public 数据，因此，举个例子，如果你的事件有一个单独的包含 Eloquent 模型的 $user 属性，广播负载定义如下： 1234567&#123; "user": &#123; "id": 1, "name": "Jonathan Banks" ... &#125;&#125; 然而，如果你希望对广播负载有更加细粒度的控制，可以添加 broadcastWith 方法到事件，该方法应该返回你想要通过事件广播的数组数据： 1234// 获取广播数据public function broadcastWith()&#123; return ['user' =&gt; $this-&gt;user-&gt;id];&#125; 消费事件广播Pusher你可以通过 Pusher 的 JavaScript SDK 方便地使用 Pusher 驱动消费事件广播。例如，让我们从之前的例子中消费 App\Events\ServerCreated 事件： 1234567this.pusher = new Pusher('pusher-key');this.pusherChannel = this.pusher.subscribe('user.' + USER_ID);this.pusherChannel.bind('App\\Events\\ServerCreated', function(message) &#123; console.log(message.user);&#125;); Redis如果你在使用 Redis 广播，你将需要编写自己的 Redis pub/sub 消费者来接收消息并使用自己选择的 websocket 技术将其进行广播。例如，你可以选择使用使用 Node 编写的流行的 Socket.io 库。 使用 Node 库 socket.io 和 ioredis，你可以快速编写事件广播发布所有广播事件： 12345678910111213141516171819202122232425var app = require('http').createServer(handler);var io = require('socket.io')(app);var Redis = require('ioredis');var redis = new Redis();app.listen(6001, function() &#123; console.log('Server is running!');&#125;);function handler(req, res) &#123; res.writeHead(200); res.end('');&#125;io.on('connection', function(socket) &#123; //&#125;);redis.psubscribe('*', function(err, count) &#123; //&#125;);redis.on('pmessage', function(subscribed, channel, message) &#123; message = JSON.parse(message); io.emit(channel + ':' + message.event, message.data);&#125;); 事件订阅者事件订阅者是指那些在类本身中订阅到多个事件的类，从而允许你在单个类中定义一些事件处理器。订阅者应该定义一个 subscribe 方法，该方法中传入一个事件分发器实例： 123456789101112131415161718192021class UserEventListener&#123; // 处理用户登录事件 public function onUserLogin($event) &#123;&#125; // 处理用户退出事件 public function onUserLogout($event) &#123;&#125; // 为订阅者注册监听器 public function subscribe($events) &#123; $events-&gt;listen( 'App\Events\UserLoggedIn', 'App\Listeners\UserEventListener@onUserLogin' ); $events-&gt;listen( 'App\Events\UserLoggedOut', 'App\Listeners\UserEventListener@onUserLogout' ); &#125;&#125; 注册一个事件订阅者订阅者被定义后，可以通过事件分发器进行注册，你可以使用 EventServiceProvider 上的 $subcribe 属性来注册订阅者。例如，让我们添加 UserEventListener： 123456789class EventServiceProvider extends ServiceProvider&#123; // 事件监听器映射数组 protected $listen = []; // 要注册的订阅者 protected $subscribe = [ 'App\Listeners\UserEventListener', ];&#125;]]></content>
      <categories>
        <category>Laravel</category>
      </categories>
      <tags>
        <tag>Laravel-5.1</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel 用法之 FileSystem 模块]]></title>
    <url>%2F2017%2F12%2F25%2Flaravel-filesystem%2F</url>
    <content type="text"><![CDATA[本文转载 [ Laravel 5.1 文档 ] 服务 —— 文件系统/云存储 官方 API 地址 https://laravel.com/api/5.1/Illuminate/Filesystem.html 基于Frank de Jonge 的PHP包 Flysystem，Laravel 提供了强大的文件系统抽象。Laravel文件系统集成提供了使用驱动处理本地文件系统的简单使用，这些驱动包括 Amazon S3，以及 Rackspace 云存储。此外在这些存储选项间切换非常简单，因为对每个系统而言，API 是一样的。 基本使用获取硬盘实例获取默认的驱动1Storage::getDefaultDriver() 获取指定驱动，比如获取本地文件驱动1$disk = Storage::disk('local') 获取文件exists 方法用于判断给定文件是否存在于磁盘上： 1$exists = Storage::disk('s3')-&gt;exists('file.jpg'); get方法用于获取给定文件的内容，该方法将会返回该文件的原生字符串内容： 1$contents = Storage::get('file.jpg'); size方法以字节方式返回文件大小： 1$size = Storage::size('file1.jpg'); lastModified 方法以 UNIX 时间戳格式返回文件最后一次修改时间： 1$time = Storage::lastModified('file1.jpg'); 存储文件put 方法用于存储文件到磁盘。可以传递一个PHP资源到put方法，该方法将会使用Flysystem底层的流支持。在处理大文件的时候推荐使用文件流： 12Storage::put('file.jpg', $contents);Storage::put('file.jpg', $resource); copy 方法将磁盘中已存在的文件从一个地方拷贝到另一个地方： 1Storage::copy('old/file1.jpg', 'new/file1.jpg'); move 方法将磁盘中已存在的文件从一定地方移到到另一个地方： 1Storage::move('old/file1.jpg', 'new/file1.jpg'); prepend 和 append 方法允许你轻松插入内容到文件开头/结尾： 12Storage::prepend('file.log', 'Prepended Text');Storage::append('file.log', 'Appended Text'); 删除文件delete 方法接收单个文件名或多个文件数组并将其从磁盘移除： 12Storage::delete('file.jpg');Storage::delete(['file1.jpg', 'file2.jpg']); 目录获取一个目录下的所有文件files 方法返回给定目录下的所有文件数组，如果你想要获取给定目录下包含子目录的所有文件列表，可以使用 allFiles 方法： 12$files = Storage::files($directory);$files = Storage::allFiles($directory); 获取一个目录下的所有子目录directories 方法返回给定目录下所有目录数组，此外，可以使用 allDirectories 方法获取嵌套的所有子目录数组： 123$directories = Storage::directories($directory);// 递归...$directories = Storage::allDirectories($directory); 创建目录makeDirectory 方法将会创建给定目录，包含子目录（递归）： 1Storage::makeDirectory($directory); 删除目录deleteDirectory 方法用于移除目录，包括该目录下的所有文件 1Storage::deleteDirectory($directory);]]></content>
      <categories>
        <category>Laravel</category>
      </categories>
      <tags>
        <tag>Laravel-5.1</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel 用法之 Cache 模块]]></title>
    <url>%2F2017%2F12%2F25%2Flaravel-cache%2F</url>
    <content type="text"><![CDATA[本文转载 [ Laravel 5.1 文档 ] 服务 —— 缓存； 官方 API 地址 https://laravel.com/api/5.1/Illuminate/Cache.html 配置Laravel 为不同的缓存系统提供了统一的 API。缓存配置位于 config/cache.php。 数据库驱动使用 database 缓存驱动时，你需要设置一张表包含缓存缓存项。下面是该表的 Schema 声明： 12345Schema::create('cache', function($table) &#123; $table-&gt;string('key')-&gt;unique(); $table-&gt;text('value'); $table-&gt;integer('expiration');&#125;); Memcached 驱动使用 Memcached 缓存要求安装了 Memcached PECL 包，即 PHP Memcached 扩展。 Memcached::addServer 默认配置使用 TCP/IP 协议： 1234567'memcached' =&gt; [ [ 'host' =&gt; '127.0.0.1', 'port' =&gt; 11211, 'weight' =&gt; 100 ],], 你还可以设置 host 选项为 UNIX socket 路径，如果你这样做，port 选项应该置为 0： 1234567'memcached' =&gt; [ [ 'host' =&gt; '/var/run/memcached/memcached.sock', 'port' =&gt; 0, 'weight' =&gt; 100 ],], Redis 驱动使用 Laravel 的 Redis 缓存之前，你需要通过 Composer 安装 predis/predis 包（~1.0）。 缓存使用获取缓存实例123Cache::getDefaultDriver()Cache::get('store_name') 指定缓存存储器使用 Cache 门面，你可以使用 store 方法访问不同的缓存存储器，传入 store 方法的键就是 cache 配置文件中 stores 配置数组里列出的相应的存储器： 1Cache::store('file')-&gt;get('foo') 获取数据Cache 门面的 get 方法用于从缓存中获取缓存项，如果缓存项不存在，返回 null 。如果需要的话你可以传递第二个参数到 get 方法指定缓存项不存在时返回的自定义默认值： 123456$value = Cache::get('key');$value = Cache::get('key', 'default');$value = Cache::get('key', function() &#123; return DB::table(...)-&gt;get();&#125;); 检查缓存项是否存在123if (Cache::has('key')) &#123; //&#125; 数值增加/减少 12345Cache::increment('key');Cache::increment('key', $amount);Cache::decrement('key');Cache::decrement('key', $amount); 获取或更新如果缓存项不存在，传递给remember方法的闭包被执行并且将结果存放到缓存中。 12345$value = Cache::remember('users', $minutes, function() &#123; return DB::table('users')-&gt;get();&#125;); $value = Cache::rememberForever('users', function() &#123; return DB::table('users')-&gt;get();&#125;); 获取并删除如果你需要从缓存中获取缓存项然后删除，你可以使用 pull 方法，和 get 方法一样，如果缓存项不存在的话返回 null： 1$value = Cache::pull('key'); 存储缓存你可以使用 Cache 门面上的 put 方法在缓存中存储缓存项。当你在缓存中存储缓存项的时候，你需要指定数据被缓存的时间（分钟数）： 1Cache::put('key', 'value', $minutes); 除了传递缓存项失效时间，你还可以传递一个代表缓存项有效时间的PHP Datetime实例： 12$expiresAt = Carbon::now()-&gt;addMinutes(10);Cache::put('key', 'value', $expiresAt); add 方法只会在缓存项不存在的情况下添加缓存项到缓存，如果缓存项被添加到缓存返回true，否则，返回false： 1Cache::add('key', 'value', $minutes); forever 方法用于持久化存储缓存项到缓存，这些值必须通过 forget 方法手动从缓存中移除： 1Cache::forever('key', 'value'); 移除缓存1Cache::forget('key'); 添加自定义缓存驱动要使用自定义驱动扩展 Laravel 缓存，我们使用 Cache 门面的 extend 方法，该方法用于绑定定义驱动解析器到管理器，通常，这可以在服务提供者中完成。 例如，要注册一个新的命名为“ mongo ”的缓存驱动： 12345678910111213use App\Extensions\MongoStore;use Illuminate\Support\ServiceProvider;class CacheServiceProvider extends ServiceProvider&#123; public function boot() &#123; Cache::extend('mongo', function($app) &#123; return Cache::repository(new MongoStore); &#125;); &#125; &#125; App\Extensions\MongoStore 文件内容如下： 1234567891011121314&lt;?phpnamespace App\Extensions;class MongoStore implements \Illuminate\Contracts\Cache\Store&#123; public function get($key) &#123;&#125; public function put($key, $value, $minutes) &#123;&#125; public function increment($key, $value = 1) &#123;&#125; public function decrement($key, $value = 1) &#123;&#125; public function forever($key, $value) &#123;&#125; public function forget($key) &#123;&#125; public function flush() &#123;&#125; public function getPrefix() &#123;&#125;&#125; 扩展完成后，只需要更新配置文件 config/cache.php 的 driver 选项为你的扩展名称。 缓存标签缓存标签不支持 file 或 database 缓存驱动，此外，在“永久”存储缓存中使用多个标签时，memcached 之类的驱动有着最佳性能，因为它可以自动清除过期的记录。 存储打上标签的缓存项缓存标签允许你给相关的缓存项打上同一个标签，然后可以输出被分配同一个标签的所有缓存值。你可以通过传递一个有序的标签名数组来访问被打上标签的缓存。例如，让我们访问一个被打上标签的缓存并将其值放到缓存中： 12Cache::tags(['people', 'artists'])-&gt;put('John', $john, $minutes);Cache::tags(['people', 'authors'])-&gt;put('Anne', $anne, $minutes); 然而，并不只限于使用 put 方法，你可以在处理标签时使用任何混存存储器提供的方法。 访问打上标签的缓存项要获取被打上标签的缓存项，传递同样的有序标签名数组到 tags 方法： 12$john = Cache::tags(['people', 'artists'])-&gt;get('John');$anne = Cache::tags(['people', 'authors'])-&gt;get('Anne'); 通过上面的语句你可以输出所有分配了该标签或标签列表的缓存项，例如，下面这个语句将会移除被打上 people，authors标签的缓存，或者，Anne 和 John 都会从缓存中移除： 1Cache::tags(['people', 'authors'])-&gt;flush(); 相比之下，下面这个语句只会移除被打上 authors 标签的缓存，所以 Anne 会被移除，而 John 不会： 1Cache::tags('authors')-&gt;flush(); 缓存事件要在每次缓存操作时执行代码，你可以监听缓存触发的事件，通常，你可以将这些缓存处理器代码放到 EventServiceProvider 的 boot 方法中： 12345678910111213141516171819public function boot(DispatcherContract $events)&#123; parent::boot($events); $events-&gt;listen('cache.hit', function ($key, $value) &#123; // &#125;); $events-&gt;listen('cache.missed', function ($key) &#123; // &#125;); $events-&gt;listen('cache.write', function ($key, $value, $minutes) &#123; // &#125;); $events-&gt;listen('cache.delete', function ($key) &#123; // &#125;);&#125;]]></content>
      <categories>
        <category>Laravel</category>
      </categories>
      <tags>
        <tag>Laravel-5.1</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel 用法之 Database 模块 ORM]]></title>
    <url>%2F2017%2F12%2F24%2Flaravel-database_2%2F</url>
    <content type="text"><![CDATA[参考阅读 [ Laravel 5.1 文档 ] Eloquent ORM —— 起步 [ Laravel 5.1 文档 ] Eloquent ORM —— 关联关系 官方 API 地址 https://laravel.com/api/5.1/Illuminate/Database.html; 定义模型1234567891011121314151617181920212223&lt;?phpnamespace App;use Illuminate\Database\Eloquent\Model;class Flight extends Model&#123; // 如果不指定表名，默认规则是模型类名的复数作为与其对应的表名 protected $table = 'my_flights'; // 默认每张表的主键名为 id protected $primaryKey = 'flight_id'; // 表明模型是否应该被打上时间戳 public $timestamps = false; // 模型日期列的存储格式 protected $dateFormat = 'U'; // 应该被调整为日期的属性 protected $dates = ['created_at', 'updated_at', 'disabled_at'];&#125; 注：时间戳格式可以参考 PHP Date()函数详细参数 访问器和修改器访问器和修改器允许你在获取模型属性或设置其值时格式化 Eloquent 属性。例如，你可能想要使用 Laravel 加密器对存储在数据库中的数据进行加密，并且在 Eloquent 模型中访问时自动进行解密。 除了自定义访问器和修改器，Eloquent 还可以自动转换日期字段为 Carbon 实例甚至将文本转换为 JSON。 定义访问器比如，要访问 ORM 模型的 first_name 属性， 可以定义如下的访问器 1234// 方法名 使用驼峰式命名规则public function getFirstNameAttribute($value) &#123; return ucfirst($value);&#125; 定义修改器比如，为 first_name 属性定义一个修改器，当我们为模型上的 first_name 赋值时该修改器会被自动调用： 123public function setFirstNameAttribute($value) &#123; $this-&gt;attributes['first_name'] = strtolower($value);&#125; 属性转换模型中的 $casts 属性提供了便利方法转换属性到通用数据类型。$casts 属性是数组格式，其键是要被转换的属性名称，其值时你想要转换的类型。目前支持的转换类型包括：integer, real, float, double, string, boolean, object 和 array。 例如，让我们转换 is_admin 属性，将其由 integer 类型转换为 boolean 类型： 1234// 应该被转化为原生类型的属性protected $casts = [ 'is_admin' =&gt; 'boolean',]; 现在，is_admin 属性在被访问时总是被转换为 boolean，即使底层存储在数据库中的值是 integer； 数组转换 array 类型转换在处理被存储为序列化 JSON 的字段是特别有用，例如，如果数据库有一个 TEXT 字段类型包含了序列化 JSON，添加 array 类型转换到该属性将会在 Eloquent 模型中访问其值时自动将其反序列化为 PHP 数组： 1234// 应该被转化为原生类型的属性protected $casts = [ 'options' =&gt; 'array',]; 类型转换被定义后，就可以访问 options 属性，它将会自动从 JSON 反序列化为 PHP 数组，当你设置 options 属性的值时，给定数组将会自动转化为 JSON 以供存储： 12345$user = App\User::find(1);$options = $user-&gt;options;$options['key'] = 'value';$user-&gt;options = $options;$user-&gt;save(); 序列化当构建 JSON API 时，经常需要转化模型和关联关系为数组或 JSON。Eloquent 包含便捷方法实现这些转换，以及控制哪些属性被包含到序列化中。 toArray() 转化模型及其加载的关联关系为数组；toJson() 转化模型及其加载的关联关系为 JSON； 你还可以转化模型或集合为字符串，这将会自动调用 toJson 方法： 12$user = App\User::find(1);return (string) $user; 追加值到 JSON有时候，需要添加数据库中没有相应的字段到数组中，要实现这个，首先要定义一个访问器;定义好访问器后，添加字段名到模型的 appends 属性：12// 追加到模型数组表单的访问器protected $appends = ['is_admin']; 字段被添加到 appends 列表之后，将会被包含到模型数组和 JSON 表单中，appends 数组中的字段还会遵循模型中的 visible 和 hidden 设置配置。 在 JSON 中隐藏属性显示 有时候你希望在模型数组或 JSON 显示中限制某些属性，比如密码，要实现这个，在定义模型的时候添加一个 $hidden 属性： 1protected $hidden = ['password']; 此外，可以使用 visible 属性定义属性显示的白名单： 1protected $visible = ['first_name', 'last_name']; 操作模型事件Eloquent 模型可以触发事件，允许你在模型生命周期中的多个时间点调用如下这些方法：creating, created, updating, updated, saving, saved, deleting, deleted, restoring, restored。事件允许你在一个指定模型类每次保存或更新的时候执行代码。 12345678910class User extends Model&#123; public static function boot() &#123; parent::boot(); // 注册 已创建事件 static::created(function ($obj) &#123; &#125; &#125;&#125; 插入想要在数据库中插入新的记录，只需创建一个新的模型实例，设置模型的属性，然后调用 save 方法： 123$flight = new Flight;$flight-&gt;name = $request-&gt;name;$flight-&gt;save(); 批量赋值还可以使用 create 方法保存一个新的模型。该方法返回被插入的模型实例。但是，在此之前，你需要指定模型的 fillable 或 guarded 属性，因为所有 Eloquent 模型都通过批量赋值（Mass Assignment）进行保护。 更新save 方法还可以用于更新数据库中已存在的模型。要更新一个模型，应该先获取它，设置你想要更新的属性，然后调用 save 方法。同样，updated_at 时间戳会被自动更新，所以没必要手动设置其值： 123$flight = App\Flight::find(1);$flight-&gt;name = 'New Flight Name';$flight-&gt;save(); 更新操作还可以同时修改给定查询提供的多个模型实例，在本例中，所有有效且 destination=San Diego 的航班都被标记为延迟： 1App\Flight::where('active', 1)-&gt;where('destination', 'San Diego')-&gt;update(['delayed' =&gt; 1]); update 方法要求以数组形式传递键值对参数，代表着数据表中应该被更新的列。 删除实例调用 delete 方法 12$flight = App\Flight::find(1);$flight-&gt;delete(); 主键删除 123App\Flight::destroy(1);App\Flight::destroy([1, 2, 3]);App\Flight::destroy(1, 2, 3); 条件查询删除 1$deletedRows = App\Flight::where('active', 0)-&gt;delete(); 软删除除了从数据库删除记录外，Eloquent 还可以对模型进行“软删除”。当模型被软删除后，它们并没有真的从数据库删除，而是在模型上设置一个 deleted_at 属性并插入数据库，如果模型有一个非空 deleted_at 值，那么该模型已经被软删除了。要启用模型的软删除功能，可以使用模型上的Illuminate\Database\Eloquent\SoftDeletestrait并添加 deleted_at 列到 $dates 属性： 12345678use Illuminate\Database\Eloquent\Model;use Illuminate\Database\Eloquent\SoftDeletes;class Flight extends Model&#123; use SoftDeletes; // 应该被调整为日期的属性 protected $dates = ['deleted_at'];&#125; 现在，当调用模型的 delete 方法时，deleted_at 列将被设置为当前日期和时间，并且，当查询一个使用软删除的模型时，被软删除的模型将会自动从查询结果中排除。 判断给定模型实例是否被软删除，可以使用 trashed 方法： 123if ($flight-&gt;trashed()) &#123; //&#125; 软删除模型将会自动从查询结果中排除，但是，如果你想要软删除模型出现在查询结果中，可以使用 withTrashed 方法： 1$flights = App\Flight::withTrashed()-&gt;where('account_id', 1)-&gt;get(); 只获取软删除模型 onlyTrashed 1$flights = App\Flight::onlyTrashed()-&gt;where('airline_id', 1)-&gt;get(); 恢复软删除模型 123$flight-&gt;restore();App\Flight::withTrashed()-&gt;where('airline_id', 1)-&gt;restore(); 永久删除模型 12// 强制删除单个模型实例...$flight-&gt;forceDelete(); 查询作用域允许你定义一个查询条件的通用集合，这样就可以在应用中方便地复用。例如，你需要频繁获取最受欢迎的用户，要定义一个作用域，只需要简单的在 Eloquent 模型方法前加上一个 scope 前缀： 123public function scopeActive($query) &#123; return $query-&gt;where('active', 1);&#125; 关联关系一对一比如，用户关联手机 123456789101112131415class User extends Model &#123; public function phone() &#123; return $this-&gt;hasOne('App\Phone'); &#125; &#125;class Phone extends Model&#123; public function user() &#123; return $this-&gt;belongsTo('App\User'); &#125; &#125; 一对多比如，一篇博客文章拥有无数评论 12345678910111213class Post extends Model&#123; public function comments() &#123; return $this-&gt;hasMany('App\Comment'); &#125;&#125;class Comment extends Model&#123; public function post() &#123; return $this-&gt;belongsTo('App\Post'); &#125;&#125; 多对多比如，一个用户有多个角色，同时一个角色被多个用户共用；要定义这样的关联关系，需要三个数据表：users、roles 和 role_user，role_user 表按照关联模型名的字母顺序命名，并且包含 user_id 和 role_id 两个列。 1234567891011121314151617class User extends Model &#123; public function roles() &#123; // 如果中间表没有按照关联模型名的字母顺序命名 // return $this-&gt;belongsToMany('App\Role', 'user_roles', 'user_id', 'role_id'); return $this-&gt;belongsToMany('App\Role'); &#125; &#125;class Role extends Model &#123; public function users() &#123; return $this-&gt;belongsToMany('App\User'); &#125; &#125; 中间表获取中间表的列 12345$user = App\User::find(1);foreach ($user-&gt;roles as $role) &#123; echo $role-&gt;pivot-&gt;created_at;&#125; 默认情况下，只有模型键才能用在 pivot 对象上，如果你的 pivot 表包含额外的属性，必须在定义关联关系时进行指定： 1return $this-&gt;belongsToMany('App\Role')-&gt;withPivot('column1', 'column2'); 如果你想要你的 pivot 表自动包含 created_at 和 updated_at 时间戳，在关联关系定义时使用 withTimestamps 方法： 1return $this-&gt;belongsToMany('App\Role')-&gt;withTimestamps(); 远层的一对多例如，Country 模型通过中间的 User 模型可能拥有多个 Post 模型。在这个例子中，你可以轻易的聚合给定国家的所有文章，让我们看看定义这个关联关系需要哪些表： 12345678910111213countries id - integer name - stringusers id - integer country_id - integer name - stringposts id - integer user_id - integer title - string 既然我们已经查看了该关联关系的数据表结构，接下来让我们在 Country 模型上进行定义： 123456class Country extends Model &#123; public function posts() &#123; // return $this-&gt;hasManyThrough('App\Post', 'App\User'); return $this-&gt;hasManyThrough('App\Post', 'App\User', 'country_id', 'user_id'); &#125;&#125; 多态关联多态关联允许一个模型在单个关联下属于多个不同模型。例如，假如你想要为产品和职工存储照片，使用多态关联，你可以在这两种场景下使用单个 photos 表，首先，让我们看看构建这种关联关系需要的表结构： 12345678910111213staff id - integer name - stringproducts id - integer price - integerphotos id - integer path - string imageable_id - integer imageable_type - string 接下来，让我们看看构建这种关联关系需要在模型中定义什么： 1234567891011121314151617181920212223242526272829class Photo extends Model&#123; /** * 获取所有拥有的imageable模型 */ public function imageable() &#123; return $this-&gt;morphTo(); &#125;&#125;class Staff extends Model&#123; /** * 获取所有职员照片 */ public function photos() &#123; return $this-&gt;morphMany('App\Photo', 'imageable'); &#125;&#125;class Product extends Model&#123; /** * 获取所有产品照片 */ public function photos() &#123; return $this-&gt;morphMany('App\Photo', 'imageable'); &#125;&#125; 获取多态关联要访问一个职员的所有照片，可以通过使用 photos 的动态属性：12345$staff = App\Staff::find(1);foreach ($staff-&gt;photos as $photo) &#123; //&#125; 你还可以通过访问调用morphTo方法名来从多态模型中获取多态关联的所属对象。在本例中，就是Photo模型中的imageable方法。因此，我们可以用动态属性的方式访问该方法： 12$photo = App\Photo::find(1);$imageable = $photo-&gt;imageable; Photo 模型上的 imageable 关联返回 Staff 或 Product 实例，这取决于那个类型的模型拥有该照片。 多对多多态关联除了传统的多态关联，还可以定义“多对多”的多态关联，例如，一个博客的 Post 和 Video 模型可能共享一个 Tag 模型的多态关联。使用对多对的多态关联允许你在博客文章和视频之间有唯一的标签列表。首先，让我们看看表结构： 12345678910111213141516posts id - integer name - stringvideos id - integer name - stringtags id - integer name - stringtaggables tag_id - integer taggable_id - integer taggable_type - string 接下来，我们准备在模型中定义该关联关系。 123456789101112131415161718192021class Post extends Model&#123; // 获取指定文章所有标签 public function tags() &#123; return $this-&gt;morphToMany('App\Tag', 'taggable'); &#125;&#125;class Tag extends Model&#123; // 获取所有分配该标签的文章 public function posts() &#123; return $this-&gt;morphedByMany('App\Post', 'taggable'); &#125; // 获取分配该标签的所有视频 public function videos() &#123; return $this-&gt;morphedByMany('App\Video', 'taggable'); &#125;&#125; 关联查询查询已存在的关联关系访问一个模型的记录的时候，你可能希望基于关联关系是否存在来限制查询结果的数目。例如，假设你想要获取所有至少有一个评论的博客文章，要实现这个，可以传递关联关系的名称到has方法： 123456// 获取所有至少有一条评论的文章...$posts = App\Post::has('comments')-&gt;get();// 获取所有至少有三条评论的文章...$posts = Post::has('comments', '&gt;=', 3)-&gt;get();// 获取所有至少有一条评论获得投票的文章...$posts = Post::has('comments.votes')-&gt;get(); 如果你需要更强大的功能，可以使用 whereHas 和 orWhereHas 方法将 where 条件放到 has 查询上，这些方法允许你添加自定义条件约束到关联关系条件约束，例如检查一条评论的内容： 1234// 获取所有至少有一条评论包含foo字样的文章$posts = Post::whereHas('comments', function ($query) &#123; $query-&gt;where('content', 'like', 'foo%');&#125;)-&gt;get(); 渴求式加载12345$books = App\Book::with('author')-&gt;get();// 渴求式加载多个关联关系$books = App\Book::with('author', 'publisher')-&gt;get();// 嵌套的渴求式加载$books = App\Book::with('author.contacts')-&gt;get(); 带条件约束的渴求式加载 1234567$users = App\User::with(['posts' =&gt; function ($query) &#123; $query-&gt;where('title', 'like', '%first%');&#125;])-&gt;get();$users = App\User::with(['posts' =&gt; function ($query) &#123; $query-&gt;orderBy('created_at', 'desc');&#125;])-&gt;get(); 懒惰渴求式加载有时候你需要在父模型已经被获取后渴求式加载一个关联关系。例如，这在你需要动态决定是否加载关联模型时可能很有用： 12345$books = App\Book::all();if ($someCondition) &#123; $books-&gt;load('author', 'publisher');&#125; 如果你需要设置更多的查询条件到渴求式加载查询上，可以传递一个闭包到 load 方法： 123$books-&gt;load(['author' =&gt; function ($query) &#123; $query-&gt;orderBy('published_date', 'asc');&#125;]); 插入关联模型基本使用save 方法Eloquent 提供了便利的方法来添加新模型到关联关系。例如，也许你需要插入新的 Comment 到 Post 模型，你可以从关联关系的 save 方法直接插入 Comment而不是手动设置Comment的post_id属性： 12345678$comment = new App\Comment(['message' =&gt; 'A new comment.']);$post = App\Post::find(1);$comment = $post-&gt;comments()-&gt;save($comment);$post-&gt;comments()-&gt;saveMany([ new App\Comment(['message' =&gt; 'A new comment.']), new App\Comment(['message' =&gt; 'Another comment.']),]); 当处理多对多关联的时候，save 方法以数组形式接收额外的中间表属性作为第二个参数： 1App\User::find(1)-&gt;roles()-&gt;save($role, ['expires' =&gt; $expires]); create 方法除了 save 和 saveMany 方法外，还可以使用 create 方法，该方法接收属性数组、创建模型、然后插入数据库。save 和 create 的不同之处在于 save 接收整个 Eloquent 模型实例而 create 接收原生 PHP 数组： 12345$post = App\Post::find(1);$comment = $post-&gt;comments()-&gt;create([ 'message' =&gt; 'A new comment.',]); 使用 create 方法之前确保先浏览属性批量赋值文档。 更新“属于”关联更新 belongsTo 关联的时候，可以使用 associate 方法，该方法会在子模型设置外键： 123$account = App\Account::find(10);$user-&gt;account()-&gt;associate($account);$user-&gt;save(); 移除 belongsTo 关联的时候，可以使用 dissociate 方法。该方法在子模型上取消外键和关联： 12$user-&gt;account()-&gt;dissociate();$user-&gt;save(); 多对多关联附加/分离处理多对多关联的时候，Eloquent 提供了一些额外的帮助函数来使得处理关联模型变得更加方便。例如，让我们假定一个用户可能有多个角色同时一个角色属于多个用户，要通过在连接模型的中间表中插入记录附加角色到用户上，可以使用 attach 方法： 12$user = App\User::find(1);$user-&gt;roles()-&gt;attach($roleId); 附加关联关系到模型，还可以以数组形式传递额外被插入数据到中间表： 1$user-&gt;roles()-&gt;attach($roleId, ['expires' =&gt; $expires]); 当然，有时候有必要从用户中移除角色，要移除一个多对多关联记录，使用 detach 方法。detach 方法将会从中间表中移除相应的记录；然而，两个模型在数据库中都保持不变： 1234// 从指定用户中移除角色...$user-&gt;roles()-&gt;detach($roleId);// 从指定用户移除所有角色...$user-&gt;roles()-&gt;detach(); 为了方便，attach 和 detach 还接收数组形式的 ID 作为输入： 123$user = App\User::find(1);$user-&gt;roles()-&gt;detach([1, 2, 3]);$user-&gt;roles()-&gt;attach([1 =&gt; ['expires' =&gt; $expires], 2, 3]); 同步你还可以使用 sync 方法构建多对多关联。sync 方法接收数组形式的 ID 并将其放置到中间表。任何不在该数组中的 ID 对应记录将会从中间表中移除。因此，该操作完成后，只有在数组中的 ID 对应记录还存在于中间表：1$user-&gt;roles()-&gt;sync([1, 2, 3]); 你还可以和 ID 一起传递额外的中间表值：1$user-&gt;roles()-&gt;sync([1 =&gt; ['expires' =&gt; true], 2, 3]); 触发父级时间戳当一个模型属于另外一个时，例如 Comment 属于 Post，子模型更新时父模型的时间戳也被更新将很有用，例如，当 Comment 模型被更新时，你可能想要“触发”创建其所属模型 Post 的 updated_at 时间戳。Eloquent 使得这项操作变得简单，只需要添加包含关联关系名称的 touches 属性到子模型中即可： 123456789class Comment extends Model&#123; // 要触发的所有关联关系 protected $touches = ['post']; // 评论所属文章 public function post() &#123; return $this-&gt;belongsTo('App\Post'); &#125;&#125; 现在，当你更新 Comment 时，所属模型 Post 将也会更新其 updated_at 值： 123$comment = App\Comment::find(1);$comment-&gt;text = 'Edit to this comment!';$comment-&gt;save();]]></content>
      <categories>
        <category>Laravel</category>
      </categories>
      <tags>
        <tag>Laravel-5.1</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel 用法之 Database 模块 原生 SQL 及 查询构建器]]></title>
    <url>%2F2017%2F12%2F20%2Flaravel-database_1%2F</url>
    <content type="text"><![CDATA[本文是基于 Laravel 5.1版本的 Database 模块代码进行分析书写； 官方 API 地址 https://laravel.com/api/5.1/Illuminate/Database.html; 参考阅读 [ Laravel 5.1 文档 ] 数据库 —— 起步 [ Laravel 5.1 文档 ] 数据库 —— 查询构建器 [ Laravel 5.1 文档 ] 数据库 —— 迁移 文件结构Database 模块包含数据库驱动、ORM、数据填充器、迁移四部分； 数据库驱动部分如下图所示： 连接获取系统目前的 connection 配置 1DB::getConnections() 运行原生 SQL 查询使用多个数据库连接的时候，可以使用 DB 门面的 connection 方法访问每个连接。传递给 connection 方法的连接名对应配置文件 config/database.php 中相应的连接： 1$users = DB::connection('foo')-&gt;select(...); DB 门面为每种查询提供了相应方法：select, update, insert, delete, 和 statement。 select 查询1$users = DB::select('select * from users where active = ?', [1]); 传递给 select 方法的第一个参数是原生的 SQL 语句，第二个参数需要绑定到查询的参数绑定，通常，这些都是 where 字句约束中的值。参数绑定可以避免 SQL 注入攻击。 select方法以数组的形式返回结果集，数组中的每一个结果都是一个PHP StdClass 对象。 除了使用 ? 占位符来代表参数绑定外，还可以使用命名绑定来执行查询： 1$results = DB::select('select * from users where id = :id', ['id' =&gt; 1]); update 查询update 方法用于更新数据库中已存在的记录，该方法返回受更新语句影响的行数： 1$affected = DB::update('update users set votes = 100 where name = ?', ['John']); insert 查询使用 DB 门面的 insert 方法执行插入语句。和 select 一样，改方法将原生 SQL 语句作为第一个参数，将绑定作为第二个参数： 1DB::insert('insert into users (id, name) values (?, ?)', [1, 'Dayle']); delete 查询delete 方法用于删除数据库中已存在的记录，和 update 一样，该语句返回被删除的行数： 1$deleted = DB::delete('delete from users'); 通用语句执行有些数据库语句不返回任何值，对于这种类型的操作，可以使用 DB 门面的 statement 方法： 1DB::statement('drop table users'); 数据库事务想要在一个数据库事务中运行一连串操作，可以使用 DB 门面的 transaction 方法，如果事务闭包中抛出异常，事务将会自动回滚。如果闭包执行成功，事务将会自动提交。使用 transaction 方法时不需要担心手动回滚或提交： 1234DB::transaction(function () &#123; DB::table('users')-&gt;update(['votes' =&gt; 1]); DB::table('posts')-&gt;delete();&#125;); 手动使用事务如果你想要手动开始事务从而对回滚和提交有一个完整的控制，可以使用 DB 门面的 beginTransaction 方法： 1DB::beginTransaction(); 你可以通过 rollBack 方法回滚事务： 1DB::rollBack(); 最后，你可以通过commit方法提交事务： 1DB::commit(); 查询日志Laravel 默认会为当前请求执行的的所有查询生成日志并保存在内存中。 因此， 在某些特殊的情况下， 比如一次性向数据库中插入大量数据， 就可能导致内存不足。 在这种情况下，你可以通过 disableQueryLog 方法来关闭查询日志: 1DB::connection()-&gt;disableQueryLog(); 开启日志的方法为 enableQueryLog()； 清理日志 flushQueryLog； 调用 getQueryLog 方法可以同时获取多个查询执行后的日志: 1$queries = DB::getQueryLog(); 查询构建器数据库查询构建器提供了一个方便的、平滑的接口来创建和运行数据库查询。查询构建器可以用于执行应用中大部分数据库操作，并且能够在支持的所有数据库系统上工作。 获取结果集从一张表中取出所有行和原生查询一样，get 方法返回结果集的数据组，其中每一个结果都是 PHP 对象的StdClass实例。1$users = DB::table('users')-&gt;get(); 从一张表中获取一行/一列如果你只是想要从数据表中获取一行数据，可以使用 first 方法，该方法将会返回单个 StdClass 对象：1$user = DB::table('users')-&gt;where('name', 'John')-&gt;first(); 从一张表中获取组块结果集如果你需要处理成千上百条数据库记录，可以考虑使用 chunk 方法，该方法一次获取结果集的一小块，然后填充每一小块数据到要处理的闭包，该方法在编写处理大量数据库记录的Artisan命令的时候非常有用。比如，我们可以将处理全部users表数据处理成一次处理 100 记录的小组块： 12345DB::table('users')-&gt;chunk(100, function($users) &#123; foreach ($users as $user) &#123; // &#125;&#125;); 你可以通过从闭包函数中返回 false 来中止组块的运行： 1234DB::table('users')-&gt;chunk(100, function($users) &#123; // 处理结果集... return false;&#125;); 获取数据列值列表如果想要获取包含单个列值的数组，可以使用 lists 方法，在本例中，我们获取所有 title 的数组： 1$titles = DB::table('roles')-&gt;lists('title'); 在还可以在返回数组中为列值指定更多的自定义键（该自定义键必须是该表的其它字段列名，否则会报错）： 12345$roles = DB::table('roles')-&gt;lists('title', 'name');foreach ($roles as $name =&gt; $title) &#123; echo $title;&#125; 聚合函数队列构建器还提供了很多聚合方法，比如count, max, min, avg, 和 sum，你可以在构造查询之后调用这些方法： 12$users = DB::table('users')-&gt;count();$price = DB::table('orders')-&gt;max('price'); 当然，你可以联合其它查询字句和聚合函数来构建查询： 1$price = DB::table('orders')-&gt;where('finalized', 1)-&gt;avg('price'); 查询指定查询子句当然，我们并不总是想要获取数据表的所有列，使用 select 方法，你可以为查询指定自定义的 select 子句： 1$users = DB::table('users')-&gt;select('name', 'email as user_email')-&gt;get(); distinct 方法允许你强制查询返回不重复的结果集：1$users = DB::table('users')-&gt;distinct()-&gt;get(); 如果你已经有了一个查询构建器实例并且希望添加一个查询列到已存在的select子句，可以使用addSelect方法： 12$query = DB::table('users')-&gt;select('name');$users = $query-&gt;addSelect('age')-&gt;get(); 原生表达式有时候你希望在查询中使用原生表达式，这些表达式将会以字符串的形式注入到查询中，所以要格外小心避免被SQL 注入。想要创建一个原生表达式，可以使用 DB::raw 方法： 12345$users = DB::table('users') -&gt;select(DB::raw('count(*) as user_count, status')) -&gt;where('status', '&lt;&gt;', 1) -&gt;groupBy('status') -&gt;get(); 连接内连接（等值连接）查询构建器还可以用于编写基本的 SQL “内连接”，你可以使用查询构建器实例上的 join 方法，传递给 join 方法的第一次参数是你需要连接到的表名，剩余的其它参数则是为连接指定的列约束，当然，正如你所看到的，你可以在单个查询中连接多张表： 12345$users = DB::table('users') -&gt;join('contacts', 'users.id', '=', 'contacts.user_id') -&gt;join('orders', 'users.id', '=', 'orders.user_id') -&gt;select('users.*', 'contacts.phone', 'orders.price') -&gt;get(); 左连接如果你是想要执行“左连接”而不是“内连接”，可以使用 leftJoin 方法。该方法和 join 方法的使用方法一样： 1$users = DB::table('users')-&gt;leftJoin('posts', 'users.id', '=', 'posts.user_id')-&gt;get(); 高级连接语句 你还可以指定更多的高级连接子句，传递一个闭包到 join 方法作为该方法的第2个参数，该闭包将会返回允许你指定join子句约束的JoinClause对象： 12345DB::table('users') -&gt;join('contacts', function ($join) &#123; $join-&gt;on('users.id', '=', 'contacts.user_id')-&gt;orOn(...); &#125;) -&gt;get(); 如果你想要在连接中使用“where”风格的子句，可以在查询中使用 where 和 orWhere 方法。这些方法将会将列和值进行比较而不是列和列进行比较： 12345DB::table('users') -&gt;join('contacts', function ($join) &#123; $join-&gt;on('users.id', '=', 'contacts.user_id')-&gt;where('contacts.user_id', '&gt;', 5); &#125;) -&gt;get(); 联合查询构建器还提供了一条“联合”两个查询的快捷方式，比如，你要创建一个独立的查询，然后使用union方法将其和第二个查询进行联合： 123$first = DB::table('users')-&gt;whereNull('first_name');$users = DB::table('users')-&gt;whereNull('last_name')-&gt;union($first)-&gt;get(); unionAll 方法也是有效的，并且和 union 有同样的使用方法。 where 子句简单 where 子句And123$users = DB::table('users')-&gt;where('votes', '=', 100)-&gt;get();或$users = DB::table('users')-&gt;where('votes', 100)-&gt;get(); Or1$users = DB::table('users')-&gt;where('votes', '&gt;', 100)-&gt;orWhere('name', 'John')-&gt;get(); 更多 where 子句whereBetween 方法验证列值是否在给定值之间： 1$users = DB::table('users')-&gt;whereBetween('votes', [1, 100])-&gt;get(); whereNotBetween 方法验证列值不在给定值之间： 1$users = DB::table('users')-&gt;whereNotBetween('votes', [1, 100])-&gt;get(); whereIn 方法验证给定列的值是否在给定数组中： 1$users = DB::table('users')-&gt;whereIn('id', [1, 2, 3])-&gt;get(); whereNotIn 方法验证给定列的值不在给定数组中： 1$users = DB::table('users')-&gt;whereNotIn('id', [1, 2, 3])-&gt;get(); whereNull 方法验证给定列的值为 NULL： 1$users = DB::table('users')-&gt;whereNull('updated_at')-&gt;get(); whereNotNull 方法验证给定列的值不是 NULL：1$users = DB::table('users')-&gt;whereNotNull('updated_at')-&gt;get(); 高级 where 子句参数分组有时候你需要创建更加高级的 where 子句比如“ where exists ”或者嵌套的参数分组。Laravel查询构建器也可以处理这些。作为开始，让我们看一个在括号中进行分组约束的例子： 1234567DB::table('users') -&gt;where('name', '=', 'John') -&gt;orWhere(function ($query) &#123; $query-&gt;where('votes', '&gt;', 100) -&gt;where('title', '&lt;&gt;', 'Admin'); &#125;) -&gt;get(); 正如你所看到的，传递闭包到 orWhere 方法构造查询构建器来开始一个约束分组，该闭包将会获取一个用于设置括号中包含的约束的查询构建器实例。上述语句等价于下面的 SQL： 1select * from users where name = 'John' or (votes &gt; 100 and title &lt;&gt; 'Admin') exists语句whereExists 方法允许你编写 where existSQL 子句，whereExists 方法接收一个闭包参数，该闭包获取一个查询构建器实例从而允许你定义放置在“exists”子句中的查询： 1234567DB::table('users') -&gt;whereExists(function ($query) &#123; $query-&gt;select(DB::raw(1)) -&gt;from('orders') -&gt;whereRaw('orders.user_id = users.id'); &#125;) -&gt;get(); 上述查询等价于下面的 SQL 语句：1234select * from userswhere exists ( select 1 from orders where orders.user_id = users.id) 排序、分组、限定orderBy 方法允许你通过给定列对结果集进行排序，orderBy 的第一个参数应该是你希望排序的列，第二个参数控制着排序的方向—— asc 或 desc： 1$users = DB::table('users')-&gt;orderBy('name', 'desc')-&gt;get(); groupBy 和 having 方法用于对结果集进行分组，having 方法和 where 方法的用法类似： 1$users = DB::table('users')-&gt;groupBy('account_id')-&gt;having('account_id', '&gt;', 100)-&gt;get(); havingRaw 方法可以用于设置原生字符串作为 having 子句的值，例如，我们要找到所有售价大于 $2500 的部分： 12345$users = DB::table('orders') -&gt;select('department', DB::raw('SUM(price) as total_sales')) -&gt;groupBy('department') -&gt;havingRaw('SUM(price) &gt; 2500') -&gt;get(); 想要限定查询返回的结果集的数目，或者在查询中跳过给定数目的结果，可以使用 skip 和 take 方法： 1$users = DB::table('users')-&gt;skip(10)-&gt;take(5)-&gt;get(); 插入查询构建器还提供了 insert 方法来插入记录到数据表。insert 方法接收数组形式的列名和值进行插入操作： 1DB::table('users')-&gt;insert(['email' =&gt; 'john@example.com', 'votes' =&gt; 0]); 你甚至可以一次性通过传入多个数组来插入多条记录，每个数组代表要插入数据表的记录： 1234DB::table('users')-&gt;insert([ ['email' =&gt; 'taylor@example.com', 'votes' =&gt; 0], ['email' =&gt; 'dayle@example.com', 'votes' =&gt; 0]]); 自增ID如果数据表有自增ID，使用insertGetId方法来插入记录将会返回ID值： 123$id = DB::table('users')-&gt;insertGetId( ['email' =&gt; 'john@example.com', 'votes' =&gt; 0]); 更新当然，除了插入记录到数据库，查询构建器还可以通过使用update方法更新已有记录。update方法和insert方法一样，接收列和值的键值对数组包含要更新的列，你可以通过where子句来对update查询进行约束： 1DB::table('users')-&gt;where('id', 1)-&gt;update(['votes' =&gt; 1]); 查询构建器还提供了方便增减给定列名数值的方法。相较于编写 update 语句，这是一条捷径，提供了更好的体验和测试接口。 1234DB::table('users')-&gt;increment('votes');DB::table('users')-&gt;increment('votes', 5);DB::table('users')-&gt;decrement('votes');DB::table('users')-&gt;decrement('votes', 5); 在操作过程中你还可以指定额外的列进行更新： 1DB::table('users')-&gt;increment('votes', 1, ['name' =&gt; 'John']); 删除当然，查询构建器还可以通过 delete 方法从表中删除记录： 1DB::table('users')-&gt;delete(); 在调用 delete 方法之前可以通过添加 where 子句对 delete 语句进行约束： 1DB::table('users')-&gt;where('votes', '&lt;', 100)-&gt;delete(); 如果你希望清除整张表，也就是删除所有列并将自增ID置为 0，可以使用 truncate 方法：1DB::table('users')-&gt;truncate(); 悲观锁查询构建器还包含一些方法帮助你在select语句中实现”悲观锁“。可以在查询中使用 sharedLock 方法从而在运行语句时带一把“共享锁”。共享锁可以避免被选择的行被修改直到事务提交： 1DB::table('users')-&gt;where('votes', '&gt;', 100)-&gt;sharedLock()-&gt;get(); 此外你还可以使用 lockForUpdate 方法。“for update”锁避免选择行被其它共享锁修改或删除： 1DB::table('users')-&gt;where('votes', '&gt;', 100)-&gt;lockForUpdate()-&gt;get();]]></content>
      <categories>
        <category>Laravel</category>
      </categories>
      <tags>
        <tag>Laravel-5.1</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何从头开始写一个 PHP 项目]]></title>
    <url>%2F2017%2F12%2F15%2Fphp-init%2F</url>
    <content type="text"><![CDATA[本文是基于一个从头开始写的 PHP 项目 mg_food 进行阅读学习，该项目未用到任何框架；通过阅读该项目源码，有利于了解纯 PHP 项目的流程； 界面展示12345678910111213141516171819202122232425262728293031323334353637383940&lt;?php // 引入简易数据库操作类 include_once "ez_sql_core.php"; include_once "ez_sql_mysql.php";?&gt;&lt;?php // 定义类似配置的一些常量，这里简约化了，可以引入 phpdotenv 第三方读取 env 文件形式进行配置 define('DB_HOST', 'localhost'); ...?&gt;&lt;?php // 启用会话 session_start();?&gt;&lt;?php // 预置功能代码 // 检查用户是否登录，否则跳转到登录页 function checkLogin() &#123; if (empty($_SESSION["user"])) &#123; header("location:login.php?error=needlogin"); &#125; &#125; // 退出登录 function logOut() &#123; $_SESSION["user"] = null; &#125; ...... 其他功能性代码?&gt;&lt;!DOCTYPE html&gt; ... ... ...&lt;/html&gt; ajax 请求的接口文件 12345678910111213// 获取请求动作$action = isset($_POST["action"]) ? $_POST["action"] : "";// 登录if ($action == "login") &#123; ......&#125;// 确认商品if ($action == "ensure") &#123; ...... echo json_encode($data);&#125; 总结： 没有使用框架的项目一般都是通过 $_ 这种超全局变量做数据周转； response 返回是跳转，则使用 header 方法；返回的是 ajax 的 json 数值，则通过 echo json_encode($data) 方法；]]></content>
      <categories>
        <category>PHP</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Laravel 大将之 Mail 模块]]></title>
    <url>%2F2017%2F12%2F08%2Flaravel-mail%2F</url>
    <content type="text"><![CDATA[本文是基于 Laravel 5.1 版本的 Mail 模块代码进行分析书写； Laravel 基于目前流行的 SwiftMailer 库提供了一套干净清爽的邮件 API。Laravel 为 SMTP、Mailgun、Mandrill、Amazon SES、PHP 的 mail 函数，以及sendmail提供了驱动，从而允许你快速通过本地或云服务发送邮件。 官方 API 地址 https://laravel.com/api/5.1/Illuminate/Mail.html 文件结构Mail 模块的文件格局及功能如下图所示： 在 MailServiceProvider 文件中，此服务提供者的 register 方法依次做了以下的事： 向服务容器注入驱动管理服务 swift.transport，对应调用的类是 TransportManager； 向服务容器注入邮件管理服务 swift.mailer，对应调用的类是 Swift_Mailer； 向服务容器注入 Laravel 自定义邮件管理服务 mailer， 对应的类是 Illuminate\Mail\Mailer；首先，实例化 Mailer 对象，参数为 $app[&#39;view&#39;]、$app[&#39;swift.mailer&#39;]、 $app[&#39;events&#39;]；其次，给 Mailer 实例绑定 容器$app 、日志器$app-&gt;make(&#39;Psr\Log\LoggerInterface&#39;)、队列$app[&#39;queue.connection&#39;]对象；然后，从config/mail.php 读取 from 和 to 参数，如果存在，即绑定到 Mailer对象中；最后，根据 config/mail.php配置文件的 pretend 参数，修改 Mailer对象的 pretending 私有变量，如果该私有变量为 true，则不实际发送邮件，而是写到日志中，便于本地开发调试； Demo准备一个用于发送文件的视图，内容如下 1234567&lt;body&gt; &#123;!! $content !!&#125; &lt;br&gt; &lt;br&gt; ### 系统邮件 请勿回复 ### &lt;/body&gt; 具体调用代码片段： 12345Mail::send('mail.email', ['content' =&gt; 'Hi！请查收补货单。'], function ($message) use ($email, $file) &#123; @$message-&gt;to([$email]); // 发送给收件人 @$message-&gt;subject('主题'); @$message-&gt;attach($file); // 绑定附件 &#125;); 参考 [ Laravel 5.1 文档 ] 服务 —— 邮件]]></content>
      <categories>
        <category>Laravel</category>
      </categories>
      <tags>
        <tag>Laravel-5.1</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[API 测试插件 Postman]]></title>
    <url>%2F2017%2F12%2F06%2Fapi-postman%2F</url>
    <content type="text"><![CDATA[具体使用参考官网 https://www.getpostman.com/docs/; Postman 是 Google 开发的一款功能强大的网页调试与发送网页 HTTP 请求，并能运行测试用例的的 Chrome 插件。其主要功能包括 模拟各种 HTTP 请求从常用的 GET、POST 到 RESTful 的 PUT 、 DELETE … 等等。 甚至还可以发送文件、送出额外的 header。 Collection 功能（测试集合）Collection 是 requests 的集合，在做完一个测试的時候， 你可以把这次的 request 存到特定的 Collection 里面，如此一来，下次要做同样的测试时，就不需要重新输入。而且一个 collection 可以包含多条 request，如果我们把一个 request 当成一个 test case，那 collection 就可以看成是一个test suite。通过collection的归类，我们可以良好的分类测试软件所提供的API。而且 Collection 还可以 Import 或是 Share 出来，让团队里面的所有人共享你建立起來的 Collection。 人性化的 Response 整理一般在用其他工具来测试的時候，response 的内容通常都是纯文字的 raw， 但如果是 JSON，就是塞成一整行的 JSON。这会造成阅读的障碍 ，而 Postman 可以针对 response 内容的格式自动美化。 JSON、 XML 或是 HTML 都會整理成我们可以阅读的格式。 内置测试脚本语言Postman 支持编写测试脚本，可以快速的检查 request 的结果，并返回测试结果。 设定变量与环境Postman 可以自由设定变量与 Environment，一般我们在编辑 request，校验 response 的时候，总会需要重复输入某些字符，比如url，postman允许我们设定变量来保存这些值。并且把变量保存在不同的环境中。比如，我们可能会有多种环境， development 、 staging 或 local， 而这几种环境中的 request URL 也各不相同，但我们可以在不同的环境中设定同样的变量，只是变量的值不一样，这样我们就不用修改我们的测试脚本，而测试不同的环境。 官方文档目录 运行 Postman 安装和更新 发送第一个请求 创建第一个collection Postman 面板 Postman 账户 同步数据 Settings 设置 New 按钮 发送 API 请求 请求 响应 历史记录 API 请求出错诊断 调试与日志 权限认证 cookie 管理 SSL 证书 捕捉 http 请求 拦截器扩展 代理 生成代码片段 发送 SOAP 请求 创建 collection 创建 collection 共享 collection 管理 collection 示例 数据导入与导出 介绍脚本 Postman 脚本的介绍 请求前的脚本 请求后的脚本 Test 脚本常用示例 指定 Collection Runder 执行的顺序 Postman 沙盒 Postman 沙盒提供的 API 环境变量和全局变量 变量 环境变量管理 全局变量管理 运行 collections 介绍 collection run 在 collection run 使用环境变量 使用 Data files 多次执行 建立工作流 共享 collection run 调试 collection run Newman 和 Jenkins 集成 和 Travis CI 集成 docker 运行 newman 团队仓库 设置一个团队仓库 共享 活动摘要和保存 collections 搜索 冲突 API 文档 API 文档的介绍 查看文档 环境变量和环境模板 用 Markdown 书写文档 发布公共文档 添加和验证自定义域名 添加团队名和 logo 监控 对监控的简介 设置一个监控器 查看监控结果 监控 API 和站点 设置接收警报 关于监控的付费 诊断监控 监控器的常见问题 模拟服务器 设置一个模拟服务器 示例 使用 Postman Pro API 来 Mock 匹配逻辑]]></content>
      <tags>
        <tag>Postman</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 不挂断运行命令工具 nohup]]></title>
    <url>%2F2017%2F11%2F28%2Flinux-nohup%2F</url>
    <content type="text"><![CDATA[nohup 命令运行由 Command 参数和任何相关的 Arg 参数指定的命令，忽略所有挂断（SIGHUP）信号。在注销后使用 nohup 命令运行后台中的程序。要运行后台中的 nohup 命令，添加 &amp; （ 表示“and”的符号）到命令的尾部。 如果不将 nohup 命令的输出重定向，输出将附加到当前目录的 nohup.out 文件中。如果当前目录的 nohup.out 文件不可写，输出重定向到 $HOME/nohup.out 文件中。如果没有文件能创建或打开以用于追加，那么 Command 参数指定的命令不可调用。如果标准错误是一个终端，那么把指定的命令写给标准错误的所有输出作为标准输出重定向到相同的文件描述符。 比如要执行 laravel 的队列监听：如果 session 会话关闭，则监听会断开； 1php artisan queue:listen session 会话意外关闭，还想继续执行监听，可以执行： 1nohup php artisan queue:listen session 会话意外关闭，还想继续执行监听，同时不阻塞命令行输入，执行： 1nohup php artisan queue:listen &amp;]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux Tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 后台进程管理利器 supervisor]]></title>
    <url>%2F2017%2F11%2F28%2Flinux-supervisor%2F</url>
    <content type="text"><![CDATA[Linux 的后台进程运行有好几种方法，例如 nohup，screen 等，但是，如果是一个服务程序，要可靠地在后台运行，我们就需要把它做成 daemon，最好还能监控进程状态，在意外结束时能自动重启。 supervisor 就是用 Python 开发的一套通用的进程管理程序，能将一个普通的命令行进程变为后台 daemon，并监控进程状态，异常退出时能自动重启。 官方文档参考 http://supervisord.org/index.html 安装 supervisor在 centos 上通过 yum 安装 1yum -y install supervisor supervisor 安装完成后会生成三个执行程序：supervisortd、supervisorctl、/etc/supervisord.conf，分别是 supervisor 的守护进程服务（用于接收进程管理命令）、客户端（用于和守护进程通信，发送管理进程的指令）、生成初始配置文件程序。 配置文件supervisord 配置123456789101112131415161718192021222324252627282930313233[supervisord]http_port=/var/tmp/supervisor.sock ; UNIX socket 文件，supervisorctl 会使用;http_port=127.0.0.1:9001 ; Web 管理后台运行的 IP 和端口，如果开放到公网，需要注意安全性;sockchmod=0700 ; socket 文件的 mode，默认是 0700;sockchown=nobody.nogroup ; socket 文件的 owner，格式： uid:gid;umask=022 ; (process file creation umask;default 022)logfile=/var/log/supervisor/supervisord.log ; 日志文件，默认是 $CWD/supervisord.loglogfile_maxbytes=50MB ; 日志文件大小，超出会 rotate，默认 50MBlogfile_backups=10 ; 日志文件保留备份数量默认 10loglevel=info ; 日志级别，默认 info，其它: debug,warn,tracepidfile=/var/run/supervisord.pid ; pid 文件nodaemon=false ; 是否在前台启动，默认是 false，即以 daemon 的方式启动minfds=1024 ; 可以打开的文件描述符的最小值，默认 1024minprocs=200 ; 可以打开的进程数的最小值，默认 200;nocleanup=true ; (don't clean up tempfiles at start;default false);http_username=user ; 登录管理后台的用户名;http_password=123 ; 登录管理后台的密码;childlogdir=/tmp ; ('AUTO' child log dir, default $TEMP);user=chrism ; (default is current user, required if root);directory=/tmp ; (default is not to cd during start);environment=KEY=value ; (key value pairs to add to environment)[supervisorctl]serverurl=unix:///var/tmp/supervisor.sock ; use a unix:// URL for a unix socket;serverurl=http://127.0.0.1:9001 ; use an http:// url to specify an inet socket;username=chris ; should be same as http_username if set;password=123 ; should be same as http_password if set;prompt=mysupervisor ; cmd line prompt (default "supervisor"); 包含其他的配置文件[include]files = relative/directory/*.ini ; 可以是 *.conf 或 *.ini program 配置可以把所有配置项都写到 supervisord.conf 文件里，但并不推荐这样做，而是通过 include 的方式把不同的程序（组）写到不同的配置文件里。 为了举例，我们新建一个目录 /etc/supervisor/ 用于存放这些配置文件，相应的，把 /etc/supervisord.conf 里 include 部分的的配置修改一下： 12[include]files = /etc/supervisor/*.conf 假设有个用 Python 和 Flask 框架编写的用户中心系统，取名 usercenter，用 gunicorn (http://gunicorn.org/) 做 web 服务器。项目代码位于 /home/leon/projects/usercenter，gunicorn 配置文件为 gunicorn.py，WSGI callable 是 wsgi.py 里的 app 属性。所以直接在命令行启动的方式可能是这样的： 12cd /home/leon/projects/usercentergunicorn -c gunicorn.py wsgi:app 现在编写一份配置文件来管理这个进程（需要注意：用 supervisord 管理时，gunicorn 的 daemon 选项需要设置为 False）12345678910111213141516[program:usercenter]directory = /home/leon/projects/usercenter ; 程序的启动目录command = gunicorn -c gunicorn.py wsgi:app ; 启动命令，可以看出与手动在命令行启动的命令是一样的autostart = true ; 在 supervisord 启动的时候也自动启动autorestart = true ; 程序异常退出后自动重启startsecs = 5 ; 启动 5 秒后没有异常退出，就当作已经正常启动了startretries = 3 ; 启动失败自动重试次数，默认是 3user = leon ; 用哪个用户启动redirect_stderr = true ; 把 stderr 重定向到 stdout，默认 falsestdout_logfile_maxbytes = 20MB ; stdout 日志文件大小，默认 50MBstdout_logfile_backups = 20 ; stdout 日志文件备份数; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件）stdout_logfile = /data/logs/usercenter_stdout.log ; 可以通过 environment 来添加需要的环境变量，一种常见的用法是修改 PYTHONPATH; environment=PYTHONPATH=$PYTHONPATH:/path/to/somewhere 此举例部分参考 使用 supervisor 管理进程； 启动关闭supervisor 服务器端启动 supervisor 服务 1supervisord -c /etc/supervisord.conf 停止 supervisor 服务 123kill -9 $(ps -ef|grep supervisor | awk '&#123;print $2&#125;')或kill -9 `ps -ef|grep supervisor | awk '&#123;print $2&#125;'` supervisorctlSupervisorctl 是 supervisord 的一个命令行客户端工具，启动时需要指定与 supervisord 使用同一份配置文件，否则与 supervisord 一样按照顺序查找配置文件。 1supervisorctl -c /etc/supervisord.conf 上面这个命令会进入 supervisorctl 的 shell 界面，然后可以执行不同的命令了： 123456&gt; status # 查看程序状态&gt; stop usercenter # 关闭 usercenter 程序&gt; start usercenter # 启动 usercenter 程序&gt; restart usercenter # 重启 usercenter 程序&gt; reread # 读取有更新（增加）的配置文件，不会启动新添加的程序&gt; update # 重启配置文件修改过的程序 上面这些命令都有相应的输出，除了进入 supervisorctl 的 shell 界面，也可以直接在 bash 终端运行： 123456$ supervisorctl status$ supervisorctl stop usercenter$ supervisorctl start usercenter$ supervisorctl restart usercenter$ supervisorctl reread$ supervisorctl update]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux Tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Symfony 组件之 Finder]]></title>
    <url>%2F2017%2F11%2F27%2Fsymfony-finder%2F</url>
    <content type="text"><![CDATA[Finder 组件用来遍历文件或目录； github的仓库地址链接 Method 方法名 参数 描述 create 创建新的 Finder 对象 directories 约束只匹配目录 files 约束只匹配文件 depth $level 针对目录或文件的目录范围或深度(0, 1, 2…) date $date 针对文件的修改时间的约束比如 &#39;&gt;= 2005-10-15&#39;、since yesterday name $pattern 针对文件名的匹配约束比如 &#39;*.php&#39;、&#39;/\.php$/&#39; notName $pattern 针对文件名的不匹配约束比如 &#39;*.php&#39;、&#39;/\.php$/&#39; contains $pattern 针对文件内容的匹配约束比如 &#39;Lorem ipsum&#39;、&#39;/Lorem ipsum/i&#39; notContains $pattern 针对文件内容的不匹配约束比如 &#39;Lorem ipsum&#39;、&#39;/Lorem ipsum/i&#39; path $pattern 针对文件名路径的匹配约束比如 &#39;some/special/dir&#39; notPath $pattern 针对文件名路径的不匹配约束比如 &#39;some/special/dir&#39; size $size 针对文件大小的匹配约束比如 &#39;&gt; 10K&#39;、&#39;&lt;= 1Ki&#39; exclude $dirs 排除掉哪些目录 ignoreDotFiles $ignoreDotFiles 参数决定是否忽略隐藏文件（即以 . 开始的文件） ignoreVCS $ignoreVCS 布尔参数决定是否忽略.svn、_svn、CVS、_darcs、.arch-params、.monotone、.bzr、.git、.hg 这些 VCS 格式 addVCSPattern $pattern 添加 VCS 模式类别，参数为数组 sort \Closure $closure 根据匿名函数排序 sortByName 根据文件名或目录名排序 sortByType 根据文件类型排序 sortByAccessedTime 根据文件的访问时间排序 sortByChangedTime 根据文件inode的修改时间排序 sortByModifiedTime 根据文件的修改时间排序 filter 根据匿名函数筛选 followLinks Forces the following of symlinks. ignoreUnreadableDirs $ignore 布尔参数决定是否忽略不可读的目录 in $dirs 约束匹配文件在哪些目录中 getIterator 获取当前 Finder 迭代器 append $iterator Appends an existing set of files/directories to the finder count 获取当前 Finder 迭代器匹配结果的数目 searchInDirectory $dir 官方的 DemoDemo11234567891011121314use Symfony\Component\Finder\Finder;$finder = new Finder();$iterator = $finder -&gt;files() -&gt;name('*.php') -&gt;depth(0) -&gt;size('&gt;= 1K') -&gt;in(__DIR__);foreach ($iterator as $file) &#123; print $file-&gt;getRealpath()."\n";&#125; Demo212345678$s3 = new \Zend_Service_Amazon_S3($key, $secret);$s3-&gt;registerStreamWrapper("s3");$finder = new Finder();$finder-&gt;name('photos*')-&gt;size('&lt; 100K')-&gt;date('since 1 hour ago');foreach ($finder-&gt;in('s3://bucket-name') as $file) &#123; print $file-&gt;getFilename()."\n";&#125; 上面 Demo 中的 foreach 循环中的 $file 是 &quot;Symfony\Component\Finder\SplFileInfo&quot;类实例，该类提供 getRelativePathname 方法来获取文件名；]]></content>
      <tags>
        <tag>Symfony</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Superset 分析示例数据]]></title>
    <url>%2F2017%2F11%2F22%2Fsuperset-demo-example%2F</url>
    <content type="text"><![CDATA[superset 默认提供 main 数据库（sqlite db），这个数据库存放整个 superset 系统的用户、角色、权限、数据集等数据，还存放预备的示例数据； 在数据表栏，默认暴露的数据表有 multiformat_time_series、 birth_france_by_region、 long_lat、 random_time_series、 birth_names、 wb_health_population、 energy_usage 六个；只有管理员才有权利暴露数据库中的哪些数据表可以在 superset中作图表展示； 切片是每一个要展示图表的最小操作单元，基于暴露的数据表作分析；目前直接在切片页面进行创建，只支持单表；但是在 SQL 工具箱自己写 sql 来创建分片是支持多表关联； 一系列切片可以放在一个看板（也叫 仪表盘）集中展示； 下面开始分析各个切片； 基于 multiformat_time_series 数据表的例子multiformat_time_series 表记录时间的各种形式； 列名 类型 描述 ds date 记录创建时间 （只有日期） ds2 datetime 记录创建时间 （日期加时间） epoch_ms bigint 记录时间时的毫秒 epoch_s bigint 记录时间时的秒 string0 varchar(100) 记录时间，格式如 2017-07-19 06:23:33.000000 string1 varchar(100) 记录时间，格式如 2017-07-19^06:23:33 string2 varchar(100) 记录时间，格式如 20170719-062333 string3 varchar(100) 记录时间，格式如 2017/07/1906:23:33.000000 切片Calendar Heatmap multiformat 0图表类型：时间热力图图表意义：类似于 github 上的打卡记录； 复盘： Time 列 对指定的时间列作筛选，时间字段选择 ds ， Time Grain 时间间隔选择 Time Column值（也就是每一个记录值都是一个时间节点）， Since 选择 1 years ago， Until 选择 now Query 列度量选择 count(*)； Options 列Domain 选择 month， subdomain 选择 day； 基于 birth_france_by_region 数据表的例子birth_france_by_region 表记录法国各城市在历年的人口出生数量； 列名 类型 描述 DEPT_ID varchar(10) 法国城市代号 … bigint 2003 年 2014 年的数据 date date 记录的创建时间 切片Birth in France by department in 2016图表类型：国家地图图表意义：直接在国家地图上展现人口数量； 复盘： Time 列 对指定的时间列作筛选，时间字段选择 year ， Time Grain 时间间隔选择 Time Column值（也就是每一个记录值都是一个时间节点）， Since 选择 无穷， Until 选择 无穷 Query 列ISO 3166-2 选择 DEPT_ID， 度量选择 avg_2004； Options 列Country Name 选择 France； 基于 random_time_series 数据表的例子random_time_series 表只有一列，记录时间； 列名 类型 描述 ds datetime 时间 切片Calendar Heatmap图表类型：时间热力图图表意义：类似于 github 上的打卡记录； 复盘： Time 列 对指定的时间列作筛选，时间字段选择 year ， Time Grain 时间间隔选择 Time Column值（也就是每一个记录值都是一个时间节点）， Since 选择 1 years ago， Until 选择 now Query 列度量选择 count(*)； Options 列Domain 选择 month， subdomain 选择 day； 基于 birth_names 数据表的例子birth_names 表记录一些学生的姓名、姓名、居住地、出生日期等信息； 列名 类型 描述 ds datetime 出生日期 gender varchar(16) 性别 name varchar(255) 姓名 num bigint 数量 state varchar(10) 所在州 sum_boys bigint 相同姓名男生的数量 sum_girls bigint 相同姓名女生的数量 切片Number of Girls图表类型：数字图表意义：直接显示女生数量； 复盘： Time 列 对指定的时间列作筛选，时间字段选择 year ， Time Grain 时间间隔选择 Time Column值（也就是每一个记录值都是一个时间节点）， Since 选择 100 years ago， Until 选择 now Query 列度量选择 sum__num； Chart Options 列Subheader 选择 total female participants 筛选列gender in girl Pivot Table图表类型：透视表图表意义：二维表展示各州各个姓名的人数； 复盘： Time 列 对指定的时间列作筛选，时间字段选择 year ， Time Grain 时间间隔选择 Time Column值（也就是每一个记录值都是一个时间节点）， Since 选择 100 years ago， Until 选择 now Query 列Group by 选择 name， columns 选择 state， Metrics 选择 sum__num Pivot Options 列Aggregation function 选择 sum Name Cloud图表类型：词汇云图表意义：优雅地展示姓名，字体大小反映使用次数的多寡； 复盘： Time 列 对指定的时间列作筛选，时间字段选择 year ， Time Grain 时间间隔选择 Time Column值（也就是每一个记录值都是一个时间节点）， Since 选择 100 years ago， Until 选择 now Query 列Series 使用 name， 度量使用 sum__num， Series limit 使用 100 Options 列Font Size From 使用 10， Font Size To 使用 70， Rotation 使用 square； Title图表类型：标记图表意义：可以显示自定义的 html 代码； 复盘： Time 列 对指定的时间列作筛选，时间字段选择 year ， Time Grain 时间间隔选择 Time Column值（也就是每一个记录值都是一个时间节点）， Since 选择 100 years ago， Until 选择 now CodeMarkup Type 选择 htmlCode 选择 12345678 &lt;div style="text-align:center"&gt; &lt;h1&gt;Birth Names Dashboard&lt;/h1&gt; &lt;p&gt; The source dataset came from &lt;a href="https://github.com/hadley/babynames" target="_blank"&gt;[here]&lt;/a&gt; &lt;/p&gt; &lt;img src="/static/assets/images/babytux.jpg"&gt;&lt;/div&gt; Average and Sum Trends图表类型：Dual Axis Line Chart图表意义：反映姓名使用率的平均值与总值随着时间的变化； 复盘： Time 列 对指定的时间列作筛选，时间字段选择 year ， Time Grain 时间间隔选择 Time Column值（也就是每一个记录值都是一个时间节点）， Since 选择 100 years ago， Until 选择 now Y Axis 1 列Left Axis Metrics 选择 avg__num； Y Axis 2 列Right Axis Metrics 选择 sum__num； Trends图表类型：时间序列 - 折线图图表意义：反映姓名随着时间的使用率； 复盘： Time 列 对指定的时间列作筛选，时间字段选择 year ， Time Grain 时间间隔选择 Time Column值（也就是每一个记录值都是一个时间节点）， Since 选择 100 years ago， Until 选择 now Query 列Metrics 选择 sum__num， Group By 选择 name， Series limit 选择 25 （显示多少组数据）； Genders by State图表类型：分布柱状图图表意义：统计各州的男女人数； Time 列 对指定的时间列作筛选，时间字段选择 ds ， Time Grain 时间间隔选择 Time Column值（也就是每一个记录值都是一个时间节点）， Since 选择 100 years ago， Until 选择 now Query 列 Metrics 依次选择 sum__sum_girls、sum__sum_boys，Series 选择 state， Row limit 选择 50000; 筛选列state not in other Genders图表类型：Pie Chart图表意义：饼图直接反映男女人数的比例大小； Time 列 对指定的时间列作筛选，时间字段选择 ds ， Time Grain 时间间隔选择 Time Column值（也就是每一个记录值都是一个时间节点）， Since 选择 100 years ago， Until 选择 now Query 列 Metrics 选择 sum__num，Group By 选择 gender; Participants图表类型：数字和趋势线图表意义：直观地反映每年参与的人数走势； Time 列 对指定的时间列作筛选，时间字段选择 ds ， Time Grain 时间间隔选择 Time Column值（也就是每一个记录值都是一个时间节点）， Since 选择 100 years ago， Until 选择 now Query 列 度量选择 sum__num Boys图表类型：表视图图表意义：表格形式展现男生姓名及人数； 复盘： Time 列 对指定的时间列作筛选，时间字段选择 ds ， Time Grain 时间间隔选择 Time Column值（也就是每一个记录值都是一个时间节点）， Since 选择 100 years ago， Until 选择 now GROUP BY 列Group By 选择 name， Metrics 选择 sum__num Options 列Row limit 选择 50000， Page Length 选择 0 筛选列gender in boy Girls图表类型：表视图图表意义：表格形式展现女生姓名及人数； 复盘： Time 列 对指定的时间列作筛选，时间字段选择 ds ， Time Grain 时间间隔选择 Time Column值（也就是每一个记录值都是一个时间节点）， Since 选择 100 years ago， Until 选择 now GROUP BY 列Group By 选择 name， Metrics 选择 sum__num Options 列Row limit 选择 50000， Page Length 选择 0 筛选列gender in girl 基于 wb_health_population 数据表的例子wb_health_population 表记录不同地域不同国家历年来的人口数量； 列名 类型 描述 country_code varchar(3) 国家代号 country_name varchar(255) 国家名 region varchar(255) 地区 year datetime 年份 … float 该国家在该年份的统计数据 切片Parallel Coordinates图表类型：平行坐标图表意义：未知； 复盘： Time 列 对指定的时间列作筛选，时间字段选择 year ， Time Grain 时间间隔选择 Time Column值（也就是每一个记录值都是一个时间节点）， Since 选择 2011-01-01 00:00:00， Until 选择 2011-01-01 00:00:00 Query 列Series 选择 country_name， Metrics 依次选择 sum__SP_POP_TOTL 、sum__SP_RUR_TOTL_ZS 和 sum__SH_DYN_AIDS； Treemap图表类型：树状图图表意义：根据国家所占长方形面积的大小，直观看出各国家总人口占世界总人口的比例； 复盘： Time 列 对指定的时间列作筛选，时间字段选择 year ， Time Grain 时间间隔选择 Time Column值（也就是每一个记录值都是一个时间节点）， Since 选择 1960-01-01 00:00:00， Until 选择 now Query 列Metrics 选择 sum__SP_POP_TOTAL， Group By 选择 region 和 country_name；也就是以地区和国家分组，统计总人数； Box plot图表类型：箱线图图表意义：粗略地看出每年地区的人口数是否具有有对称性，分布的分散程度等信息； 箱线图是用数据中的五个统计量：最小值、第一四分位数（Q1）、中位数（Q2）、第三四分位数（Q3）与最大值来描述数据的一种方法 复盘： Time 列 对指定的时间列作筛选，时间字段选择 year ， Time Grain 时间间隔选择 Time Column值（也就是每一个记录值都是一个时间节点）， Since 选择 1960-01-01 00:00:00， Until 选择 now Query 列Metrics 选择 sum__SP_POP_TOTAL， Group By 选择 region， Series limit 选择 25 （显示多少组数据）； World&#39;s Pop Growth图表类型：时间序列-堆积图图表意义：以年为维度，体现世界总人口的变化，以及每个区域人口在任意一个时间大概的占比； 复盘： Time 列 对指定的时间列作筛选，时间字段选择 year ， Time Grain 时间间隔选择 Time Column值（也就是每一个记录值都是一个时间节点）， Since 选择 1960-01-01 00:00:00， Until 选择 now Query 列Metrics 选择 sum__SP_POP_TOTAL， Group By 选择 region， Series limit 选择 25 （显示多少组数据）； Rural Breakdown图表类型：环状层次图图表意义：查看某一年，国家人口占世界人口的百分比，国家人口占地域人口的百分比，国家农村人口占国家总人口的百分比； 复盘： Time 列 对指定的时间列作筛选，时间字段选择 year ， Time Grain 时间间隔选择 Time Column值（也就是每一个记录值都是一个时间节点）， Since 选择 2011-01-01 00:00:00， Until 选择 2011-01-01 00:00:00 Query 列Hierarchy 依次选择 region、country_name, Primary Metric 选择 sum__SP_POP_TOTAL， Secondary Metric 选择 sum__SP_RUR_TOTAL， Row limit 选择 50000 （数据记录 Limit 值）； Life Expectancy VS Rural %图表类型：气泡图图表意义：未知；国表特点：根据国家的两个数据作 x轴 和 y轴 的定位，气泡大小取决于给定的 sum__SP_POP_TOTL 值 复盘： Time 列 对指定的时间列作筛选，时间字段选择 year ， Time Grain 时间间隔选择 Time Column值（也就是每一个记录值都是一个时间节点）， Since 选择 2011-01-01 00:00:00， Until 选择 2011-01-02 00:00:00 Query 列Series 选择 region， Entity 选择 country_name， Bubble Size 选择 sum_SP_POP_TOTL， Series limit选择 0（列出所有组数据） 筛选列country_code not in [ TCA、 MNP、 DMA、 MHL、MCO、SXM、CYM、 TUV、IMY、KNA、ASM、ADO、AMA、PLW ] Bubbles 列Bubbles Size 选择 sum__SP_POP_TOTL， Max Bubble Size 选择 25 X Axis 列X Axis 选择 sum__SP_RUR_TOTL_ZS Y Axis 列Y Axis 选择 sum__SP_DYN_LE00_IN % Rural图表类型：世界地图图表意义：以世界地图的方式展现国家总人口和农村人口比例； 复盘： Time 列 对指定的时间列作筛选，时间字段选择 year ， Time Grain 时间间隔选择 Time Column值（也就是每一个记录值都是一个时间节点）， Since 选择 2014-01-01 00:00:00， Until 选择 2014-01-02 00:00:00 Query 列Country Control 选择 country_code， Country Field Type 选择 code ISO 3166-1 alpha-3(cca3)， Metric for color 选择 sum_SP_RUR_TOTL_ZS； Bubbles 列Bubbles Size 选择 sum__SP_POP_TOTL， Max Bubble Size 选择 25； 气泡显示国家总人口； Growth Rate图表类型：时间序列-折线图图表意义：折线的方式体现各个国家人口增长的走势； 复盘： Time 列 对指定的时间列作筛选，时间字段选择 year ， Time Grain 时间间隔选择 Time Column值（也就是每一个记录值都是一个时间节点）， Since 选择 1960-01-01 00:00:00， Until 选择 2014-01-02 00:00:00 Query 列Metrics 选择 sum__SP_POP_TOTAL， Group By 选择 country_name， Series limit 选择 25 （显示多少组数据）； Advanced Analytics 列Peroid Ratio 选择 10 (意义还不清楚)； Most Populated Countries图表类型：表视图图表意义：表格形式展现国家人口； 复盘： Time 列 对指定的时间列作筛选，时间字段选择 year ， Time Grain 时间间隔选择 Time Column值（也就是每一个记录值都是一个时间节点）， Since 选择 2000-01-01 00:00:00， Until 选择 2014-01-02 00:00:00 GROUP BY 列Group By 选择 country_name， Metrics 选择 sum__SP_POP_TOTAL Options 列Row limit 选择 50000， Page Length 选择 0 World&#39;s Population图表类型：数字和趋势线图表意义：暴力展示世界总人口的走势和数字； 复盘： Time 列 对指定的时间列作筛选，时间字段选择 year ， Time Grain 时间间隔选择 Time Column值（也就是每一个记录值都是一个时间节点）， Since 选择 2014-01-01 00:00:00， Until 选择 2014-01-02 00:00:00 Query 列度量选择 sum__SP_POP_TOTAL Chart Options 列Comparison Period Lag 选择 1， Comparison suffix 选择 年增长率 Region Filter图表类型：Filter Box图表显示：一个输入框，列出地域名（阴影表示人口数）或国家名（阴影表示人口数）； 复盘： Time 列 对指定的时间列作筛选，时间字段选择 year ， Time Grain 时间间隔选择 Time Column值（也就是每一个记录值都是一个时间节点）， Since 选择 2014-01-01 00:00:00， Until 选择 2014-01-02 00:00:00 Query 列Filter controls 选择 region 和 country_name； 度量选择 sum_SP_POP_TOTAL 基于 energy_usage 数据表的例子energy_usage 表记录能源的流通； 列名 类型 描述 source varchar(255) 能源的来源 target varchar(255) 能源周转后的形态 value float 值 切片Heatmap图表类型：热力图图表意义：看出能源互转的热度与比例； 复盘： Query 列X 轴选择 source，Y 轴选择 target， 度量选择 sum__value Energy Force Layout图表类型：有向图图表意义： 直观地看出能源互转 复盘： Query 列Source / Target 依次选择 source 和 target， 度量选择 sum__value，Row limit 选择 5000 （表示读取多少数据作分析） Energy Sankey图表类型：蛇形图图表意义： 更好地体现能源周转的值与比例 复盘： Query 列Source / Target 依次选择 source 和 target， 度量选择 sum__value，Row limit 选择 5000 （表示读取多少数据作分析）]]></content>
      <tags>
        <tag>Superset</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Superset 介绍与环境搭建]]></title>
    <url>%2F2017%2F11%2F21%2Fsuperset-install%2F</url>
    <content type="text"><![CDATA[介绍Superset 是一个数据挖掘和可视化的 Web 应用； Superset 提供以下功能: 快速创建可交互的、直观形象的数据集合 有丰富的可视化方法来分析数据，且具有灵活的扩展能力 简单, 代码自由, 可对暴露在仪表盘上的数据进行切片操作； 仪表盘和图表是更深层次分析的起点； 丰富的在线 SQL 编辑器，以及一个简单的工作流来创建任何结果集的可视化。 具有可扩展的、高粒度的安全模型，可以用复杂规则来控制访问权限。目前支持主要的认证提供商：DB、OpenID、LDAP、OAuth、和 Flask AppBuiler 的 REMOTE_USER 使用简单的语法，就可以控制数据在 UI 中的展现方式 支持大多数 SQL 数据库 与 Druid 深度结合，可快速的分析大数据 配置缓存来快速加载仪表盘 有效链接： superset 官网 superset 官网上的文档 github - superset的仓库 Superset的技术组成：后端是基于Python，采用了 Flask、Pandas、SqlAlchemy框架等；前端用了用到了npm、react、webpack； 安装笔者基于Centos 6.8 系统安装； 安装系统环境依赖12yum -y upgrade python-setuptoolsyum -y install gcc gcc-c++ libffi-devel python-devel python-pip python-wheel openssl-devel libsasl2-devel openldap-devel 建立 python 虚拟环境123pip install virtualenvvirtualenv venv. ./venv/bin/activate # 激活，进入虚拟环境 要退出虚拟环境 deactivate 准备 python 环境与依赖1pip install --upgrade setuptools pip 安装与初始化1234567891011121314151617181920# 安装 superset；从清华的源获取pip install -i https://pypi.tuna.tsinghua.edu.cn/simple superset# 创建一个 admin 用户 (你会被提示输入 username first 和 lastname 在输入密码前)fabmanager create-admin --app superset# 初始化数据库superset db upgrade# 加载一些例子数据superset load_examples# 初始化，创建默认的角色和权限superset init# 启动 web 服务器，端口号 8088， 可以用 -p 参数指定其它端口号superset runserver# 要开启一个开发服务器，使用 -d 参数# superset runserver -d 入门操作连接 mysql准备 superset 默认安装是没有准备连接 mysql 的环境，因为需要提前准备好连接 mysql 的一些工具包及驱动 1234pip install pymysqlyum -y install mysql-develpip install mysql-python 新建 mysql 的数据库连接“数据库” 》 “数据源” 》添加新记录 数据库名 ： 起一个有标识度，自己能分辨的名称SQLAlchemy URI ： 例如 mysql+mysqldb://root:111111@192.168.1.168/test?charset=utf8在SQL工具箱中公开：勾选则可以在 sql 工具箱中操作； 点击保存；]]></content>
      <tags>
        <tag>Superset</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cenos7 网络配置、换源、更新 yum]]></title>
    <url>%2F2017%2F11%2F19%2Fcentos7-network%2F</url>
    <content type="text"><![CDATA[Centos 7 使用 ip 命令替换 ifconfig；键入命令，查看当前网络配置情况 1&gt; ip addr 从图片可以发现，保存网卡 ip 信息的配置文件名也由以前的 ifcfg-eth0 变成了 ifcfg-enp0s3; 动态IP通过编辑 /etc/sysconfig/network-scripts/ifcfg-enp0s3 123BOOTPROTO=dhcp......ONBOOT=yes 重启网络服务 service network restart 固定IP编辑 /etc/sysconfig/network-scripts/ifcfg-enp0s31234567BOOTPROTO=staticONBOOT=yesIPADDR=192.168.1.68NETMASK=255.255.255.0GATEWAY=192.168.1.1BROADCAST=192.168.1.255 编辑 /etc/resolv.conf12nameserver 192.168.1.1search bogon 重启网络服务 service network restart 附录换源123mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bakwget -P /etc/yum.repos.d http://mirrors.163.com/.help/CentOS6-Base-163.repo mv /etc/yum.repos.d/CentOS6-Base-163.repo /etc/yum.repos.d/CentOS-Base.repo yum 更新1234# 安装epel, epel是免费开源发行软件包版本库yum install -y epel-release# 更新 yumyum -y update]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Centos7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel 异常树]]></title>
    <url>%2F2017%2F11%2F18%2Flaravel-exception-tree%2F</url>
    <content type="text"><![CDATA[异常树 Exception ErrorException RuntimeException 运行时异常 UnexpectedValueException 未预期值异常 Symfony\Component\HttpKernel\Exception\HttpException Symfony\Component\HttpKernel\Exception\NotFoundHttpException Symfony\Component\HttpKernel\Exception\MethodNotAllowedHttpException Illuminate\Http\Exception\HttpResponseException http response 异常 Illuminate\Database\Eloquent\ModelNotFoundException 找不到 Model 异常 Illuminate\Database\Eloquent\MassAssignmentException Illuminate\Contracts\Encryption\DecryptException 解密异常 Illuminate\Contracts\Encryption\EncryptException 加密异常 Illuminate\Contracts\Validation\ValidationException Illuminate\Contracts\Validation\UnauthorizedException LogicException InvalidArgumentException 参数错误异常 Illuminate\Contracts\Queue\EntityNotFoundException BadFunctionCallException BadMethodCallException 调用方法异常 PDOException Illuminate\Database\QueryException 数据库查询异常 Illuminate\Auth\Access\UnauthorizedException 未认证用户 Illuminate\Contracts\Filesystem\FileNotFoundException 文件不存在 Illuminate\Session\TokenMismatchException Token不匹配异常 Illuminate\Http\Exception\PostTooLargeException post 数据量大异常 Illuminate\Container\BindingResolutionException Illuminate\Contracts\Container\BindingResolutionException 异常概要ExceptionException 是所有异常的基类。 123456789101112131415161718Exception &#123; /* 属性 */ protected string $message ; // 异常消息内容 protected int $code ; // 异常代码 protected string $file ; // 抛出异常的文件名 protected int $line ; // 抛出异常在该文件中的行号 /* 方法 */ public __construct ([ string $message = "" [, int $code = 0 [, Throwable $previous = NULL ]]] ) final public string getMessage ( void ) // 获取异常消息内容 final public Throwable getPrevious ( void ) // 返回异常链中的前一个异常 final public int getCode ( void ) // 获取异常代码 final public string getFile ( void ) // 创建异常时的程序文件名称 final public int getLine ( void ) // 获取创建的异常所在文件中的行号 final public array getTrace ( void ) // 获取异常追踪信息 final public string getTraceAsString ( void ) // 获取字符串类型的异常追踪信息 public string __toString ( void ) // 将异常对象转换为字符串 final private void __clone ( void ) // 异常克隆&#125; 异常捕捉中间件首先，定义中间件 CatchExceptionMiddleware 1234567891011121314151617181920use Closure;use Exception;use stdClass;use Illuminate\Http\Response;class CatchExceptionMiddleware &#123; public function handle($request, Closure $next) &#123; try &#123; $response = $next($request); return $response; &#125; catch (Exception $e) &#123; $response = new Response([ 'status' =&gt; 500, 'msg' =&gt; $e-&gt;getCode() . " : " . $e-&gt;getMessage(), "data" =&gt; new stdClass() ], 200); return $response; &#125; &#125;&#125; 然后在 某个ServiceProvider 中的 boot 方法执行注册： 1234567use Illuminate\Routing\Router;... public function boot(Router $router)&#123; $router-&gt;middleware('catch_exception', CatchExceptionMiddleware::class); &#125; 支持跨域中间件12345678910111213141516use Closure;class EnableCrossRequestMiddleware &#123; public function handle($request, Closure $next) &#123; $response = $next($request); $response-&gt;header('Access-Control-Allow-Origin', config('app.cross_allow_origin', '*')); $response-&gt;header('Access-Control-Allow-Headers', 'Origin, Content-Type, Cookie, Accept'); $response-&gt;header('Access-Control-Allow-Methods', 'GET, POST, PATCH, PUT, OPTIONS'); // $response-&gt;header('Access-Control-Allow-Credentials', 'true'); return $response; &#125;&#125; 其中有以下需要注意的地方： 对于跨域访问并需要伴随认证信息的请求，需要在 XMLHttpRequest 实例中指定 withCredentials 为 true； 这个中间件你可以根据自己的需求进行构建，如果需要在请求中伴随认证信息（包含 cookie，session）那么你就需要指定 Access-Control-Allow-Credentials 为 true, 因为对于预请求来说如果你未指定该响应头，那么浏览器会直接忽略该响应； 在响应中指定 Access-Control-Allow-Credentials 为 true 时，Access-Control-Allow-Origin 不能指定为 *； 后置中间件只有在正常响应时才会被追加响应头，而如果出现异常，这时响应是不会经过中间件的； 如果想要设置 Access-Control-Allow-Origin 的值为 请求的 referer 值：1234567$request_referer_info = parse_url($request-&gt;header('Referer'));$request_referer = count($request_referer_info) &gt; 1 ? $request_referer_info['scheme'] . '://' . $request_referer_info['host'] . (isset($request_referer_info['port']) ? ':' . $request_referer_info['port'] : '') : '*' $response-&gt;header('Access-Control-Allow-Origin', $$request_referer); 参考阅读 Laravel 开启跨域功能；]]></content>
      <categories>
        <category>Laravel</category>
      </categories>
      <tags>
        <tag>Laravel-5.4</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 包之pymysql]]></title>
    <url>%2F2017%2F11%2F17%2Fpython-pymysql%2F</url>
    <content type="text"><![CDATA[详细文档见官方； 安装1pip install pymysql 使用执行 Mysql 语句1234567891011121314151617181920212223242526# -*- coding: UTF-8 -*-import pymysql# 创建连接conn = pymysql.connect(host='192.168.1.168', port=3306, user='root', passwd='', db='test', charset='utf8')# 创建游标cursor = conn.cursor()# 执行 查 SQL，并返回受影响的行数#effect_row = cursor.execute("select * from hardware_device_infos")# 执行 改 SQL，并返回受影响的行数#effect_row = cursor.execute("update hardware_device_infos set number = 'DYY' where name = %s", ('电源',))# 执行 增 SQL，并返回受影响行数, 执行多次#effect_row = cursor.executemany("insert into hardware_device_infos(name, number) values(%s,%s)", [("显示器1","XSQ1"), ("显示器2","XSQ2")])# 提交，不然无法保存新建或者修改的数据conn.commit()# 关闭游标cursor.close()# 关闭连接conn.close() 获取查询数据1234567891011121314151617181920212223242526# -*- coding: UTF-8 -*-import pymysql# 创建连接conn = pymysql.connect(host='192.168.1.168', port=3306, user='root', passwd='', db='test', charset='utf8')# 创建游标cursor = conn.cursor()# 执行 查 SQL，并返回受影响的行数effect_row = cursor.execute("select * from hardware_device_infos")# 获取剩余结果的第一行数据，形如 (第一列的值，第二列的值...)row_1 = cursor.fetchone()# 获取剩余结果前 3 行数据 ((第一列的值，第二列的值...), (第一列的值，第二列的值...), (第一列的值，第二列的值...))row_2 = cursor.fetchmany(3) # 获取剩余结果所有数据 ((第一列的值，第二列的值...), (第一列的值，第二列的值...), (第一列的值，第二列的值...), ...)row_3 = cursor.fetchall()# 关闭游标cursor.close()# 关闭连接conn.close() 操作都是靠游标，在 fetch 数据时按照顺序进行，可以使用 cursor.scroll(num,mode) 来移动游标位置，如： 12cursor.scroll(1, mode='relative') # 相对当前位置移动cursor.scroll(2, mode='absolute') # 相对绝对位置移动 默认获取的数据是元祖类型，如果想要字典类型的数据 1cursor = conn.cursor(cursor=pymysql.cursors.DictCursor) 获取新创建数据自增 ID1234567891011121314151617181920212223# -*- coding: UTF-8 -*-import pymysql# 创建连接conn = pymysql.connect(host='192.168.1.168', port=3306, user='root', passwd='', db='test', charset='utf8')# 创建游标cursor = conn.cursor()# 执行 增 SQL，并返回受影响行数, 执行多次cursor.executemany("insert into hardware_device_infos(name, number) values(%s,%s)", [("显示器1","XSQ1"), ("显示器2","XSQ2")])# 提交，不然无法保存新建或者修改的数据conn.commit()# 关闭游标cursor.close()# 关闭连接conn.close()# 获取最新的自增id print cursor.lastrowid 使用 with 简化连接过程1234567891011121314151617181920212223242526272829# -*- coding: UTF-8 -*-import pymysqlimport contextlib#定义上下文管理器，连接后自动关闭连接@contextlib.contextmanagerdef mysql(host='192.168.1.168', port=3306, user='root', passwd='111111', db='test', charset='utf8'): # 创建连接 conn = pymysql.connect(host=host, port=port, user=user, passwd=passwd, db=db, charset=charset) # 创建游标 cursor = conn.cursor(cursor=pymysql.cursors.DictCursor) try: yield cursor finally: # 提交，不然无法保存新建或者修改的数据 conn.commit() # 关闭游标 cursor.close() # 关闭连接 conn.close()# 执行sqlwith mysql() as cursor: # 执行 查 SQL，并返回受影响的行数 cursor.execute("select * from hardware_device_infos") # 获取第一行数据 row_1 = cursor.fetchone() print row_1 参考阅读 Python中操作mysql的pymysql模块详解]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python-Packages</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP 性能分析工具 xhprof]]></title>
    <url>%2F2017%2F11%2F15%2Fphp-xhprof%2F</url>
    <content type="text"><![CDATA[XHProf 是 facebook 开发的一个 php 扩展，用于采集 php 程序中每个函数的性能开销。采集的数据包括：内存消耗、CPU 计算时间、函数执行时长等等。 安装下载1sudo wget https://codeload.github.com/phacility/xhprof/zip/master -O xhprof.zip 你也可以从 http://pecl.php.net/package/xhprof 这里下载。 注意：php5.4 及以上版本不能在 pecl 中下载，不支持。需要在 github 上下载 https://github.com/facebook/xhprof。另外 xhprof 已经很久没有更新过了，截至目前还不支持 php7。 安装12345cd xhprof-master/cd extension/sudo /opt/bksite/php/bin/phpizesudo ./configure --with-php-config=/opt/bksite/php/bin/php-config --enable-xhprofsudo make &amp;&amp; make install 修改配置 php.ini 123[xhprof]extension=xhprof.soxhprof.output_dir=/tmp/xhprof 定义输出文件的存放位置 使用优雅地注入目前大部分 MVC 框架都有唯一的入口文件，只需要在入口文件的开始处注入 xhprof 的逻辑 123456789101112131415161718192021require_once "/tmp/xhprof-master/xhprof_lib/utils/xhprof_lib.php";require_once "/tmp/xhprof-master/xhprof_lib/utils/xhprof_runs.php";//开启xhprofxhprof_enable(XHPROF_FLAGS_CPU + XHPROF_FLAGS_MEMORY);//注册一个函数，当程序执行结束的时候去执行它。register_shutdown_function(function() &#123; //stop profiler $xhprof_data = xhprof_disable(); //冲刷(flush)所有响应的数据给客户端 if (function_exists('fastcgi_finish_request')) &#123; fastcgi_finish_request(); &#125; $xhprof_runs = new XHProfRuns_Default(); //save the run under a namespace "xhprof_foo" $run_id = $xhprof_runs-&gt;save_run($xhprof_data, "xhprof_foo");&#125;); 但是这样免不了要修改项目的源代码，其实 php 本身就提供了更好的注入方式，比如将上述逻辑保存为 /opt/bitnami/php/etc/xhprof-inject.php，然后修改 php配置文件 php.ini 1auto_prepend_file = /opt/bitnami/php/etc/xhprof-inject.php 这样所有的 php-fpm 请求的 php 文件前都会自动注入 /opt/bitnami/php/etc/xhprof-inject.php 文件; 如果使用Nginx的话，还可以通过Nginx的配置文件设置，这样侵入性更小，并且可以实现基于站点的注入。 1fastcgi_param PHP_VALUE "auto_prepend_file=/opt/bitnami/php/etc/xhprof-inject.php"; Laravel 项目中局部使用首先，将 xhprof-master 包中的 xhprof_lib/utils/ 下的文件移到 Laravel 根目录下的 utils 文件夹中； 1cp /tmp/xhprof-master/xhprof_lib/utils/* utils/ 然后，配置文件的自动加载，在 composer.json 中修改： 12345678"autoload": &#123; "files":[ ..., "utils/xhprof_lib.php", "utils/xhprof_runs.php" ], ...&#125; 执行 composer dump-autoload； 最后在业务代码附近加如下代码：1234567xhprof_enable(XHPROF_FLAGS_NO_BUILTINS | XHPROF_FLAGS_CPU | XHPROF_FLAGS_MEMORY);// 业务代码$xhprof_data = xhprof_disable();$xhprof_runs = new \XHProfRuns_Default();$run_id = $xhprof_runs-&gt;save_run($xhprof_data, "xhprof_take_stock"); Web 页面查看Nginx 配置；（环境 bitnami） 123456789101112131415161718server &#123; listen 7777; server_name localhost; root /tmp/xhprof-master/xhprof_html; index index.php index.html; location ~* \.php$ &#123; fastcgi_pass unix:/opt/bitnami/php/var/run/www.sock; include fastcgi_params; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_index index.php; &#125; include "/opt/bitnami/nginx/conf/bitnami/phpfastcgi.conf"; include "/opt/bitnami/nginx/conf/bitnami/bitnami-apps-prefix.conf";&#125; 支持图表查看，得安装 graphviz插件； 12yum install -y libpngyum install -y graphviz 页面表格各列含义： 列名 描述 Function Name 函数名 Calls 调用次数 Calls% 调用次数占比 Incl.Wall Time(microsec) 函数运行时间（包括子函数） IWall% 函数运行时间（包括子函数）占比 Excl.Wall Time(microsec) 函数运行时间（不包括子函数） EWall% 函数运行时间（不包括子函数）占比 Incl.CPU(microsec) 函数执行花费的 CPU 时间（包括子函数） ICpu% 函数执行花费的 CPU 时间（包括子函数）占比 Excl.CPU(microsec) 函数执行花费的 CPU 时间（不包括子函数） ECpu% 函数执行花费的 CPU 时间（不包括子函数）占比 Incl.MemUse(bytes) 函数执行占用的内存（包括子函数） IMemUse% 函数执行占用的内存（包括子函数）占比 Excl.MemUse(bytes) 函数执行占用的内存（不包括子函数） EMemUse% 函数执行占用的内存（不包括子函数）占比 Incl.PeakMemUse(bytes) Incl.MemUse 峰值 IPeakMemUse% Incl.MemUse 峰值占比 Excl.PeakMemUse(bytes) Excl.MemUse 峰值 EPeakMemUse% Excl.MemUse 峰值占比 xhprof 数据保存注入代码后我们还需要实现保存 xhprof 数据以及展示数据的 UI，听起来似乎又是一大堆工作，有现成的轮子可以用吗？ 经过搜索和比较，貌似比较好的选择有 xhprof.io 以及 xhpgui。 两个项目做得事情差不多，都提供了 xhprof 数据保存功能以及一套索引展示数据的 UI，下面是一些比较 xhprof.io ✗ 年久失修 ✗ 保存xhprof数据到MySQL ✓ 支持域名、URI等多个维度的数据索引 ✓ 函数调用记录完整，内核级别函数都能显示 ✗ 无法针对个别URI开启 ✗ 注入被分割成两个文件，如果程序被强制中断时xhprof数据将无法收集 xhgui ✓ 保存xhprof数据到MongoDB ✗ 不支持域名索引 ✗ 函数调用记录不完整，部分内核级别函数（如扩展内）无法显示 ✓ 有配置文件可以控制开启条件 ✓ 注入只有一个文件 ✓ 狂拽酷炫的基于D3.js的调用关系动态图]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP-Extensions</tag>
        <tag>xhprof</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 包之 pymongo]]></title>
    <url>%2F2017%2F11%2F13%2Fpython-pymongo%2F</url>
    <content type="text"><![CDATA[详细命令及说明，点击官网指南； 常用命令包引入1234import pymongofrom pymongo import MongoClient# 使用 ID 查找需要 ObjectIDfrom bson.objectid import ObjectId 连接123client= MongoClient('localhost',27017)或client = MongoClient('mongodb://localhost:27017/') 参考阅读 python操作mongodb之基础操作]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python-Packages</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 虚拟环境工具 virtualenv]]></title>
    <url>%2F2017%2F11%2F13%2Fpython-virtualenv%2F</url>
    <content type="text"><![CDATA[常用命令创建 virtualenv进行指定项目根目录，执行 1virtualenv venv 然后，会在项目根目录下有一个venv文件夹。这个文件夹下，bin, bin/python存放在当前环境是使用的 python 解释器；所有安装的 python 库都会放在这个目录中的 lib/pythonx.x/site-packages/ 下。 指定 python 版本12345#创建python2.7虚拟环境➜ Test git:(master) ✗ virtualenv -p /usr/bin/python2.7 ENV2.7Running virtualenv with interpreter /usr/bin/python2.7New python executable in ENV2.7/bin/pythonInstalling setuptools, pip...done. 1234567#创建python3.4虚拟环境➜ Test git:(master) ✗ virtualenv -p /usr/local/bin/python3.4 ENV3.4Running virtualenv with interpreter /usr/local/bin/python3.4Using base prefix '/Library/Frameworks/Python.framework/Versions/3.4'New python executable in ENV3.4/bin/python3.4Also creating executable in ENV3.4/bin/pythonInstalling setuptools, pip...done. 激活Windows平台1venv\scripts\activate Linux平台1. venv/bin/activate 关闭 virtualenv1deactivate 参考阅读 廖雪峰的官方网站 virtualenv]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mysql 服务器管理员忘记密码]]></title>
    <url>%2F2017%2F11%2F11%2Fmysql-forget-password%2F</url>
    <content type="text"><![CDATA[先停止 mysql 服务 1service mysqld stop 然后打开 mysql 配置文件 /etc/my.cnf, 在【mysqld】下面添加一行代码：skip-grant-tables。这行代码意思就是跳过跳过授权表，即是可以跳过密码验证直接进入数据库。 重启 mysql 数据库。假如不重启的话，不会生效。并进入 mysql 12service mysqld restartmysql -uroot -p 更改 root 密码。 1update user set password=password('123456') where user="root"; 用户选 root ,可以随便更改成任意密码，我这里设置的123456，password()是mysql密码加密的一个函数。 刷新下密码，使更改的生效 1flush privileges; 退出数据库。 1exit 退出数据库，重新登录 1mysql -uroot -p // 回车输入刚刚更改的密码 然后再次进入配置文件 /etc/my.cnf 把 skip-grant-tables 去掉。]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql 用户与权限]]></title>
    <url>%2F2017%2F11%2F11%2Fmysql-privileges%2F</url>
    <content type="text"><![CDATA[用户管理查看服务器上的用户 123USE mysql;SELECT host, user FROM USER; 注： host 显示值： ::1 是 IPv6 下的本地回环地址；% 是任意 IP； 创建identified by 会将纯文本密码加密作为散列值存储1CREATE USER 【用户名】 IDENTIFIED BY '【密码】'; 这里的【用户名】可以是 用户名（等价于 用户名@’%’） 或者 用户名@’IP‘； 重命名用户名1RENAME USER 【原用户名】 TO 【新用户名】; 修改密码123UPDATE mysql.userSET password=PASSWORD('【密码】')WHERE user='【用户名】'; 删除1DROP USER test_root; 权限管理查看用户权限1SHOW GRANTS FOR 【用户名】; 设置权限时必须给出一下信息 要授予的权限 被授予访问权限的数据库或表 用户名 赋予权限，比如将 test 数据库的所有操作权限给 test_admin； 1GRANT SELECT, INSERT, UPDATE, DELETE ON test.* TO test_admin; 回收权限，比如 test_admin 用户撤销 delete 权限： 1REVOKE DELETE ON test.* FROM test_admin; 注： 如果希望立即看到结果 flush privileges; 更多的示例与 demo， 参考mysql 用户管理和权限设置 附录服务器支持远程访问修改 my.cnf 文件的 bind-address 值为 0.0.0.0 1bind-address=0.0.0.0]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql 数据库和表操作]]></title>
    <url>%2F2017%2F11%2F10%2Fmysql-table%2F</url>
    <content type="text"><![CDATA[表增示例 demo 1234567891011121314151617CREATE TABLE `【表名字】` ( `id` int(11) NOT NULL AUTO_INCREMENT, `dot_id` int(11) NOT NULL DEFAULT '2', `uid` int(11) NOT NULL, `shelf_id` int(11) NOT NULL, `shelf_code` varchar(16) NOT NULL, `floor_id` int(11) NOT NULL, `shelf_trading_id` varchar(25) NOT NULL, `type` int(2) NOT NULL DEFAULT '1', `default_num` int(11) DEFAULT '10', `relative_num` int(11) NOT NULL DEFAULT '0', `fill_num` int(11) NOT NULL DEFAULT '0' COMMENT '填充数量', `timestamp_flag` varchar(12) DEFAULT NULL, `created_at` datetime DEFAULT CURRENT_TIMESTAMP, `updated_at` datetime DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; 如果有索引，在创建表的语法里写法如下：1KEY `INDEX_SHELF_TRADINGID_SHELFCODE` (`shelf_code`,`shelf_trading_id`) 如果是唯一索引：1UNIQUE KEY `INDEX_UNIQUE` (`id`) 删删除表结构及数据： 1DROP TABLE IF EXISTS `【表名字】`; 不删除表结构，只清空数据： 123DELETE FROM 【表名字】;# 或TRUNCATE TABLE 【表名字】; 效率上 truncate 比 delete 快，但 truncate 删除后不记录 mysql 日志，不可以恢复数据。 改删除列1ALTER TABLE 【表名字】 DROP 【列名称】 增加列新增列123ALTER TABLE 【表名字】 ADD 【列名称】 INT# 等价于ALTER TABLE shelf_deal_log ADD system_num INT DEFAULT NULL; 新增列，非空，并带说明1ALTER TABLE 【表名字】 ADD 【列名称】 INT NOT NULL COMMENT '注释说明' 新增一个 datetime 列，设置默认值为创建时的当前时间；1ALTER TABLE 【表名字】 ADD 【列名称】 DATETIME DEFAULT CURRENT_TIMESTAMP; 新增一个 datetime 列，设置默认值为修改时的当前时间，修改时时间会更新； 1ALTER TABLE 【表名字】 ADD 【列名称】 DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP; 修改列的类型信息1ALTER TABLE 【表名字】 CHANGE 【列名称】【新列名称（这里可以用和原来列同名即可）】 BIGINT NOT NULL COMMENT '注释说明' 重命名列1ALTER TABLE 【表名字】 CHANGE 【列名称】【新列名称】 BIGINT NOT NULL COMMENT '注释说明' 重命名表1ALTER TABLE 【表名字】 RENAME 【表新名字】 删除表中主键1Alter TABLE 【表名字】 drop primary key 替换主键1ALTER TABLE 【表名字】 DROP PRIMARY KEY ,ADD PRIMARY KEY (【新主键名称，有多个，逗号隔开】); 添加索引1ALTER TABLE 【表名字】 ADD INDEX 【索引名】 (【索引字段，有多个，逗号隔开】); 添加唯一限制条件索引1ALTER TABLE 【表名字】 ADD UNIQUE 【索引名】 (【索引字段】); 删除索引1ALTER TABLE 【表名字】 DROP INDEX 【索引名】; 查查看当前数据库下所有的表： 1SHOW TABLES; 查询表的字段信息： 1DESC 【表名字】; 查看表字段详细信息； 1SHOW FULL COLUMNS FROM 【表名字】; 数据库查找当前服务器上存在哪些数据库； 1SHOW DATABASES; 使用指定数据库，比如使用 antenna 数据库； 1USE antenna; 创建数据库，比如新创建的数据库名称叫 hello; 1CREATE DATABASE hello;]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql 数据类型]]></title>
    <url>%2F2017%2F11%2F08%2Fmysql-data%2F</url>
    <content type="text"><![CDATA[MySQL 支持多种类型，大致可以分为三类：数值、日期/时间和字符串（字符）类型。 数值 类型 大小 范围（有符号） 范围（无符号） 用途 tinyint 1 字节 (-128，127) (0，255) 小整数值 smallint 2 字节 (-32 768，32 767) (0，65535) 大整数值 mediumint 3 字节 (-8 388 608，8 388 607) (0，16 777 215) 大整数值 int 或 Integer 4 字节 (-2 147 483 648，2 147 483 647) (0，4 294 967 295) 大整数值 bigint 8 字节 (-9 233 372 036 854 775 808，9 223 372 036 854 775 807) (0，18 446 744 073 709 551 615) 极大整数值 float 4 字节 (-3.402 823 466 E+38，-1.175 494 351 E-38)，0，(1.175 494 351 E-38，3.402 823 466 351 E+38) 0，(1.175 494 351 E-38，3.402 823 466 E+38) 单精度浮点数值 double 8 字节 (-1.797 693 134 862 315 7 E+308，-2.225 073 858 507 201 4 E-308)，0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308) 0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308) 双精度浮点数值 decimal 对 DECIMAL(M,D) ，如果 M &gt; D，为 M + 2 否则为 D + 2 依赖于 M 和 D 的值 依赖于 M 和 D 的值 小数值 日期和时间 表示时间值的日期和时间类型为 DATETIME、DATE、TIMESTAMP、TIME 和 YEAR。 每个时间类型有一个有效值范围和一个”零”值，当指定不合法的 MySQL 不能表示的值时使用”零”值。 TIMESTAMP 类型有专有的自动更新特性。 类型 大小 范围（有符号） 范围（无符号） 用途 date 3 1000-01-01/9999-12-31 YYYY-MM-DD 日期值 time 3 ‘-838:59:59’/‘838:59:59’ HH:MM:SS 时间值或持续时间 year 1 1901/2155 YYYY 年份值 datetime 8 1000-01-01 00:00:00/9999-12-31 23:59:59 YYYY-MM-DD HH:MM:SS 混合日期和时间值 timestamp 4 1970-01-01 00:00:00/2038 结束时间是第 2147483647 秒 YYYYMMDD HHMMSS 混合日期和时间值，时间戳 字符串字符串类型指 CHAR、VARCHAR、BINARY、VARBINARY、BLOB、TEXT、ENUM 和 SET。 类型 大小 用途 char 0-255 字节 定长字符串 varchar 0-65535 字节 变长字符串 tinyblob 0-255 字节 不超过 255 个字符的二进制字符串 tinytext 0-255字节 短文本字符串 blob 0-65 535 字节 二进制形式的长文本数据 text 0-65 535字节 长文本数据 mediumblob 0-16 777 215字节 二进制形式的中等长度文本数据 mediumtext 0-16 777 215字节 中等长度文本数据 longblob 0-4 294 967 295字节 二进制形式的极大文本数据 longtext 0-4 294 967 295字节 极大文本数据 CHAR 和 VARCHAR 类型类似，但它们保存和检索的方式不同。它们的最大长度和是否尾部空格被保留等方面也不同。在存储或检索过程中不进行大小写转换。 BINARY 和 VARBINARY 类似于 CHAR 和 VARCHAR，不同的是它们包含二进制字符串而不要非二进制字符串。也就是说，它们包含字节字符串而不是字符字符串。这说明它们没有字符集，并且排序和比较基于列值字节的数值。 BLOB 是一个二进制大对象，可以容纳可变数量的数据。有 4 种 BLOB 类型：TINYBLOB、BLOB、MEDIUMBLOB 和 LONGBLOB。它们只是可容纳值的最大长度不同。 有 4 种 TEXT 类型：TINYTEXT、TEXT、MEDIUMTEXT 和 LONGTEXT。这些对应 4 种 BLOB 类型，有相同的最大长度和存储需求。]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 模块之 os]]></title>
    <url>%2F2017%2F11%2F01%2Fpython-module-os%2F</url>
    <content type="text"><![CDATA[os 模块包含普遍的操作系统功能，与具体的平台无关，比如操作文件、目录等；本篇笔记基于 Python 2.7.1 进行描述； 运行参数 命令 描述 os.environ 一个 mapping 对象表示环境 os.chdir(path) 改变当前工作目录到指定的路径 os.fchdir(fd) 通过文件描述符改变当前工作目录 os.getcwd() 返回当前工作目录 os.ctermid() 返回进程控制终端的文件名 os.getegid() 返回当前进程有效的 group 的 id；对应于当前进程的可执行文件的”set id “的bit位。 os.geteuid() 返回当前进程有效的 user 的 id os.getgid() 返回当前进程当前 group 的 id os.getgroups() 返回当前进程支持的 groups 的 id 列表 os.initgroups(username, gid) os.getlogin() 返回进程控制终端登陆用户的名字 os.getpgid(pid) 返回 pid 进程的 group id。如果 pid 为 0，返回当前进程的 group id os.getpgrp() 返回当前进程组的 id os.getpid() 返回当前进程的 id os.getppid() 返回当前父进程的 id os.getresuid() os.getresgid() os.getuid() 返回当前当前进程用户的 id os.getenv(varname[, value]) 返回 environment 变量 varname 的值，如果 value 不存在，默认为 None os.putenv(varname, value) 设置 varname 环境变量为 value 值。此改变影响以os.system()， popen() 或 fork()和execv()启动的子进程 os.setegid(egid) 设置当前进程有效组的 id os.seteuid(euid) 设置当前进程有效用户的 id os.setgid(gid) 设置当前进程组的 id os.setgroups(groups) 设置当前进程支持的 groups id 列表 os.setpgrp() 调用 system 的 setpgrp() 或 setpgrp(0, 0)() ，依赖于使用的是哪个版本的 system os.setpgid(pid, pgrp) 调用 system 的 setpgid() 设置 pid 进程 group 的 id 为 pgrp。 os.setregid(rgid, egid) os.setresgid(rgid, egid, sgid) os.setresuid(ruid, euid, suid) os.setreuid(ruid, euid) os.getsid(pid) os.setsid() os.setuid(uid) 设置当前 user id os.strerror(code) 返回程序中错误 code 的错误信息 os.umask(mask) 设置当前权限掩码，同时返回先前的权限掩码 os.uname() os.unsetenv(varname) 删除 varname 环境变量 文件对象创建 命令 描述 os.fdopen(fd[, mode[, bufsize]]) 返回一个文件描述符号为 fd 的打开的文件对象。mode 和 bufsize 参数，和内建的 open() 函数是同一个意思 os.popen(command[, mode[, bufsize]]) 给或从一个 command 打开一个管理。返回一个打开的连接到管道文件对象，文件对象可以读或写 os.tmpfile() 返回一个打开的模式为( w+b )的文件对象 .这文件对象没有文件夹入口，没有文件描述符，将会自动删除. os.popen2(cmd[, mode[, bufsize]]) os.popen3(cmd[, mode[, bufsize]]) os.popen4(cmd[, mode[, bufsize]]) 文件描述符操作 命令 描述 os.close(fd) 关闭文件描述符 fd os.closerange(fd_low, fd_high) 关闭从fd_low（包含）到 fd_high（不包含）所有的文件描述符 os.dup(fd) 返回文件描述符 fd 的 cope os.dup2(fd, fd2) 复制文件描述符 fd 到 fd2， 如果有需要首先关闭 fd2 os.fchmod(fd, mode) 改变文件描述符为 fd 的文件 “mode“ 为 mode os.fchown(fd, uid, gid) 改变文件描述符为 fd 的文件的所有者和 group 的 id 为 uid 和 gid os.fdatasync(fd) 强制将文件描述符为 fd 的文件写入硬盘. 不强制更新 metadata os.fpathconf(fd, name) 返回一个打开的文件的系统配置信息。 name 为检索的系统配置的值，它也许是一个定义系统值的字符串 os.fstat(fd) 返回文件描述符 fd 的状态 os.fstatvfs(fd) 返回包含文件描述符 fd 的文件的文件系统的信息，像 statvfs() os.fsync(fd) 强制将文件描述符为 fd 的文件写入硬盘 os.ftruncate(fd, length) 裁剪文件描述符 fd 对应的文件, 所以它最大不能超过文件大小 os.isatty(fd) 如果文件描述符 fd 是打开的，同时与 tty(-like)设备相连，则返回 true, 否则 False os.lseek(fd, pos, how) 设置文件描述符 fd 当前位置为 pos, how方式修改: SEEK_SET 或者 0 设置从文件开始的计算的 pos; SEEK_CUR 或者 1 则从当前位置计算; os.SEEK_END 或者2则从文件尾部开始 os.SEEK_SET os.SEEK_CUR os.SEEK_END os.open(file, flags[, mode]) 打开 file 同时根据 flags 设置变量 flags ，如果有 mode，则设置它的mode。 默认的 mode 是 0777 (八进制) os.openpty() os.pipe() 创建一个管道。 返回一对文件描述符(r, w) 分别为读和写 os.read(fd, n) 从文件描述符 fd 中读取最多 n 个字节。返回包含读取字节的 string。 文件描述符 fd 对应文件已达到结尾， 返回一个空 string os.tcgetpgrp(fd) os.tcsetpgrp(fd, pg) os.ttyname(fd) os.write(fd, str) 写入字符串到文件描述符 fd 中。 返回实际写入的字符串长度 文件和目录 命令 描述 os.access(path, mode) 使用现在的 uid/gid 尝试访问 path os.F_OK 作为 access() 的mode参数，测试 path 是否存在 os.R_OK 包含在 access() 的 mode 参数中 ， 测试 path 是否可读 os.W_OK 包含在 access() 的 mode 参数中 ，测试 path 是否可写 os.X_OK 包含在 access() 的 mode 参数中 ，测试 path 是否可执行 os.chdir(path) 改变当前工作目录 os.fchdir(fd) os.getcwd() 返回当前工作目录的字符串 os.getcwdu() 返回一个当前工作目录的 Unicode 对象 os.chflags(path, flags) os.chroot(path) os.chmod(path, mode) os.chown(path, uid, gid) os.lchflags(path, flags) os.lchmod(path, mode) os.lchown(path, uid, gid) os.link(source, link_name) os.listdir(path) 返回 path 指定的文件夹包含的文件或文件夹的名字的列表 os.lstat(path) 像 stat()，但是没有符号链接。这是 stat() 的别名 os.mkfifo(path[, mode]) os.mknod(filename[, mode=0600[, device=0]]) 创建一个名为 filename 文件系统节点（文件，设备特别文件或者命名 pipe）。 mode 指定创建或使用节点的权限 os.major(device) 从原始的设备号中提取设备 major 号码 os.minor(device) 从原始的设备号中提取设备 minor 号码 os.makedev(major, minor) 以 major 和 minor 设备号组成一个原始设备号 os.mkdir(path[, mode]) 以数字 mode 的 mode 创建一个名为 path 的文件夹.默认的 mode 是 0777 (八进制) os.makedirs(path[, mode]) 递归文件夹创建函数 os.pathconf(path, name) os.pathconf_names os.readlink(path) os.remove(path) 删除路径为 path 的文件。如果 path 是一个文件夹，将抛出OSError； os.removedirs(path) 递归删除 directorie。 像 rmdir(), 如果子文件夹成功删除， removedirs() 才尝试它们的父文件夹，直到抛出一个 error os.rename(src, dst) 重命名 file 或者 directory src 到 dst。如果 dst 是一个存在的 directory， 将抛出 OSError os.renames(old, new) 递归重命名文件夹或者文件 os.rmdir(path) 删除 path 文件夹. 仅当这文件夹是空的才可以, 否则, 抛出 OSError os.stat(path) 执行一个 stat() 系统调用在给定的 path 上. 返回值是一个对象，属性与 stat 结构成员有关 os.stat_float_times([newvalue]) 决定 stat_result 是否以 float 对象显示时间戳 os.statvfs(path) os.symlink(source, link_name) os.tempnam([dir[, prefix]]) 为创建一个临时文件返回一个唯一的 path；警告: 使用 tempnam() 对于 symlink 攻击是一个漏洞; 考虑使用 tmpfile() 代替 os.tmpnam() 为创建一个临时文件返回一个唯一的 path os.TMP_MAX 将产生唯一名字的最大数值 os.unlink(path) 删除 file 路径. 与 remove() 相同 os.utime(path, times) 返回指定的 path 文件的访问和修改的时间。如果时间是 None, 则文件的访问和修改设为当前时间 os.walk(top, topdown=True, onerror=None, followlinks=False) 输出在文件夹中的文件名通过在树中游走，向上或者向下.在根目录下的每一个文件夹(包含它自己), 产生 3-tuple (dirpath, dirnames, filenames)【文件夹路径, 文件夹名字, 文件名】 进程管理 命令 描述 os.abort() 产生一个 SIGABRT 标识到当前的进程 os.execl(path, arg0, arg1, …) os.execle(path, arg0, arg1, …, env) os.execlp(file, arg0, arg1, …) os.execlpe(file, arg0, arg1, …, env) os.execv(path, args) os.execve(path, args, env) os.execvp(file, args) os.execvpe(file, args, env) 这些函数将执行一个新程序，替换当前进程； 他们没有返回。在 Unix，新的执行体载入到当前的进程， 同时将和当前的调用者有相同的id。 将报告Errors 当抛出 OSError 时。 os._exit(n) 使用状态 n 退出系统，没有调用清理函数，刷新缓冲区。 os.EX_OK os.EX_USAGE os.EX_DATAERR os.EX_NOINPUT os.EX_NOUSER os.EX_NOHOST os.EX_UNAVAILABLE os.EX_SOFTWARE os.EX_OSERR os.EX_OSFILE os.EX_CANTCREAT os.EX_IOERR os.EX_TEMPFAIL os.EX_PROTOCOL os.EX_NOPERM os.EX_CONFIG os.EX_NOTFOUND os.fork() os.forkpty() os.kill(pid, sig) os.killpg(pgid, sig) os.nice(increment) os.plock(op) os.popen(…) os.popen2(…) os.popen3(…) os.popen4(…) os.spawnl(mode, path, …) os.spawnle(mode, path, …, env) os.spawnlp(mode, file, …) os.spawnlpe(mode, file, …, env) os.spawnv(mode, path, args) os.spawnve(mode, path, args, env) os.spawnvp(mode, file, args) os.spawnvpe(mode, file, args, env) os.P_NOWAIT os.P_NOWAITO os.P_WAIT os.P_DETACH os.P_OVERLAY os.startfile(path[, operation]) os.system(command) 在 shell 中执行 string 命令. os.times() 返回一个 5-tuple 的浮点数字， 表示(处理器或者其它)累积时间， 以秒为单位。 items为：用户时间， 系统time， 子用户time， 子系统time， 和从过去一个固定的点真实流逝的时间 os.wait() os.waitpid(pid, options) Unix：等待一个指定的 pid 的子进程完成，返回一个 tuple 返回它的进程id和退出状态 。 一般情况下option设为 0。Windows: 等待一个指定的 pid 的进程完成, 返回一个 tuple 返回它的进程 id 和退出状态向左移动了 8 位 。 如果 pid 小于或等于 0 没有特别的意思,将抛出exception。 integer options 没有任何影响。 pid 可以指向任何进程的 id，不一定是子进程的id。 os.wait3(options) os.wait4(pid, options) os.WNOHANG os.WCONTINUED os.WUNTRACED os.WCOREDUMP(status) os.WIFCONTINUED(status) os.WIFSTOPPED(status) os.WIFSIGNALED(status) os.WIFEXITED(status) os.WEXITSTATUS(status) os.WSTOPSIG(status) os.WTERMSIG(status) 各种各样的系统信息 命令 描述 os.curdir 操作系统用此常数字符串作为当前文件夹的引用。 os.pardir 操作系统用此常数字符串作为父文件夹的引用。 os.sep 系统使用此字符来分割路径。 os.altsep 系统使用另外一个字符来分割路径，如果只有一个分割字符存在，则是 None。 os.extsep 分割基本文件名和扩展名的字符。 os.pathsep 系统使用此字符来分割搜索路径。如 POSIX 上 ‘:‘，Windows上的’;‘ os.defpath 默认的搜索路径 os.linesep 当前平台上的换行符字符串。 在 POSIX 上是 ‘\n‘ ,或者 在 Windows 上是 ‘\r\n‘。 os.devnull 空设备的文件路径。例如: POSIX上 ‘/dev/null‘。 os.confstr(name) os.confstr_names os.getloadavg() os.sysconf(name) os.sysconf_names 其他函数 命令 描述 os.urandom(n) 随机产生 n 个字节的字符串，可以作为随机加密 key 使用]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Centos 安装 vim 8.0]]></title>
    <url>%2F2017%2F10%2F31%2Flinux-vim8%2F</url>
    <content type="text"><![CDATA[编译安装如下123456789yum install ncurses-devel wget https://github.com/vim/vim/archive/master.zip unzip master.zip cd vim-master cd src/ ./configure --enable-multibyte --enable-pythoninterp=yesmake sudo make install vim --version 检查 python 支持检查 vim 是否有 python 支持，命令如下： 1vim --version |grep python 重新编译的时候，想要支持 python2.x，则加入 --enable-pythoninterp=yes 参数。如果想开启 Python3 支持，则 --enable-python3interp=yes。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux Tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何判断 Javascript 对象是否存在]]></title>
    <url>%2F2017%2F10%2F29%2Fjs-object%2F</url>
    <content type="text"><![CDATA[转自 阮一峰的博客 Javascript 语言的设计不够严谨，很多地方一不小心就会出错。 举例来说，请考虑以下情况。现在，我们要判断一个全局对象 myObj 是否存在，如果不存在，就对它进行声明。用自然语言描述的算法如下： 123if (myObj 不存在)&#123; 声明 myObj;&#125; 你可能会觉得，写出这段代码很容易。但是实际上，它涉及的语法问题，远比我们想象的复杂。Juriy Zaytsev指出，判断一个 Javascript 对象是否存在，有超过 50 种写法。只有对 Javascript 语言的实现细节非常清楚，才可能分得清它们的区别。 第一种写法根据直觉，你可能觉得可以这样写： 123if (! myObj) &#123; myObj = &#123; &#125;;&#125; 但是，运行这段代码，浏览器会直接抛出 ReferenceError 错误，导致运行中断。请问错在哪里？ 对了， if 语句判断 myObj 是否为空时，这个变量还不存在，所以才会报错。改成下面这样，就能正确运行了。 123if (! myObj) &#123; var myObj = &#123; &#125;;&#125; 为什么加了一个 var 以后，就不报错了？难道这种情况下，if 语句做判断时，myObj 就已经存在了吗？要回答这个问题，就必须知道 Javascript 解释器的工作方式。Javascript 语言是”先解析，后运行”，解析时就已经完成了变量声明，所以上面的代码实际等同于： 1234var myObj;if (! myObj) &#123; var myObj = &#123; &#125;;&#125; 因此，if 语句做判断时，myObj 确实已经存在了，所以就不报错了。这就是 var 命令的”代码提升”（hoisting）作用。Javascript 解释器，只”提升” var 命令定义的变量，对不使用 var 命令、直接赋值的变量不起作用，这就是为什么不加 var 会报错的原因。 第二种写法除了 var 命令，还可以有另一种改写，也能得到正确的结果： 123if (! window.myObj) &#123; myObj = &#123; &#125;;&#125; window 是 javascript 的顶层对象，所有的全局变量都是它的属性。所以，判断 myobj 是否为空，等同于判断 window 对象是否有 myobj 属性，这样就可以避免因为 myObj 没有定义而出现 ReferenceError 错误。不过，从代码的规范性考虑，最好还是对第二行加上 var： 123if (! window.myObj) &#123; var myObj = &#123; &#125;;&#125; 或者写成这样： 123if (! window.myObj) &#123; window.myObj = &#123; &#125;;&#125; 第三种写法上面这种写法的缺点在于，在某些运行环境中（比如V8、Rhino），window未必是顶层对象。所以，考虑改写成： 123if (!this.myObj) &#123; this.myObj = &#123; &#125;;&#125; 在全局变量的层面中，this关键字总是指向顶层变量，所以就可以独立于不同的运行环境。 第四种写法但是，上面这样写可读性较差，而且 this 的指向是可变的，容易出错，所以进一步改写： 1234var global = this;if (! global.myObj) &#123; global.myObj = &#123; &#125;;&#125; 用自定义变量 global 表示顶层对象，就清楚多了。 第五种写法还可以使用 typeof 运算符，判断 myObj 是否有定义。 123if (typeof myObj == "undefined") &#123; var myObj = &#123; &#125;;&#125; 这是目前使用最广泛的判断 javascript 对象是否存在的方法。 第六种写法由于在已定义、但未赋值的情况下，myObj 的值直接等于 undefined，所以上面的写法可以简化： 123if (myObj == undefined) &#123; var myObj = &#123; &#125;;&#125; 这里有两个地方需要注意，首先第二行的 var 关键字不能少，否则会出现 ReferenceError 错误，其次 undefined 不能加单引号或双引号，因为这里比较的是 undefined 这种数据类型，而不是”undefined“这个字符串。 第七种写法上面的写法在”精确比较”（===）的情况下，依然成立： 123if (myObj === undefined) &#123; var myObj = &#123; &#125;;&#125; 第八种写法根据 javascript 的语言设计，undefined == null，所以比较 myObj 是否等于 null，也能得到正确结果： 123if (myObj == null) &#123; var myObj = &#123; &#125;;&#125; 不过，虽然运行结果正确，但是从语义上看，这种判断方法是错的，应该避免。因为 null 指的是已经赋值为 null 的空对象，即这个对象实际上是有值的，而 undefined 指的是不存在或没有赋值的对象。因此，这里只能使用”比较运算符”（==），如果这里使用”精确比较运算符”（===），就会出错。 第九种写法还可以使用 in 运算符，判断 myObj 是否为顶层对象的一个属性： 123if (! ('myObj' in window)) &#123; window.myObj = &#123; &#125;;&#125; 第十种写法最后，使用 hasOwnProperty 方法，判断 myObj 是否为顶层对象的一个属性： 123if (!this.hasOwnProperty('myObj')) &#123; this.myObj = &#123; &#125;;&#125; 总结 如果只判断对象是否存在，推荐使用第五种写法。 如果除了对象是否存在，还要判断对象是否有 null 值，推荐使用第一种写法。 除非特殊情况，所有变量都应该使用 var 命令声明。 为了跨平台，建议避免使用 window 表示顶层对象。 在 Javascript 语言中，null 和 undefined 容易产生混淆。在可能同时涉及两者的情况下，建议使用”精确比较”运算符（===）。]]></content>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP 正则表达式函数]]></title>
    <url>%2F2017%2F10%2F26%2Fphp-regex%2F</url>
    <content type="text"><![CDATA[在PHP中有两套正则表达式函数库。一套是由PCRE（Perl Compatible Regular Expression）库提供的。PCRE 库使用和 Perl 相同的语法规则实现了正则表达式的模式匹配，其使用以“preg_”为前缀命名的函数。另一套是由POSIX（Portable Operation System interface）扩展库提供的。POSIX扩展的正则表达式由POSIX 1003.2定义，一般使用以“ereg_”为前缀命名的函数。两套函数库的功能相似，执行效率稍有不同。一般而言，实现相同的功能，使用PCRE库的效率略占优势。 preg_match 函数原型：int preg_match (string $pattern, string $content [, array $matches]) preg_match() 函数在$content字符串中搜索与$pattern给出的正则表达式相匹配的内容。如果提供了$matches，则将匹配结果放入其中。$matches[0]将包含与整个模式匹配的文本，$matches[1]将包含第一个捕获的与括号中的模式单元所匹配的内容，以此类推。该函数只作一次匹配，最终返回 0 或 1 的匹配结果数。 示例： 12345$content = "Current date and time is ".date("Y-m-d h:i a").", we are learning PHP together.";if (preg_match ("/([\d-]&#123;10&#125;) ([\d:]&#123;5&#125; [ap]m)/", $content, $matches)) &#123; print_r($matches);&#125; preg_match_all 函数原型：int preg_match_all( string pattern, string subject, array matches [, int flags ] ) 用于进行正则表达式全局匹配，成功返回整个模式匹配的次数（可能为零），如果出错返回 FALSE 。 12345$str = "&lt;pre&gt;学习php是一件快乐的事。&lt;/pre&gt;&lt;pre&gt;所有的phper需要共同努力！&lt;/pre&gt;";preg_match_all("/&lt;pre&gt;([^&lt;]*?)&lt;\/pre&gt;/i", $str, $matches);print_r($matches); preg_grep 函数原型：array preg_grep (string $pattern, array $input) preg_grep()函数返回一个数组，其中包括了$input数组中与给定的$pattern模式相匹配的单元。对于输入数组$input中的每个元素，preg_grep()也只进行一次匹配。 示例： 123456789101112$subjects = array( "Mechanical Engineering", "Medicine", "Social Science", "Agriculture", "Commercial Science", "Politics"); $alonewords = preg_grep("/^[a-z]*$/i", $subjects);print_r($alonewords); 整理常用的正则表达式邮箱1"/^[_a-z0-9-]+(\.[_a-z0-9-]+)*@[a-z0-9-]+(\.[a-z0-9-]+)*(\.[a-z]&#123;2,&#125;)$/" 手机号1"/^1[34578]\d&#123;9&#125;$/" 中文1"/([\x&#123;4e00&#125;-\x&#123;9fa5&#125;])/u" 身份证1"/^\d&#123;15&#125;|\d&#123;18&#125;$/"]]></content>
      <categories>
        <category>PHP</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[PHP 常用函数汇总]]></title>
    <url>%2F2017%2F10%2F25%2Fphp-function%2F</url>
    <content type="text"><![CDATA[String比较 函数名 描述 strcmp 该函数是二进制安全的，且对大小写敏感 strncmp 前 n 个字符的字符串比较（对大小写敏感） strcasecmp 比较两个字符串，对大小写不敏感 strncasecmp 前 n 个字符的字符串比较（对大小写不敏感） strnatcmp 使用一种“自然”算法来比较两个字符串（对大小写敏感） strnatcasecmp 使用一种“自然”算法来比较两个字符串（对大小写不敏感） substr_compare 从指定的开始长度比较两个字符串 strcoll 该函数不是二进制安全的，对大小写敏感；字符串的比较会根据本地设置而变化。（Aa） 修改 函数名 描述 str_repeat 把字符串重复指定的次数 strrev 反转字符串 str_shuffle 随机地打乱字符串中的所有字符 wordwrap 按照指定长度对字符串进行折行处理 chunk_split 把字符串分割为一连串更小的部分 money_format 把字符串格式化为货币字符串 number_format 通过千位分组来格式化数字 str_pad 把字符串填充为指定的长度 strtolower 把字符串转换为小写 strtoupper 把字符串转换为大写 lcfirst 把字符串中的首字符转换为小写 ucfirst 把字符串中的首字符转换为大写 ucwords 把字符串中每个单词的首字符转换为大写 strtr 转换字符串中特定的字符 str_replace 使用一个字符串替换字符串中的另一些字符（对大小写敏感） str_ireplace 替换字符串中的一些字符。（对大小写不敏感） substr_replace 函数把字符串的一部分替换为另一个字符串 hebrev 把希伯来逻辑文本转换为希伯来可见文本 hebrevc 把希伯来逻辑文本转换为希伯来可见文本，把新行 (\n) 转换为 &lt;br /&gt; convert_cyr_string 把字符串由一种 Cyrillic 字符集转换成另一种 插入 函数名 描述 addslashes 在指定的预定义字符前添加反斜杠，可用于为存储在数据库中的字符串以及数据库查询语句准备合适的字符串 stripslashes 删除由 addslashes() 函数添加的反斜杠 addcslashes 在指定的字符前添加反斜杠 stripcslashes 删除由 addcslashes() 函数添加的反斜杠 quotemeta 在字符串中某些预定义的字符前添加反斜杠 删除 函数名 描述 trim 从字符串的两端删除空白字符和其他预定义字符 chop rtrim() 的别名 ltrim 从字符串左侧删除空格或其他预定义字符 rtrim 从字符串的末端开始删除空白字符或其他预定义字符 子字符串 函数名 描述 substr 返回字符串的一部分 strrchr 查找字符串在另一个字符串中最后一次出现的位置，并返回从该位置到字符串结尾的所有字符 strtok 按需切割字串，不可以用中文切割会乱码 搜索 函数名 描述 strchr strstr 的别名 strstr 搜索一个字符串在另一个字符串中的第一次出现，返回的是字符串的其余部分（从匹配点），对大小写敏感 stristr 搜索一个字符串在另一个字符串中的第一次出现，返回的是字符串的其余部分（从匹配点），对大小写不敏感 strpos 返回字符串在另一个字符串中第一次出现的位置， 返回匹配点位置，对大小写敏感 stripos 返回字符串在另一个字符串中第一次出现的位置， 返回匹配点位置，对大小写不敏感 strrpos 返回字符串在另一个字符串中最后一次出现的位置， 返回匹配点位置，对大小写敏感 strripos 返回字符串在另一个字符串中最后一次出现的位置， 返回匹配点位置，对大小写不敏感 strpbrk 在字符串中搜索指定字符中的任意一个，对大小写敏感 与数组相关 函数名 描述 join implode() 的别名 implode 把数组元素组合为一个字符串 explode 把字符串打散为数组 str_split 把字符串分割到数组中 解析 函数名 描述 parse_str 把查询字符串解析到变量中 sscanf 根据指定的格式解析来自一个字符串的输入 str_getcsv 解析 CSV 格式字段的字符串，并返回一个包含所读取字段的数组 与 Html 相关 函数名 描述 html_entity_decode 是 htmlentities() 的反函数，把 HTML 实体转换为字符 htmlentities 把字符转换为 HTML 实体 htmlspecialchars_decode 把一些预定义的 HTML 实体转换为字符 htmlspecialchars 把一些预定义的字符转换为 HTML 实体 nl2br 在字符串中的每个新行 (\n) 之前插入 HTML 换行符 (&lt;br /&gt;) strip_tags 剥去 HTML、XML 以及 PHP 的标签 与ASCII相关 函数名 描述 ord 返回字符串第一个字符的 ASCII 值 chr 从指定的 ASCII 值返回字符 长度、计算 函数名 描述 strlen 返回字符串的长度 str_word_count 计算字符串中的单词数 substr_count 计算子串在字符串中出现的次数 count_chars 返回字符串所用字符的信息 strcspn 返回在找到任何指定的字符之前，在字符串查找的字符数 strspn 返回在字符串中包含 charlist 参数中指定字符的数目 md5_file 计算文件的 MD5 散列 md5 计算字符串的 MD5 散列 crc32 计算一个字符串的 crc32 多项式，该函数可用于验证数据的完整性 sha1_file 计算文件的 SHA-1 散列 sha1 计算字符串的 SHA-1 散列 soundex 计算字符串的 soundex 键，为发音相似的单词创建相同的键 metaphone 计算字符串的 metaphone 键，metaphone 键字符串的英语发音 levenshtein 返回两个字符串之间的 Levenshtein 距离 similar_text 计算两个字符串的匹配字符的数目 输出 函数名 描述 echo 同printf，比printf快【echo(strings)】 print 输出一个字符串【print() 函数实际上不是函数，所以不必对它使用括号】【 print(strings)】 printf 输出格式化的字符串 【printf(format,arg1,arg2,arg++)】 vprintf 输出格式化的字符串，与printf不同的是第二参数为数组【vprintf(format,argarray)】 sprintf 返回格式化的字符串【sprintf(format,arg1,arg2,arg++)】 vsprintf 返回格式化的字符串，与sprintf不同的是第二参数为数组【vsprintf(format,argarray)】 fprintf 把格式化的字符串写到指定的输出流【fprintf(stream,format,arg1,arg2,arg++)】 vfprintf 把格式化的字符串写到指定的输出流【vfprintf(stream,format,argarray)】 编码解码、校验 函数名 描述 crypt 单向加密 str_rot13 对字符串执行 ROT13 编码 convert_uudecode 对 uuencode 编码的字符串进行解码 convert_uuencode 使用 uuencode 算法对字符串进行编码 quoted_printable_decode 把 quoted-printable 字符串解码为 8 位 ASCII 字符串 quoted_printable_encode 把 8 位字符串转换为 quoted-printable 字符串 bin2hex 将二进制数据转换成十六进制表示 hex2bin 把十六进制值转换为 ASCII 字符 配置信息 函数名 描述 nl_langinfo 返回指定的本地信息 setlocale 设置地区信息（地域信息） localeconv 包含本地数字及货币信息格式的数组 get_html_translation_table 返回被 htmlentities() 和 htmlspecialchars() 函数使用的翻译表 Array新建 函数名 描述 array 新建一个数组 compact 建立一个数组，包括变量名和它们的值 array_rand 返回给定数组中的随机键名 array_fill 用给定的值填充数组 array_fill_keys 用给定的指定键名的键值填充数组 array_pad 指定数量的带有指定值的元素插入到数组中 range 创建一个包含指定范围的元素的数组 array_combine 通过合并两个数组来创建一个新数组，其中的一个数组元素为键名，另一个数组元素为键值 array_column 返回数组中指定的一列 array_chunk 把数组分割为新的数组块，其中每个数组的单元数目由 size 参数决定 返回新数组 函数名 描述 array_slice 数组中根据条件取出一段值，并返回(key为数字，删；非数字，保留) array_splice 从数组中移除选定的元素，并用新元素取代它。该函数也将返回包含被移除元素的数组(删) 赋值 函数名 描述 list 把数组中的值赋给一些变量 extract 使用数组键名作为变量名，使用数组键值作为变量值 键或值 函数名 描述 array_keys 返回包含数组中所有键名的一个新数组 array_key_exists 检查某个数组中是否存在指定的键名，如果键名存在则返回 true key_exists array_key_exists 函数的别名 array_change_key_case 将数组的所有的键转换为大写字母 array_replace 根据Key, 使用后面数组的值替换第一个数组的值 array_replace_recursive 递归地使用后面数组的值替换第一个数组的值 array_values 返回一个包含给定数组中所有键值的数组，但不保留键名 array_unique 移除数组中的重复的值，并返回结果数组，返回的数组中键名不变 array_flip 返回一个键值反转后的数组，如果同一值出现了多次，则最后一个键名将作为它的值，所有其他的键名都将丢失 搜索 函数名 描述 in_array 搜索数组中是否存在指定的值 array_search 在数组中搜索某个键值，并返回对应的键名 进出 函数名 描述 array_shift 删除数组中第一个元素，并返回被删除元素的值(key为数字，删；非数字，保留) array_unshift 向数组插入新元素。新数组的值将被插入到数组的开头(key为数字，删；非数字，保留) array_pop 删除数组中的最后一个元素 array_push 向第一个参数的数组尾部添加一个或多个元素（入栈），然后返回新数组的长度 排序 函数名 描述 shuffle 把数组中的元素按随机顺序重新排列(删除Key) array_reverse 返回一个单元顺序相反的数组(可保留，可删除，由第二参数决定) array_multisort 对多个数组或多维数组进行排序(key为数字，删；非数字，保留) sort 按升序对给定数组的值排序(删除Key) rsort 按降序对给定数组的值排序(删除Key) asort 对关联数组按照键值进行升序排序(保留Key) arsort 对关联数组按照键值进行降序排序(保留Key) ksort 对关联数组按照键名进行升序排序(保留Key) krsort 对关联数组按照键名进行降序排序(保留Key) natsort 用”自然排序”算法对数组进行排序(保留Key) natcasesort 用“自然排序”算法对数组进行不区分大小写字母的排序(保留Key) usort 使用用户自定义的比较函数对数组中的元素进行排序(删除Key) uksort 使用用户自定义的比较函数对数组 中的元素按键名进行排序(保留Key) uasort 使用用户自定义的比较函数对数组中的值进行排序并保持索引关联(保留Key) 交集和差集， 合并 函数名 描述 array_diff 返回所有在被比较的数组中，但是不在任何其他参数数组中的键值。（保留key） array_udiff 比较两个数组的键值（使用用户自定义函数比较键值），并返回差集 array_diff_key 比较键值，返差集；（保留key） array_diff_ukey 用户定义的比较函数比较键值，返差集；（保留key） array_diff_assoc 返回所有在被比较的数组中，但是不在任何其他参数数组中的键和值（保留key） array_udiff_assoc 同diff_assoc比，多了自定义回调函数（参数为键值） array_diff_uassoc 相比diff_assoc，使用的是用户自定义的比较函数（参数为键名） array_udiff_uassoc 相比diff_uassoc，多了两个回调函数，分别用于键名和键值的比较 array_intersect 比较两个（或更多个）数组的键值，并返回交集数组（保留被比较数组的key） array_uintersect 用自定义回调函数（参数为键值）比较交集 array_intersect_key 比较键名计算数组的交集（保留被比较数组的key） array_intersect_ukey 用回调函数比较键名来计算数组的交集（保留被比较数组的key） array_intersect_assoc 比较两个数组的键名和键值，并返回交集 array_uintersect_assoc 同intersect_assoc比，多了自定义回调函数（参数为键值） array_intersect_uassoc 用回调函数比较两个数组的键名和键值，并返回交集 array_uintersect_uassoc 相比intersect_uassoc，多了两个回调函数，分别用于键名和键值的比较 array_merge 把一个或多个数组合并为一个数组(key为数字，重新排序；非数字，替换) array_merge_recursive array_merge_recursive()不会进行键名覆盖，而是将多个相同键名的值递归组成一个数组 数学运算 函数名 描述 count 返回数组中元素的数目 sizeof 同count array_sum 返回数组中所有值的和 array_count_values 统计数组中所有的值出现的次数，数组中的值作为键名，出现的次数作为值 array_product 计算数组中所有值的乘积 array_map 将函数作用到数组中的每个值上，每个值都乘以本身，并返回带有新值的数组 内部指针 函数名 描述 currrent 返回数组中的当前单元 pos 返回数组中的当前单元，同current函数 end 将数组的内部指针指向最后一个单元，并返回指向的单元 next 将数组中的内部指针向前移动一位，并返回指向的单元 prev 将数组的内部指针倒回一位，并返回指向的单元 reset 将数组的内部指针指向第一个单元，并返回指向的单元（即第一个单元） each 返回数组中当前的键／值对并将数组指针向前移动一步 key 返回数组中内部指针指向的当前单元的键名。 但它不会移动指针 用户自定义函数 函数名 描述 array_walk 对数组中的每个元素应用用户自定义函数 array_walk_recursive 该函数与 array_walk()函数的不同在于可以操作更深的数组（一个数组中包含另一个数组） array_reduce 向用户自定义函数发送数组中的值，并返回一个字符串 array_filter 用回调函数过滤数组中的单元(数组的键名保留不变) Math常用计算 函数名 描述 min 找出最小值 max 找出最大值 abs 绝对值 round 对浮点数进行四舍五入 ceil 返回大于或者等于指定表达式的最小整数，天花板函数 floor 返回小于或者等于指定表达式的最大整数，地板函数 intdiv 对除法结果取整，返回商 fmod 返回除法的浮点数余数，返回余数 is_nan 判断是否为合法数值 hypot 计算一直角三角形的斜边长度 sqrt 平方根 角度、弧度 函数名 描述 pi 得到圆周率值 deg2rad 将角度转换为弧度 rad2deg 将弧度数转换为相应的角度数 进制转换 函数名 描述 base_convert 在任意进制之间转换数字 decbin 十进制转换为二进制 bindec 二进制转换为十进制 decoct 十进制转换为八进制 octdec 八进制转换为十进制 dechex 十进制转换为十六进制 hexdec 十六进制转换为十进制 随机数 函数名 描述 lcg_value 组合线性同余发生器，返回范围为 (0, 1) 的一个伪随机数 rand 产生一个随机整数，如果没有提供可选参数 min 和 max，rand() 返回 0 到 RAND_MAX 之间的伪随机整数。 mt_rand 生成更好的随机整数 getrandmax 显示随机数最大的可能值 mt_getrandmax 显示随机数的最大可能值 srand 播下随机数发生器种子，自 PHP 4.2.0 起，不再需要用 srand() 或 mt_srand() 函数给随机数发生器播种，现在已自动完成 mt_srand 播下一个更好的随机数发生器种子(Mersenne Twister) 对数 函数名 描述 log 自然对数 log10 以 10 为底的对数 log1p 返回 log(1 + number)，甚至当 number 的值接近零也能计算出准确结果 指数 函数名 描述 exp 计算 e 的指数 expm1 返回 exp(number) - 1，甚至当 number 的值接近零也能计算出准确结果 pow 指数表达式 正切正弦余弦 函数名 描述 tan 正切 atan 反正切 tanh 双曲正切 atanh 反双曲正切 atan2 两个参数的反正切 sin 正弦 asin 反正弦 sinh 双曲正弦 asinh 反双曲正弦 cos 余弦 acos 反余弦 cosh 双曲余弦 acosh 反双曲余弦 有限值、无限值 函数名 描述 is_finite 判断是否为有限值 is_infinite 判断是否为无限值 Directory文件夹，获取目录信息 函数名 描述 dir 打开一个目录句柄，并返回一个对象。这个对象包含三个方法：read() , rewind() 以及 close() opendir 打开一个目录句柄，，并返回该句柄。可由 closedir()，readdir() 和 rewinddir() 使用 rewinddir 倒回目录句柄 getcwd 取得当前工作目录 scandir 列出指定路径中的文件和目录 chdir 把当前的目录改变为指定的目录。若成功，则该函数返回 true，否则返回 false chroot 把当前进程的根目录改变为指定的目录。若成功，则该函数返回 true，否则返回 false 文件夹，读 函数名 描述 readdir 从目录句柄中读取条目 文件夹，关 函数名 描述 closedir 关闭目录句柄 FileSystem创建 函数名 描述 tmpfile 建立一个临时文件 tempnam 建立一个具有唯一文件名的文件。在指定目录中建立一个具有唯一文件名的文件。如果该目录不存在，tempnam() 会在系统临时目录中生成一个文件，并返回其文件名。 mkdir 新建目录 获取文件信息 函数名 描述 fileatime 取得文件的上次访问时间。如果出错则返回 false。时间以 Unix 时间戳的方式返回 filectime 取得文件的 inode 修改时间。如果出错则返回 false。时间以 Unix 时间戳的方式返回 filemtime 取得文件内容修改时间。若成功，则时间以 Unix 时间戳的方式返回。若失败，则返回 false fileinode 取得文件的 inode编号 filegroup 取得文件的组ID fileowner 取得文件的所有者 fileperms 取得文件的权限 filesize 取得文件大小 filetype 取得文件类型 basename 返回路径中的文件名部分 dirname 返回路径中的目录部分 realpath 返回规范化的绝对路径名 stat 获取指定文件的统计信息。 fstat 通过已打开的文件指针取得文件信息 pathinfo 返回文件路径的信息 disk_free_space 返回目录中的可用空间 diskfreespace disk_free_space 的别名 disk_total_space 返回一个目录的磁盘总大小 realpath_cache_get Get realpath cache entries realpath_cache_size Get realpath cache size 改变 函数名 描述 chgrp 改变文件所属的组 chmod 改变文件权限 chown 改变文件的所有者 touch 设定文件的访问和修改时间 umask 改变当前的 umask rename 重命名一个文件或目录 ftruncate 将文件截断到给定的长度 flock 锁定或释放文件。 移动或拷贝 函数名 描述 copy 拷贝文件 move_uploaded_file 将上传的文件移动到新位置 读写 函数名 描述 feof 测试文件指针是否到了文件结束的位置 fgetc 从文件指针中读取,返回一个包含有一个字符的字符串 fgetcsv 从文件指针中读入一行并解析 CSV 字段 fputcsv 将行格式化为 CSV 并写入文件指针 fgets 从文件指针中读取一行 fgetss 从文件指针中读取一行并过滤掉 HTML 标记 file 把整个文件读入一个数组中。数组中的每个单元都是文件中相应的一行，包括换行符在内。 readfile 读入一个文件并写入到输出缓冲。 fscanf 根据指定的格式对来自打开的文件的输入进行解析。 fread 读取文件（可安全用于二进制文件） fwrite 写入文件（可安全用于二进制文件） fputs fwrite 的别名 file_get_contents 将整个文件读入一个字符串 file_put_contents 将一个字符串写入文件 parse_ini_file 解析一个配置文件 parse_ini_string Parse a configuration string fnmatch 根据指定的模式来匹配文件名或字符串 glob 返回匹配指定模式的文件名或目录 fopen 打开文件或者 URL fclose 关闭一个已打开的文件指针 rewind 倒回文件指针的位置 fseek 在文件指针中定位 ftell 返回文件指针读/写的位置 fpassthru 将给定的文件指针从当前的位置读取到 EOF，并把结果写到输出缓冲区。 set_file_buffer 设置打开文件的缓冲大小。 fflush 将缓冲内容输出到文件 clearstatcache 清除文件状态缓存 删除 函数名 描述 unlink 删除文件 rmdir 删除目录 delete 参见 unlink 或 unset 判断 函数名 描述 is_dir 判断给定文件名是否是一个目录 is_executable 判断给定文件名是否可执行 is_file 判断给定文件名是否为一个正常的文件 is_link 判断给定文件名是否为一个符号连接 is_readable 判断给定文件名是否可读 is_uploaded_file 判断文件是否是通过 HTTP POST 上传的 is_writable 判断给定的文件名是否可写 is_writeable is_writable 的别名 file_exists 检查文件或目录是否存在 连接Link 函数名 描述 link 建立一个硬连接 linkinfo 获取一个连接的信息 lstat 给出一个文件或符号连接的信息 readlink 返回符号连接指向的目标 symlink 建立符号连接 lchgrp Changes group ownership of symlink lchown Changes user ownership of symlink 进程 函数名 描述 pclose 关闭进程文件指针 popen 打开进程文件指针 ErrorHandling创建 函数名 描述 trigger_error 创建用户定义的错误消息，用于在用户指定的条件下触发一个错误消息。它与内建的错误处理器一同使用，也可以与由 set_error_handler() 函数创建的用户自定义函数使用 user_error trigger_error 的别名 set_error_handler 设置用户自定义的错误处理函数，替换内建的错误处理器 set_exception_handler 设置用户自定义的异常处理函数，替换内建的异常处理器 获取 函数名 描述 error_get_last 以数组的形式返回最后发生的错误 debug_backtrace 返回异常追溯数组（backtrace） 清理 函数名 描述 error_clear_last 清除内存中最近的异常信息 恢复 函数名 描述 restore_error_handler 之前的错误处理程序可能是在错误处理程序或用户自定义函数中构建的，恢复内建的错误处理程序 restore_exception_handler 之前的异常处理程序可能是在异常处理程序或用户自定义函数中构建的，恢复内建的异常处理程序 输出 函数名 描述 error_log 向服务器错误记录、文件或远程目标发送一个错误 debug_print_backtrace 输出异常追溯数组（backtrace） 配置 函数名 描述 error_reporting 设置 PHP 的报错级别并返回当前级别 Date/Time设置时间（时间戳） 函数名 描述 date_timestamp_set 设置基于 Unix 时间戳的日期和时间 获取时间（时间戳） 函数名 描述 time 返回当前时间的 Unix 时间戳 microtime 返回当前 Unix 时间戳和微秒数 mktime 返回一个日期的 Unix 时间戳 gmmktime 返回 GMT 日期的 UNIX 时间戳 date_timestamp_get 返回今天的日期和时间的 Unix 时间戳 strtotime 将任何英文文本的日期或时间描述解析为 Unix 时间戳 设置时间（非时间戳） 函数名 描述 date_time_set 用于设置时间 date_date_set 设置一个新的日期 strftime 根据区域设置格式化本地日期和时间 gmstrftime 根据区域设置格式化 GMT/UTC 日期和时间 date_isodate_set 根据 ISO 8601 标准设置日期，使用周和天的偏移量（而不是使用一个规定的日期） 获取时间（非时间戳） 函数名 描述 localtime 返回本地时间（一个数组存放关于时间的各项信息） getdate 返回一个根据 timestamp 得出的包含有日期信息的结合数组。如果没有给出时间戳，则认为是当前本地时间 gettimeofday 返回一个包含当前时间信息的数组 strptime 解析由 strftime() 生成的时间/日期 date_parse 返回一个包含指定日的详细信息的关联数组 date_parse_from_format 根据指定的格式返回一个包含指定日期信息的关联数组 date 格式化一个本地时间／日期 gmdate 格式化 GMT/UTC 日期和时间，并返回格式化的日期字符串 idate 将本地时间/日期格式化为整数，与 date() 不同，idate() 只接受一个字符作为 format 参数 date_format 返回一个根据指定格式进行格式化的日期 date_interval_format 用于格式化时间间隔 date_interval_create_from_date_string Sets up a DateInterval from the relative parts of the string date_sun_info 返回一个包含有关指定日期与地点的日出/日落和黄昏开始/黄昏结束的信息的数组 date_sunrise 返回指定日期与地点的日出时间 date_sunset 返回指定日期与地点的日落时间 date_create 返回一个新的 DateTime 对象 date_create_from_format 返回一个根据指定格式进行格式化的新的 DateTime 对象 date_create_immutable Returns new DateTimeImmutable object date_create_immutable_from_format Returns new DateTime Immutable object formatted according to the specified format 时间加减 函数名 描述 date_add 添加日、月、年、时、分和秒到一个日期 date_sub 从指定日期减去日、月、年、时、分和秒 date_modify 修改时间戳 date_diff 返回两个 DateTime 对象间的差值 校验 函数名 描述 checkdate 用于验证格利高里日期 时区 函数名 描述 timezone_open 创建一个新的 DateTimeZone 对象 timezone_name_get 返回时区的名称 timezone_name_from_abbr 根据时区缩略语返回时区名称 timezone_abbreviations_list 返回包含夏令时、偏移量和时区名称的关联数组 timezone_identifiers_list 返回带有所有时区标识符的数值数组 timezone_location_get 返回指定时区的位置信息 date_offset_get 返回时区偏移 timezone_offset_get 返回相对于 GMT 的时区偏移 timezone_transitions_get 返回所有时区转换 timezone_version_get 以字符串形式返回时区数据库的版本 date_timezone_get Alias of DateTime::getTimezone date_timezone_set Alias of DateTime::setTimezone date_default_timezone_get 返回脚本中所有日期/时间函数使用的默认时区 date_default_timezone_set 设置脚本中所有日期/时间函数使用的默认时区 其它 函数名 描述 date_get_last_errors 返回解析日期字符串时找到的警告/错误 Calendar日历信息、月、星期、时间戳 函数名 描述 cal_info 返回选定历法的信息 cal_days_in_month 返回某个历法中某年中某月的天数 JDDayOfWeek 返回星期的日期 JDMonthName 返回月份的名称 jdtounix 转变Julian Day计数为一个Unix时间戳 unixtojd 转变Unix时间戳为Julian Day计数 日历转换 函数名 描述 cal_to_jd 从一个支持的历法转变为 Julian Day（儒略历）计数。 cal_from_jd 转换Julian Day计数到一个支持的历法。 FrenchToJD 从一个French Republican历法（法国共和历）的日期得到Julian Day计数。 JDToFrench 转变一个Julian Day计数到French Republican历法的日期 GregorianToJD 转变一个Gregorian历法（格利高里历法）日期到Julian Day计数 JDToGregorian 转变一个Julian Day计数为Gregorian历法日期 JewishToJD 转变一个Jewish历法（犹太历法）的日期为一个Julian Day计数 jdtojewish 转换一个julian天数为Jewish历法的日期 JulianToJD 转变一个Julian历法（儒略历）的日期为Julian Day计数 JDToJulian 转变一个Julian Day计数到Julian历法的日期 西方特用 函数名 描述 easter_date 得到指定年份的复活节午夜时的 Unix 时间戳。 easter_days 得到指定年份的3月21日到复活节之间的天数]]></content>
      <categories>
        <category>PHP</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[PHP 常量]]></title>
    <url>%2F2017%2F10%2F23%2Fphp-const%2F</url>
    <content type="text"><![CDATA[常量自定义常量 比较项 define const 版本 php 4.0 + php 5.3.0 + 定义位置 任意 作用域的最顶端，不能在函数内、循环内以及 if 语句之内 是否支持表达式 是 否 是否支持大小写不敏感 是, 第三个参数为 true , 表示不敏感 否 常量数组支持的版本 php 7 + php 5.6 + 详细说明, 参考 PHP中const和define()定义常量的细节区别 预定义常量是在 PHP 的内核中就定义好了的常量。区分大小写。这些变量包括了以下这些东西：从外部变量到内置的环境变量，从最新的错误信息到最新收到的 header。 常用的预定义常量有： 名称 说明 PHP_VERSION 当前 php 的版本 PHP_OS 当前所使用的操作系统类型 PHP_SAPI web 服务器与 php 之间的接口 DEFAULT_INCLUDE_PATH php 默认的包含路径 PHP_BINDIR php 的执行路径 PHP_LIBDIR php 扩展模块的路径 PEAR_INSTALL_DIR pear 的安装路径 PEAR_EXTENSION_DIR pear 的扩展路径 E_ERROR 指向最近的错误处 E_WARNING 指向最近的警告处 E_NOTICE 指向最近的注意处 PHP_INT_MAX 最大的整型数 M_E 自然对数 e值 M_PI 数学上的圆周率的值 TRUE 逻辑真值 FALSE 逻辑假值 魔术常量 名称 说明 __DIR__ 文件所在的目录。如果用在被包括文件中，则返回被包括的文件所在的目录。它等价于 dirname(__FILE__)。除非是根目录，否则目录中名不包括末尾的斜杠。 【PHP 5.3.0+】 __FILE__ 文件的完整路径和文件名。如果用在被包含文件中，则返回被包含的文件名。自 PHP 4.0.2 起，__FILE__ 总是包含一个绝对路径（如果是符号连接，则是解析后的绝对路径），而在此之前的版本有时会包含一个相对路径。 __LINE__ 文件中的当前行号。 __NAMESPACE__ 当前命名空间的名称（区分大小写）。此常量是在编译时定义的。 【PHP 5.3.0+】 __FUNCTION__ 函数名称。【PHP 4.3.0+】 __TRAIT__ Trait 的名字，包括其被声明的作用区域（例如 Foo\Bar）【PHP 5.4.0+】 __CLASS__ 类的名称。【PHP 4.3.0+】 __METHOD__ 类的方法名。返回该方法被定义时的名字（区分大小写）。 【PHP 5.0.0+】]]></content>
      <categories>
        <category>PHP</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[PHP 类型比较表]]></title>
    <url>%2F2017%2F10%2F23%2Fphp-relax-compare%2F</url>
    <content type="text"><![CDATA[以下的表格显示了 PHP 类型和比较运算符在松散和严格比较时的作用。]]></content>
      <categories>
        <category>PHP</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[PHP 操作符的优先级]]></title>
    <url>%2F2017%2F10%2F23%2Fphp-prority%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>PHP</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[详解 PHP 服务器变量 $_SERVER]]></title>
    <url>%2F2017%2F10%2F21%2Fphp-server%2F</url>
    <content type="text"><![CDATA[客户端浏览当前页面的用户的 IP 地址。1[REMOTE_ADDR] =&gt; 192.168.1.5 用户机器上连接到 Web 服务器所使用的端口号。1[REMOTE_PORT] =&gt; 51666 请求通信协议1[REQUEST_SCHEME] =&gt; http 请求页面时通信协议的名称和版本。1[SERVER_PROTOCOL] =&gt; HTTP/1.1 访问页面使用的请求方法；例如，“GET”, “HEAD”，“POST”，“PUT”。1[REQUEST_METHOD] =&gt; GET query string（查询字符串），如果有的话，通过它进行页面访问。1[QUERY_STRING] =&gt; 当前请求头中 Accept: 项的内容，如果存在的话。1[HTTP_ACCEPT] =&gt; text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8 当前请求头中 User-Agent: 项的内容，如果存在的话。该字符串表明了访问该页面的用户代理的信息。除此之外，你可以通过 get_browser() 来使用该值，从而定制页面输出以便适应用户代理的性能。1[HTTP_USER_AGENT] =&gt; Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.91 Safari/537.36 当前请求头中 Host: 项的内容，如果存在的话。1[HTTP_HOST] =&gt; 192.168.1.168 当前请求头中 Connection: 项的内容1[HTTP_CONNECTION] =&gt; keep-alive 当前请求头中 Accept-Language: 项的内容1[HTTP_ACCEPT_LANGUAGE] =&gt; zh-CN,zh;q=0.8 当前请求头中 Accept-Encoding: 项的内容1[HTTP_ACCEPT_ENCODING] =&gt; gzip, deflate 表示浏览器可读懂服务器发过来的请求。1[HTTP_UPGRADE_INSECURE_REQUESTS] =&gt; 1 表示浏览器是否会缓存这个页面信息。1[HTTP_CACHE_CONTROL] =&gt; max-age=0 服务器端当前运行脚本所在的服务器的主机名。如果脚本运行于虚拟主机中，该名称是由那个虚拟主机所设置的值决定。1[SERVER_NAME] =&gt; localhost 当前运行脚本所在的服务器的 IP 地址1[SERVER_ADDR] =&gt; 192.168.1.168 Web 服务器使用的端口。默认值为 “80”。如果使用 SSL 安全连接，则这个值为用户设置的 HTTP 端口。1[SERVER_PORT] =&gt; 80 服务器标识字符串，在响应请求时的头信息中给出。1[SERVER_SOFTWARE] =&gt; nginx/1.13.5 服务器使用的 CGI 规范的版本1[GATEWAY_INTERFACE] =&gt; CGI/1.1 当前运行脚本所在的文档根目录。在服务器配置文件中定义。1[DOCUMENT_ROOT] =&gt; /usr/local/nginx/html URI 用来指定要访问的页面。例如 “/index.html”。1[REQUEST_URI] =&gt; /phpinfo.php 当前执行脚本的文件名，与 document root 有关。1[PHP_SELF] =&gt; /phpinfo.php 包含当前脚本的路径。这在页面需要指向自己时非常有用。__FILE__ 常量包含当前脚本(例如包含文件)的完整路径和文件名。1[SCRIPT_NAME] =&gt; /phpinfo.php 当前执行脚本的绝对路径。1[SCRIPT_FILENAME] =&gt; /usr/local/nginx/html/phpinfo.php 请求开始时的时间戳，微秒级别的精准度。 自 PHP 5.4.0 开始生效。1[REQUEST_TIME_FLOAT] =&gt; 1508427782.9947 请求开始时的时间戳。从 PHP 5.1.0 起可用。1[REQUEST_TIME] =&gt; 1508427782 待确定1[HOSTNAME] =&gt; Redgo 1[USER] =&gt; root 1[HOME] =&gt; /root 1[SHELL] =&gt; /bin/bash 1[LANG] =&gt; en_US.UTF-8 1[PATH] =&gt; /usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin:/root/bin 1[OLDPWD] =&gt; /usr/local/nginx 1[PWD] =&gt; /usr/local/nginx/html 1[TERM] =&gt; screen-256color 1[TMUX] =&gt; /tmp/tmux-0/default,1690,1 1[TMUX_PANE] =&gt; %2 1[LS_COLORS] =&gt; rs=0:di=38;5;27:ln=38;5;51:mh=44;38;5;15:pi=40;38;5;11:so=38;5;13:do=38;5;5:bd=48;5;232;38;5;11:cd=48;5;232;38;5;3:or=48;5;232;38;5;9:mi=05;48;5;232;38;5;15:su=48;5;196;38;5;15:sg=48;5;11;38;5;16:ca=48;5;196;38;5;226:tw=48;5;10;38;5;16:ow=48;5;10;38;5;21:st=48;5;21;38;5;15:ex=38;5;34:*.tar=38;5;9:*.tgz=38;5;9:*.arj=38;5;9:*.taz=38;5;9:*.lzh=38;5;9:*.lzma=38;5;9:*.tlz=38;5;9:*.txz=38;5;9:*.zip=38;5;9:*.z=38;5;9:*.Z=38;5;9:*.dz=38;5;9:*.gz=38;5;9:*.lz=38;5;9:*.xz=38;5;9:*.bz2=38;5;9:*.tbz=38;5;9:*.tbz2=38;5;9:*.bz=38;5;9:*.tz=38;5;9:*.deb=38;5;9:*.rpm=38;5;9:*.jar=38;5;9:*.rar=38;5;9:*.ace=38;5;9:*.zoo=38;5;9:*.cpio=38;5;9:*.7z=38;5;9:*.rz=38;5;9:*.jpg=38;5;13:*.jpeg=38;5;13:*.gif=38;5;13:*.bmp=38;5;13:*.pbm=38;5;13:*.pgm=38;5;13:*.ppm=38;5;13:*.tga=38;5;13:*.xbm=38;5;13:*.xpm=38;5;13:*.tif=38;5;13:*.tiff=38;5;13:*.png=38;5;13:*.svg=38;5;13:*.svgz=38;5;13:*.mng=38;5;13:*.pcx=38;5;13:*.mov=38;5;13:*.mpg=38;5;13:*.mpeg=38;5;13:*.m2v=38;5;13:*.mkv=38;5;13:*.ogm=38;5;13:*.mp4=38;5;13:*.m4v=38;5;13:*.mp4v=38;5;13:*.vob=38;5;13:*.qt=38;5;13:*.nuv=38;5;13:*.wmv=38;5;13:*.asf=38;5;13:*.rm=38;5;13:*.rmvb=38;5;13:*.flc=38;5;13:*.avi=38;5;13:*.fli=38;5;13:*.flv=38;5;13:*.gl=38;5;13:*.dl=38;5;13:*.xcf=38;5;13:*.xwd=38;5;13:*.yuv=38;5;13:*.cgm=38;5;13:*.emf=38;5;13:*.axv=38;5;13:*.anx=38;5;13:*.ogv=38;5;13:*.ogx=38;5;13:*.aac=38;5;45:*.au=38;5;45:*.flac=38;5;45:*.mid=38;5;45:*.midi=38;5;45:*.mka=38;5;45:*.mp3=38;5;45:*.mpc=38;5;45:*.ogg=38;5;45:*.ra=38;5;45:*.wav=38;5;45:*.axa=38;5;45:*.oga=38;5;45:*.spx=38;5;45:*.xspf=38;5;45: 1[SHLVL] =&gt; 2 1[LOGNAME] =&gt; root 1[LESSOPEN] =&gt; ||/usr/bin/lesspipe.sh %s 1[G_BROKEN_FILENAMES] =&gt; 1 1[_] =&gt; /usr/local/php7/bin/php-cgi 1[FCGI_ROLE] =&gt; RESPONDER 1[REDIRECT_STATUS] =&gt; 200 1[DOCUMENT_URI] =&gt; /phpinfo.php 1[CONTENT_LENGTH] =&gt; 1[CONTENT_TYPE] =&gt; 1[MAIL] =&gt; /var/spool/mail/root 1[QTDIR] =&gt; /usr/lib64/qt-3.3 1[QTINC] =&gt; /usr/lib64/qt-3.3/include 1[QTLIB] =&gt; /usr/lib64/qt-3.3/lib 1[SELINUX_ROLE_REQUESTED] =&gt; 1[SELINUX_USE_CURRENT_RANGE] =&gt; 1[SELINUX_LEVEL_REQUESTED] =&gt; 1[HISTCONTROL] =&gt; ignoredups 1[HISTSIZE] =&gt; 1000 1[CVS_RSH] =&gt; ssh 1[SSH_CLIENT] =&gt; 192.168.1.5 49775 22 1[SSH_CONNECTION] =&gt; 192.168.1.5 51100 192.168.1.168 22 1[SSH_TTY] =&gt; /dev/pts/0]]></content>
      <categories>
        <category>PHP</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[PHP 常用的打印方法]]></title>
    <url>%2F2017%2F10%2F19%2Fphp-print%2F</url>
    <content type="text"><![CDATA[PHP 常用的打印方法打印方法用于输出变量信息，输出对象等，可以方便调试等； echoecho() 实际上不是一个函数，是 php 语句，因此无需对其使用括号。不过，如果希望向 echo() 传递一个以上的参数，那么使用括号会发生解析错误。而且 echo 是返回 void 的，并不返回值，所以不能使用它来赋值。 示例：1234567891011121314// 输出 wordsecho "words"; // 输出 wordsecho("words"); // 不用括号的时候可以用逗号隔开多个值， 会输出 alicebillcartdaring 不管是否换行，最终显示都是为一行echo "alice", "bill", "cart", "daring";// 如果 $firstname = "alice", 则会输出 alice com. echo "$fistname com";// 由于使用单引号，所以不会输出 $firstname 的值，而是输出 $firstname comecho '$firstname com'; printprint() 和 echo() 用法一样，但是 echo 速度会比 print 快一点点。实际上它也不是一个函数，因此无需对其使用括号。不过，如果希望向 print() 传递一个以上的参数，那么使用括号会发生解析错误。注意 print 总是返回 1 的，这个和 echo 不一样，也就是可以使用 print 来赋值，不过没有实际意义。 示例：123$a = print("alice"); // 这个是允许的 echo $a; // $a的值是1 print_rprint_r 函数打印关于变量的易于理解的信息。 如果变量是 string , integer 或 float , 将会直接输出其值，如果变量是一个数组，则会输出一个格式化后的数组，便于阅读，也就是有 key 和 value 对应的那种格式。对于 object 对象类同。 示例：12$a = "alice";print_r($a); // 输出 "alice" printfprintf 函数返回一个格式化后的字符串。语法：printf(format, arg1, arg2, arg...) 参数 format 是转换的格式，以百分比符号 (“%”) 开始到转换字符结束。下面是可能的 format 值 format符号 呈现 %% 返回百分比符号 %b 二进制数 %c 依照 ASCII 值的字符 %d 带符号十进制数 %e 可续计数法（比如 1.5e+3） %u 无符号十进制数 %f 浮点数(local settings aware) %F 浮点数(not local settings aware) %o 八进制数 %s 字符串 %x 十六进制数（小写字母） %X 十六进制数（大写字母） 示例：1printf("My name is %s %s。","alice", "com"); // 输出 My name is alice com。 sprintf此函数使用方法和 printf 一样，唯一不同的就是该函数把格式化的字符串写写入一个变量中，而不是输出来。 示例：1234567//你会发现没有任何东西输出的。sprintf("My name is %1\$s %1\$s","alice", "com");$out = sprintf("My name is %1\$s %2\$s","alice", "com");//输出 My name is alice comecho $out; var_dump功能: 输出变量的内容、类型或字符串的内容、类型、长度。常用来调试。 var_export此函数返回关于传递给该函数的变量的结构信息，它和 var_dump() 类似，不同的是其返回的表示是合法的 PHP 代码。]]></content>
      <categories>
        <category>PHP</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[PHP 扩展 Mongodb 的 FAQ]]></title>
    <url>%2F2017%2F10%2F18%2Fphp-extensions-mongo%2F</url>
    <content type="text"><![CDATA[mongo.native_long 配置项笔者在 Laravel框架，读取 mongodb 数据，其中字段是 Int64 的这些数据，在php内存中显示为浮点型，然后过滤筛选之类的就出了问题；而在测试机上部署相同的代码，一切显示正常，最后发现是 mongo.native_long配置项不同； 本地环境 测试机环境 解决方法，在代码公共引用处添加一行 ini_set(&#39;mongo.native_long&#39;, 1);这样，php 不会将 mongo 数据库中的 Int64 字段转为 浮点型； php 与 mongo 数字类型转换规律 参考阅读 64-bit integers in MongoDB]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP-Extensions</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 下内网映射工具 ngrock]]></title>
    <url>%2F2017%2F10%2F17%2Flinux-ngrock%2F</url>
    <content type="text"><![CDATA[ngrok 是非常流行的反向代理服务，可以进行内网穿透，支持 80 端口以及自定义 tcp 端口转发。这样你就可以运行本地的程序，而让别人通过公网访问了。比如微信公众号开发的时候，需要接入一个外网的IP地址，由于我们在自己的电脑上需要开发，测试很不方便，不可能每次都把代码上传到服务器，测试一次。 按照官网下载并安装，如图所示： 运行时，指定http端口号，即可；对暴露的公网IP进行访问，相当于访问本机器的此端口应用；]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux Tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cmder 常用命令]]></title>
    <url>%2F2017%2F10%2F16%2Fwindows-cmder%2F</url>
    <content type="text"><![CDATA[cmder 是一个跨平台的命令行增强工具，可以集成windows batch, power shell, git, linux bash等多种命令行于一体；详情见官网； 快捷键ctrl + t：快速新建一个 tab框；ctrl + w：快速关闭一个 tab框；alt + enter：全屏；ctrl + &#96;：快速打开或关闭 cmder 面板；shift + 鼠标左键拖动：复制选择文本；win + alt + p 键快速打开 settings页面； Settings显示中文如果当前目录下存在中文文件，ls 会显示乱码，解决的方法也简单，就是： 打开设置，在 startup -&gt; environment 中输入： 1set LANG=zh_CN.UTF-8 中文文字乱码重叠打开设置，在 main 中，取消勾选 Monospace 选项； 设置默认打开目录打开设置，在 startup -&gt; tasks 中，修改 {cmd::Cmder}项，把 123cmd /k "%ConEmuDir%\..\init.bat" -new_console:d:%USERPROFILE%``` 替换为 cmd /k “%ConEmuDir%..\init.bat” -new_console:d:D:\vscode_workspace`笔者，将默认打开目录设置为 D:\vscode_workspace 关闭启动时自动更新打开设置，在 main -&gt; update 中， Do automatic check on选项中取消 startup 选项； 修改背景透明色打开设置，在 features -&gt; transparency 中， 调整 transparent 指标的位置；]]></content>
      <tags>
        <tag>Windows Tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows 上 hexo 安装]]></title>
    <url>%2F2017%2F10%2F15%2Fheox-window-install%2F</url>
    <content type="text"><![CDATA[环境准备全局安装 hexo， 需要准备环境 node.js、 git； Node.js从Node.js 官网下载地址，下载，双击安装； 进入 cmd 环境下，键入 node -v 查看是否安装成功； git参考之前写的文章 Windows 上 Git 安装部署 开始安装鼠标右击 Git Bash Here，进入 Bash 环境，先修改安装源 12npm config set registry https://registry.npm.taobao.orgnpm info underscore 然后，键入 1npm install -g hexo]]></content>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows 上 Git 安装部署]]></title>
    <url>%2F2017%2F10%2F14%2Fgit-window-install%2F</url>
    <content type="text"><![CDATA[下载打开 http://git-scm.com/download/win，下载会自动开始。 笔者安装的是 32 位的客户端，所以默认安装位置在 C:\Program Files (x86)\Git; 公密钥生成生成进入 C:\Program Files (x86)\Git\bin目录，双击 bash 命令；在打开的图形界面中键入 1ssh-keygen -t rsa -C "your_email@example.com" 提示你把新生成的 id_rsa 存放到哪里，此处默认会存放在c盘的用户名下的 .ssh 文件夹下并默认名为 id_rsa，注意防止命名重复导致覆盖； 在输入了路径后，会提示你输入提交项目时输入的验证密码，不输则表示不用密码； 添加默认 SSH 只会读取 id_rsa，所以为了让 SSH 识别新的私钥，需要将其添加到 SSH agent1ssh-add ~/.ssh/id_rsa_github 如果报错：Could not open a connection to your authentication agent. 即无法连接到ssh agent；则执行 ssh-agent bash 命令后再执行 ssh-add 命令 配置c盘的用户名下的 .ssh 文件夹下如果不存在 config 文件，即创建； 内容如下 1234567891011Host github.com HostName github.com User git PubkeyAuthentication yes IdentityFile C:\Users\Administrator\.ssh\id_rsa_githubHost git.coding.net HostName git.coding.net User git PubkeyAuthentication yes IdentityFile C:\Users\Administrator\.ssh\id_rsa_codingnet 测试使用命令：1ssh -T git@github.com]]></content>
      <categories>
        <category>Version Management</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 下压缩与解压缩命令 zip 和 tar]]></title>
    <url>%2F2017%2F10%2F12%2Flinux-tar-zip%2F</url>
    <content type="text"><![CDATA[zip 在 /home/blog目录下，压缩 source 目录，命令为 source.zip 1zip -r source.zip source 将 source.zip 文件解压缩至指定目录；不加 -d 参数，默认是在当前目录下 1unzip source.zip -d source_dir 查看 source.zip 文件的完整性 1unzip -t source.zip 查看 source.zip 文件的内容 1unzip -v source.zip 将 source.zip 中的所有文件扁平解压至 zip 文件所在目录 1unzip -j source.zip tar 压缩 123tar -cvf source.tar source &lt;== 仅打包，不压缩！tar -zcvf source.tar.gz source &lt;== 打包后，以 gzip 压缩tar -jcvf source.tar.bz2 source &lt;== 打包后，以 bzip2 压缩 解压缩 123tar -xvf source.tar &lt;== 解压缩 打包文件tar -zxvf source.tar.gz &lt;== 解压缩 以 gzip 压缩的打包文件tar -jxvf source.tar.bz2 &lt;== 解压缩 以 bzip2 压缩的打包文件 查看 1tar -tvf source.tar 主选项 -c： 创建新的档案文件。如果用户想备份一个目录或是一些文件，就要选择这个选项。相当于打包。 -x：从档案文件中释放文件。相当于拆包。 -t：列出档案文件的内容，查看已经备份了哪些文件。 辅助选项 -z： 是否同时具有 gzip 的属性？亦即是否需要用 gzip 压缩或解压？一般格式为 xx.tar.gz 或 xx. tgz -j： 是否同时具有 bzip2 的属性？亦即是否需要用 bzip2 压缩或解压？一般格式为 xx.tar.bz2 -v：压缩的过程中显示文件！这个常用 -f：使用档名，请留意，在 f 之后要立即接档名喔！不要再加其他参数！ -p：使用原文件的原来属性（属性不会依据使用者而变） --exclude FILE：在压缩的过程中，不要将指定 FILE 打包！可使用正则 *，要排除多个文件，则多次使用本参数；]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux Tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 下进程查看命令 ps]]></title>
    <url>%2F2017%2F10%2F12%2Flinux-ps%2F</url>
    <content type="text"><![CDATA[ps 命令是基本同时也是非常强大的进程查看命令。使用该命令可以确定有哪些进程正在运行和运行的状态、进程是否结束、进程有没有僵死、哪些进程占用了过多的资源； 参数挺多的，记录实际一些用法； 显示所有使用者的进程命令：ps auxf参数介绍： a : 显示其他用户启动的进程 u : 启动这个进程的用户和它启动的时间，没有指定值，默认是 root; 会被 a 参数覆盖 x : 显示没有控制终端的进程 f : 全部列出 显示： 内容包括： USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND 用户名 进程ID cpu占用率 内存占用率 使用虚存大小 实际内存的大小 关联的终端（tty） 进程的状态 进程启动时间和日期 占用总cpu时间 正在执行的命令行命令 指定用户的进程命令：ps -fu rpc --forest参数介绍： f : 全部列出 u : 指定用户名或者用户ID，没有指定值，默认是 root; 会被 a 参数覆盖 --forest : 打印过程树，过程树显示系统中的进程如何相互链接; 父类被杀死的进程由init（或systemd）采用 显示： 指定用户组的进程命令：ps -fG daemon --forest参数介绍： f : 全部列出 G : 指定组名或组ID --forest : 打印过程树，过程树显示系统中的进程如何相互链接; 父类被杀死的进程由init（或systemd）采用 显示： 指定 PID 的进程命令：ps -fp 1021参数介绍： f : 全部列出 p : 指定进程ID，可选多个，以逗号隔开 显示： 指定 PPID 的子进程命令：ps -f --ppid 2参数介绍： f : 全部列出 --ppid : 指定进程ID的子进程 显示： 指定 TTY 的进程命令：ps -ft tty1参数介绍： f : 全部列出 t : 指定tty的进程 显示： 指定进程的所有线程命令：ps -fL -C httpd参数介绍： f : 全部列出 L : 打印线程 C : 指定进程名 显示： 内容包括： USER PID PPID LWP C NLWP 用户名 进程ID 父进程ID 线程 进程名 线程数 根据CPU使用排序进程静态命令：ps -eo pid,ppid,cmd,%mem,%cpu --sort=-%cpu | head动态命令：watch -n 1 &#39;ps -eo pid,ppid,cmd,%mem,%cpu --sort=-%cpu | head&#39;参数介绍： e : 显示所有进程，同A参数 o : 自定义显示字段 --sort：根据哪个字段排序 根据内存使用排序进程静态命令：ps -eo pid,ppid,cmd,%mem,%cpu --sort=-%mem | head动态命令：watch -n 1 &#39;ps -eo pid,ppid,cmd,%mem,%cpu --sort=-%mem | head&#39;参数介绍： e : 显示所有进程，同A参数 o : 自定义显示字段 --sort：根据哪个字段排序 附录进程状态 R: 运行 S: 睡眠 I: 空闲 Z: 僵死 D: 不可中断 T: 终止 P: 等待交换页 W: 无驻留页 X: 死掉的进程 &lt;: 高优先级进程 N: 低优先级进程 L: 内存锁页 s: 进程的领导者（在它之下有子进程） +: 位于后台的进程组]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux Tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 下 python 版本管理工具 pyenv]]></title>
    <url>%2F2017%2F10%2F09%2Flinux-pyenv%2F</url>
    <content type="text"><![CDATA[简介pyenv是一个简单的python版本管理工具，前身为pythonbrew，pyenv允许你改变全局的python版本，安装多种不同的python版本，设置应用指定的python版本以及创建/管理虚拟的python环境； 安装Centos6.8上安装pyenv，先安装依赖 1yum -y install readline readline-devel readline-static openssl openssl-devel openssl-static sqlite-devel bzip2-devel bzip2-libs 安装pyenv:1curl -L https://raw.githubusercontent.com/pyenv/pyenv-installer/master/bin/pyenv-installer | bash 配置环境变量，并添加 pyenv 初始化到你的shell，123echo 'export PYENV_ROOT="$HOME/.pyenv"' &gt;&gt; ~/.bashrcecho 'export PATH="$PYENV_ROOT/bin:$PATH"' &gt;&gt; ~/.bashrcecho 'eval "$(pyenv init -)"' &gt;&gt; ~/.bashrc 常用命令 查看当前设置默认的 python 版本 1pyenv version 查看当前已安装的所有python版本 1pyenv versions 查看当前可安装的python版本列表 1pyenv install -l | less 安装指定版本的python 1pyenv install 2.7.1 设置全局python版本 1pyenv global &lt;python版本&gt; 设置局部 Python 版本设置之后可以在目录内外分别试下which python或python --version看看效果, 如果没变化的话可以pyenv rehash之后再试试 1pyenv local &lt;python版本&gt; python版本本地安装以本地安装 2.7.1 版本为例， 通过执行pyenv install 2.7.1 -v获取下载地址，然后通过浏览器下载文件，在目录/tmp准备Python-2.7.1.tgz文件； 然后在 /tmp下启动一个简单的 httpserver 12cd /tmppython -m SimpleHTTPServer 4999 在执行pyenv install 2.7.1之前要先添加一个环境变量 12export PYTHON_BUILD_MIRROR_URL="http://127.0.0.1:4999/"pyenv install 2.7.1 -v 从httpserver的打印log中发现收到的请求是一个字符串“HEAD /ca13e7b1860821494f70de017202283ad73b1fb7bd88586401c54ef958226ec8 HTTP/1.1“，我们要把Python-2.7.1.tgz复制一份到这个字符串为名的文件，然后重启httpserver，最后用pyenv即可安装 12345cp Python-2.7.1.tgz ca13e7b1860821494f70de017202283ad73b1fb7bd88586401c54ef958226ec8python -m SimpleHTTPServer 4999 pyenv install 2.7.1 FAQ支持 YouCompleteMe需要在 .bashrc 加入下面命令： 1export PYTHON_CONFIGURE_OPTS="--enable-shared"]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux Tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建 LNMP 环境]]></title>
    <url>%2F2017%2F10%2F02%2Flnmp-install%2F</url>
    <content type="text"><![CDATA[本文是在Centos 6.8服务器上进行搭建PHP + Nginx + Mysql环境的指导性文章； PHP7下载PHP7的源码包 1wget http://tw2.php.net/get/php-7.1.9.tar.gz/from/this/mirror -O php7.1.9.tar.gz 说明，-o参数指定存在下载文件的路径 解压 1tar zxvf php7.1.9.tar.gz 说明，可以加-C参数指定安装目录； 安装依赖库1yum -y install libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel mysql pcre-devel dpkg dpkg-dev bzip2-devel curl-devel db4-devel libXpm-devel gmp-devel libc-client-devel openldap-devel unixODBC-devel postgresql-devel libxslt-devel libxml2-devel 生成 Makefile，为下一步的编译做准备 12345678910111213141516171819202122232425262728293031323334./configure --prefix=/usr/local/php7 \ --with-curl \ --with-freetype-dir \ --with-gd \ --with-gettext \ --with-iconv-dir \ --with-kerberos \ --with-libdir=lib64 \ --with-libxml-dir \ --with-mysqli \ --with-openssl \ --with-pcre-regex \ --with-pdo-mysql \ --with-pdo-sqlite \ --with-pear \ --with-png-dir \ --with-xmlrpc \ --with-xsl \ --with-zlib \ --enable-fpm \ --enable-bcmath \ --enable-libxml \ --enable-inline-optimization \ --enable-gd-native-ttf \ --enable-mbregex \ --enable-mbstring \ --enable-opcache \ --enable-pcntl \ --enable-shmop \ --enable-soap \ --enable-sockets \ --enable-sysvsem \ --enable-xml \ --enable-zip 编译 1make 安装1make install 移动配置文件1234cd /usr/local/php7/etccp /home/php/php-7.1.9/php.ini-development ../lib/php.inicp php-fpm.conf.default php-fpm.conf 通过软链接，加入系统命令1ln -s /usr/local/php7/bin/php /usr/local/bin/php7 确认安装成功1php7 -v Nginx下载nginx源码包，nginx 官方下载地址 笔者在 home 目录进行解压缩 1tar zxvf nginx-1.13.5.tar.gz 配置、编译、安装12./configuremake &amp;&amp; make install 通过软链接，加入系统命令1ln -s /usr/local/nginx/sbin/nginx /usr/local/bin/nginx 检查是否安装成功1nginx -t 显示如下图 配置支持 PHP修改php的php.ini信息12345678extension_dir = /usr/local/php7/lib/php/extensionsenable_dl = Oncgi.fix_pathinfo=1cgi.force_redirect = 0fastcgi.impersonate = 1cgi.rfc2616_headers = 1 修改nginx配置文件/usr/local/nginx/conf/nginx.con 1234567location ~ \.php$ &#123; root /usr/local/nginx/html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /usr/local/nginx/html$fastcgi_script_name; include fastcgi_params; &#125; 验证启动内置 fastcgi 管理器1/usr/local/php7/bin/php-cgi -b 127.0.0.1:9000 -c /usr/local/php7/etc/php.ini&amp; 重新加载nginx配置与1nginx -s reload 通过浏览器访问nginx所在服务器 http://192.168.31.168/phpinfo.php; 出现php相关信息页面，成功； 关闭nginx服务器与fastcgi 管理器12nginx -s stopkillall -9 php-cgi 启用 PHP-Fpm为什么用php-fpm替换php-cgi,参考文章如何通俗地解释 CGI、FastCGI、php-fpm 之间的关系？; 笔者也还没怎么理清呢； 至于步骤，只需要把这部分的操作替换上面启动内置 fastcgi 管理器即可； 准备用户及用户组12groupadd wwwuseradd -g www www 通过cat /etc/passwd查看当前系统有哪些用户；通过cat /etc/group命令来查看当前系统有哪些用户组； 文件配置1cp /usr/local/php7/etc/php-fpm.d/www.conf.default /usr/local/php7/etc/php-fpm.d/www.conf 同时修改文件/usr/local/php7/etc/php-fpm.d/www.conf内容 12user = wwwgroup = www 启动 php-fpm 1/usr/local/php7/sbin/php-fpm 查看启动1netstat -lnt | grep 9000 关闭php-fpm1pkill php-fpm MysqlMysql 官网页面，选择 Linux Generuc 版本，下载最新版本 (mysql-5.7.19-linux-glibc2.12-x86_64.tar.gz); 解压123cd /hometar zxvf mysql-5.7.19-linux-glibc2.12-x86_64.tar.gzmv mysql-5.7.19-linux-glibc2.12-x86_64 mysql 目录权限设置如果mysql目录下没有data目录，手动建一个。12cd /home/mysqlmkdir data 将mysql及其下所有的目录所有者和组均设为mysql1chown mysql:mysql -R . 通过软链接，加入系统命令1ln -s /home/mysql/bin/mysql /usr/local/bin/mysql 初始化1/home/mysql/bin/mysqld --initialize --user=mysql --datadir=/home/mysql/data --basedir=/home/mysql 初始化成功，显示如下： 注意最后一行，这也是和之有版本不同的地方，它给了root一个初始密码，后面要登录的时候要用到这个密码。 配置由于在5.7.18开始，二进制包不再包含示例文件my-default.cnf，参考5.7.17版本中的文件，在/etc/my.cnf中复制以下内容：12345678910111213141516171819202122232425262728293031323334# For advice on how to change settings please see# http://dev.mysql.com/doc/refman/5.7/en/server-configuration-defaults.html# *** DO NOT EDIT THIS FILE. It‘s a template which will be copied to the# *** default location during install, and will be replaced if you# *** upgrade to a newer version of MySQL.[mysqld]# Remove leading # and set to the amount of RAM for the most important data# cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%.# innodb_buffer_pool_size = 128M# Remove leading # to turn on a very important data integrity option: logging# changes to the binary log between backups.# log_bin# These are commonly set, remove the # and set as required.basedir = /home/mysqldatadir = /home/mysql/dataport = 3306# server_id = .....socket = /home/mysql/tmp/mysql.sock# Remove leading # to set options mainly useful for reporting servers.# The server defaults are faster for transactions and fast SELECTs.# Adjust sizes as needed, experiment to find the optimal values.# join_buffer_size = 128M# sort_buffer_size = 2M# read_rnd_buffer_size = 2M sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES [client]socket = /home/mysql/tmp/mysql.sock 注意，tmp目录不存在，请创建之。注意权限 chown -R mysql:mysql tmp 运行 运行服务器程序 1/home/mysql/bin/mysqld_safe&amp; 在这个启动脚本里已默认设置--user=mysql；在脚本末尾加&amp;表示设置此进程为后台进程，区别就是在控制台输入bg，即可将当前进程转入后台，当前shell可进行其他操作。 停止 mysql 1/home/mysql/bin/mysqladmin -uroot -p shutdown 客户端连接测试1mysql -uroot -p 输入初始化时提供的默认密码，然后进行mysql客户端界面，修改密码1alter user 'root'@'localhost' identified by '111111'; 设置mysql以服务运行并且开机启动将/home/mysql/support-files/mysql.server 拷贝为/etc/init.d/mysql并设置运行权限12cp /home/mysql/support-files/mysql.server /etc/init.d/mysqlchmod +x /etc/init.d/mysql 把mysql注册为开机启动的服务1chkconfig --add mysql 当然也可以手动进行服务的开启和关闭：12/etc/init.d/mysql start/etc/init.d/mysql stop]]></content>
      <categories>
        <category>PHP</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[搭建 WNMP 环境]]></title>
    <url>%2F2017%2F09%2F30%2Fwnmp_install%2F</url>
    <content type="text"><![CDATA[本文是在Win10上进行搭建PHP + Nginx + Mysql环境的指导性文章； PHPPHP 官方下载地址 下地地址会出现 Thread Safe 和 Non Thread Safe 两个版本，选择哪种版本参考以下： 采用IIS + ISAPI的话， 就使用 TS 版本 采用IIS + FastCGI的话，就使用 NTS 版本 配置 进入 php 的解压目录，将 php.ini-production 文件复制一份，重新命名为 php.ini 修改 php.ini取消下列设置的注释 123456789101112131415extension_dir = "ext"extension=php_curl.dllextension=php_gd2.dllextension=php_mbstring.dllextension=php_mysqli.dllextension=php_pdo_mysql.dllextension=php_pdo_odbc.dllextension=php_xmlrpc.dllenable_dl = Oncgi.fix_pathinfo=1cgi.force_redirect = 0fastcgi.impersonate = 1cgi.rfc2616_headers = 1 配置 session功能 1session.save_path = "D:/php_session" 配置文件上传功能 1upload_tmp_dir = "D:/php_upload" 修改时区信息 1date.timezone = Asia/Shanghai 加入全局环境变量；将 php 当下的目录以及 php\ext 的目录放置到系统环境变量中的 PATH中去。（环境变量的设置路径： win + x键 &gt; 系统信息 &gt; 高级系统设置 &gt; 环境变量 &gt; 系统变量，找到 Path ） NginxNginx 官方下载地址 将下载的文件移到自定义的文件夹，解压，双击nginx.exe即可运行 nginx（默认为 80端口）； Nginx 启用 PHP修改 config.php; 先将前面的“#”去掉，同样将root html;改为 root D:\Nginx\nginx\html;。再把“/scripts”改为“$document_root”(重要)，这里的“$document_root”就是指前面“root”所指的站点路径，这是改完后的： 1234567location ~ \.php$ &#123; root D:/Nginx/nginx/html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME D:/Nginx/nginx/html/$fastcgi_script_name; include fastcgi_params;&#125; 验证任务管理器结束nginx.exe进程； 启动内置 fastcgi 管理器 php-cgi.exe -b 127.0.0.1:9000 -c D:\Nginx\php\php.ini 再运行nginx.exe； 通过浏览器访问 http://127.0.0.1/phpinfo.php； 优化：一键启动与关闭目前每次启动nginx，都需要开cmd，执行php-cgi.exe -b 127.0.0.1:9000 -c D:\Nginx\php\php.ini来启动内置 fastcgi 管理器，还要保证cmd页面不关；然后要启动nginx服务，操作步骤繁琐，易出错； .bat 脚本制作利用一个windows插件工具RunHiddenConsole.exe，下载； 同目录下，自制一个启动脚本start_nginx.bat与关闭脚本stop_nginx.bat；这样，通过点击启动脚本，就可以同时开启内置 fastcgi 管理器与nginx服务； start_nginx.bat文件123456789101112@echo offREM Windows 下无效REM set PHP_FCGI_CHILDREN=5REM 每个进程处理的最大请求数，或设置为 Windows 环境变量set PHP_FCGI_MAX_REQUESTS=1000 echo Starting PHP FastCGI...RunHiddenConsole D:/Nginx/php/php-cgi.exe -b 127.0.0.1:9000 -c D:/Nginx/php/php.ini echo Starting nginx...RunHiddenConsole D:/Nginx/nginx/nginx.exe -p D:/Nginx/nginx stop_nginx.bat文件123456@echo offecho Stopping nginx... taskkill /F /IM nginx.exe &gt; nulecho Stopping PHP FastCGI...taskkill /F /IM php-cgi.exe &gt; nulexit MysqlMysql 官方下载地址 如果遇到 (mysql-installer-web-community-5.7.19.0.msi) 和 (mysql-installer-community-5.7.19.0.msi) 选择后一个； 安装简单，不记录；]]></content>
      <categories>
        <category>PHP</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python 数据结构]]></title>
    <url>%2F2017%2F09%2F29%2Fpython_data_structure%2F</url>
    <content type="text"><![CDATA[各数据结构与字符串之间的转换 列表123fruit_list = ['apple','banana','orange']fruit_str = str(fruit_list) # 列表转字符串fruit_list = eval(fruit_str) # 字符串转列表 元组123fruits = ('apple','banana','orange') fruit_str = fruits.__str__() # 元组转字符串fruits = eval(fruit_str) # 字符串转元组 集合123set1 = set(['apple', 'orange', 'apple', 'pear', 'orange', 'banana'])set1_str = str(set1) # 集合转字符串set1 = eval(set1_str) # 字符串转集合 字典123defalut_str = "&#123;'a':1 ,'b':2&#125;"dict1 = eval(defalut_str) # 字符串转字典dict1_str = str(dict1) # 字典转字符串 列表初始化逗号分隔值，方括号列表。一个列表中的项不一定是同个数据类型；1list = ['physics', 'chemistry', 1997, 2000]; 定义空的 list1list = []; 增 描述 运算 添加元素到指定下标位置 list.insert(index, item) 添加元素到末尾 list.append(item) 相当于 a[len(list):] = [item] 添加一个列表 list.extend(NList) 相当于 a[len(list):] = NList 删 描述 运算 删除列表末尾的元素 list.pop() 删除列表指定下标位置的元素 list.pop(index) 相当于 del list[index] VE 删除链表中值为 x 的第一个元素 list.remove(x) 改 描述 运算 修改列表指定下标位置的元素 list[index] = item 查 描述 运算 读取列表中第一个元素 list[0] 读取列表中第最后一个元素 list[-1] 读取列表中第二个到第四个元素 list[1:5] VE 返回链表中第一个值为 x 的元素的索引 list.index(x) V 返回 x 在链表中出现的次数 list.count(x) 获取元素个数 len(list) V 获取元素最大值 max(list) V 获取元素最小值 min(list) 排序 描述 运算 原列表进行升序 list.sort() 原列表进行降序 list.sort(reverse=True) 反向列表中的元素 list.reverse() 不影响原列表，返回升序列表 sorted(list) 不影响原列表，返回降序列表 sorted(list, reverse=True) 比较 描述 运算 比较两个列表的大小 cmp(list1, list2) 元组初始化元组中只包含一个元素时，需要在元素后面添加逗号来消除歧义12345tuple1 = ('physics', 'chemistry', 1997, 2000);tuple2 = (1, 2, 3, 4, 5 );tuple3 = "a", "b", "c", "d";tuple4 = ();tuple5 = (50,); 删删除整个元组 123tup = ('physics', 'chemistry', 1997, 2000);del tup; 改元组中的元素值是不允许修改的，但可以对元组进行连接组合 1tuple6 = (12, 34.56) + ('abc', 'xyz'); 查 描述 运算 读取元组中第一个元素 tuple1[0] 读取元组中第最后一个元素 tuple1[-1] 读取元组中第二个到第四个元素 tuple1[1:5] 获取元素个数 len(tuple) 获取元素最大值 max(tuple) 获取元素最小值 min(tuple) 比较 描述 运算 比较两个元组的大小 cmp(tuple1, tuple2) 集合初始化集合是一个无序不重复元素的集; 大括号或 set() 函数可以用来创建集合。注意：想要创建空集合，你必须使用 set() 而不是 {} 123set1 = set(['apple', 'orange', 'apple', 'pear', 'orange', 'banana'])set2 = &#123;'apple', 'orange', 'banana', 'pear'&#125; 增 描述 运算 增加一个元素 set1.add(item1) 增加多个元素 set1.update(item1, item2, item3) 删 描述 运算 清空集合 set1.clear() 删除一个元素 set1.discard(item1) E 删除一个元素 set1.remove(item1) E 随机删除并返回一个元素 set.pop() 查 描述 运算 查看集合的长度 len(set1) 其他操作 描述 运算 t 和 s 的并集 t &#124; s 或 s.union(t) t 和 s 的交集 t &amp; s 或 s.intersection(t) 差集（项在 t 中，但不在 s 中） t – s 或 t.difference(s) 对称差集（项在 t 或 s 中，但不会同时出现在二者中） t ^ s 或 s.symmetric_difference(t) s 是 t 的子集 s &lt;= t 或 s.issubset(t) 或 t.issuperset(s) 字典初始化123456dict1 = &#123;&#125;;dict2 = &#123;'jack': 4098, 'sape': 4139&#125;;dict3 = dict([('sape', 4139), ('guido', 4127), ('jack', 4098)]);dict4 = dict(sape=4139, guido=4127, jack=4098); 增 描述 操作 添加另一个字典的内容 dict1.update(dict2) 添加键值对 dict[key] = value 删 描述 操作 随机返回并删除字典中的一对键和值 dict.popitem() 删除字典给定键 key 所对应的值，返回值为被删除的值。key值必须给出。否则，返回default值 dict.pop(key[, default]) 根据键名删除元素 del dict1[key] 清空字典 dict1.clear() 改 描述 操作 修改指定键名的值 dict[key] = value 查 描述 操作 E 根据键名访问键值 dict[key] 或 dict.get(key, default=None) 判断字典是否存在键名 dict.has_key(key) 以列表返回所有的键名 dict.keys() 以列表返回所有的键值 dict.values() 查看字典的数目 len(dict) 比较 描述 操作 比较两个字典的大小 cmp(dict1, dict2)]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[PHP 依赖管理工具 Composer 入门]]></title>
    <url>%2F2017%2F09%2F28%2Fphp-composer%2F</url>
    <content type="text"><![CDATA[阅读链接 最详细的命令行教程 Composer入门文章，介绍 autoload 字段 安装安装前请务必确保已经正确安装了 PHP。打开命令行窗口并执行 php -v 查看是否正确输出版本号。 第一步，下载安装脚本 composer-setup.php 到当前目录：1php -r "copy('https://install.phpcomposer.com/installer', 'composer-setup.php');" 第二步，执行安装过程：1php composer-setup.php 第三步，删除安装脚本：1php -r "unlink('composer-setup.php');" 第四步（可选），全局安装：1sudo mv composer.phar /usr/local/bin/composer 配置镜像源中国全量镜像源全局使用1composer config -g repo.packagist composer https://packagist.phpcomposer.com 可以在~/.composer/composer.json文件中看到repositories的值； 项目单独使用如果仅限当前工程使用镜像，去掉 -g 即可，如下： 1composer config repo.packagist composer https://packagist.phpcomposer.com 取消镜像 1composer config -g --unset repos.packagist Laravel China 镜像源全局使用1composer config -g repo.packagist composer https://packagist.laravel-china.org 项目单独使用如果仅限当前工程使用镜像，去掉 -g 即可，如下： 1composer config repo.packagist composer https://packagist.laravel-china.org 取消镜像 1composer config -g --unset repos.packagist 命令诊断 composer 状态 1composer diagnose]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP-Plugin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP响应可视化测试工具 httpstat]]></title>
    <url>%2F2017%2F09%2F28%2Flinux-httpstat%2F</url>
    <content type="text"><![CDATA[httpstat是一款可以测试http状态的可视化工具，通过这个工具可以看出来http响应信息。包括dns解析、tcp连接等信息，httpstat一共有golang版本和python版本。安装及使用，移步到对应的github地址； golang版本：https://github.com/davecheney/httpstat python版本：https://github.com/reorx/httpstat 说明，如果打算使用python版本的httpstat，请确保python环境至少是2.7，因为代码中使用了列表推导式，在python2.7之后才支持该语法； Demo笔者拿该命令测试博客站点的响应，效果图很直观！ 1python httpstat.py greenlightt.github.io]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux Tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 下防火墙工具 iptables]]></title>
    <url>%2F2017%2F09%2F28%2Flinux-iptables%2F</url>
    <content type="text"><![CDATA[简介iptables命令是Linux上常用的防火墙软件，是netfilter项目的一部分。可以直接配置，也可以通过许多前端和图形界面配置。 iptables可以用来过滤流入流出主机的数据包，其中一个应用场景是禁止异常IP地址访问Web暴露的端口，阻止Dos攻击； 由上表可以看到，iptables有三条链，Chain INPUT、Chain FORWARD和Chain OUTPUT；这三条链的默认策略都是Policy； Chain INPUT：负责过滤所有进入主机的数据包(最主要) Chain FORWARD：负责流经主机的数据包 Chain OUTPUT：处理所有源地址都是本机地址的数据包（也就是主机发出去的数据包） 链（chains）是数据包传播的路径，每一条链其实就是众多规则中的一个检查清单，每一条链中可以有一 条或数条规则。当一个数据包到达一个链时，iptables就会从链中第一条规则开始检查，看该数据包是否满足规则所定义的条件。如果满足，系统就会根据该条规则所定义的方法处理该数据包；否则iptables将继续检查下一条规则，如果该数据包不符合链中任一条规则，iptables就会根据该链预先定 义的默认策略来处理数据包。所以，规则的次序非常关键，谁的规则越严格，应该放的越靠前，因为检查规则的时候，是按照从上往下的方式进行检查的。 语法 iptables [-t 表名] 命令选项 ［链名］ ［条件匹配］ ［-j 目标动作或跳转］ 说明， -t参数：指定iptables命令所操作的表，有三种值filter、nat、manage； 命令选项：指定管理iptables规则的方式（比如：插入、增加、删除、查看等）； 链名：INPUT、FORWARD、OUTPUT 条件匹配：通过给定参数及值的方式，指定对符合什么样条件的数据包进行处理； -j参数：目标动作或跳转，用于指定数据包的处理方式，值有ACCEPT（允许）、DROP（丢弃）、REJECT（拒绝）、REDIRECT（跳转）； Command命令 链管理命令 -P：设置指定链的默认策略（设定默认门是关着的还是开着的）；默认策略一般只有两种：ACCEPT和DROP； 例如 iptables -P INPUT (DROP|ACCEPT)； -N： 新建一条用户自己定义的规则链，例如 iptables -N my_chain； -F： 清空规则链，例如 iptables -F my_chain； -X： 删除用户自定义的空链，例如 iptables -X my_chain； -E： 给用户自定义的链重命名，例如 iptables -E my_chain my_new_chain； 规则管理命令 -A：追加，在当前链的最后新增一个规则 -I num: 插入，把当前规则插入为第几条，不加参数，默认加在第一条。例如：-I 3表示插入为第三条； -R num：Replays替换/修改第几条规则；格式：iptables -R 3 …………； -D num：删除，明确指定删除第几条规则； 查看管理命令 -L 列出（list）指定链中所有的规则进行查看 -n：以数字的方式显示ip，它会将ip直接显示出来，如果不加-n，则会将ip反向解析成主机名。 -v：显示详细信息 -vv -vvv：越多越详细 --line-numbers : 显示规则的行号 -t nat：显示所有的关卡的信息 匹配参数通用匹配 -s：指定作为源地址匹配，这里不能指定主机名称，必须是IP（IP | IP/MASK | 0.0.0.0/0.0.0.0），而且地址可以取反，加一个“!”表示除了哪个IP之外； -d：表示匹配目标地址 -p：用于匹配协议的（这里的协议通常有3种，TCP/UDP/ICMP） -i eth0：从这块网卡流入的数据，流入一般用在INPUT和PREROUTING上 -o eth0：从这块网卡流出的数据，流出一般用在OUTPUT和POSTROUTING上 扩展匹配 隐含扩展：对协议的扩展 -p tcp：TCP协议的扩展。一般有三种扩展 --dport XX-XX：指定目标端口,不能指定多个非连续端口,只能指定单个端口，比如--dport 21 或者 --dport 21-23 (此时表示21,22,23) --sport：指定源端口 --tcp-fiags：TCP的标志位（SYN，ACK，FIN，PSH，RST，URG） -p udp：UDP协议的扩展 --dport --sport -p icmp：icmp数据报文的扩展 --icmp-type： echo-request（请求回显)，一般用 8 来表示，所以 --icmp-type 8 匹配请求回显数据包 echo-reply（响应的数据包)，一般用 0 来表示 显示扩展扩展各种模块；-m multiport表示启用多端口扩展，之后我们就可以启用比如--dports 21,23,80； 常用命令永久关闭与开启防火墙关闭 chkconfig iptables off开启 chkconfig iptables on 查看防火墙状态1service iptables status 参考阅读 永志●哥德的博客 - iptables详解 可以从该博客扩展阅读一些 Demon示例 hhktony 的博客 - iptables详解 可以从该博客扩展阅读一些原理和对state概念的理解]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux Tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 下邮件发送工具 mutt]]></title>
    <url>%2F2017%2F09%2F27%2Flinux-mutt%2F</url>
    <content type="text"><![CDATA[使用正文只包含文字 -s参数指定邮件主题 1echo "正文" | mutt -s "Linux测试发送邮件" xxx@qq.com 或者，通过读取文件内容作正文主体 1cat xx.txt | mutt -s "Linux测试发送邮件" xxx@qq.com 正文是HTML内容1mutt xxx@qq.com -s "Linux测试发送邮件" -e 'set content_type="text/html"' &lt; /tmp/hello.html 带附件 -a携带附件； 1mutt xxx@qq.com -s "Linux测试发送邮件" -e 'set content_type="text/html"' -a /tmp/phpcs_phpexcel.log -a /tmp/phpcs2.log &lt; /tmp/hello.html 日志查看：centos虚拟机可以在/var/log/maillog文件中查看发送邮件日志信息； 语法 mutt [-hnpRvxz][-a&lt;文件&gt;][-b&lt;地址&gt;][-c&lt;地址&gt;][-f&lt;邮件文件&gt;][-F&lt;配置文件&gt;][-H&lt;邮件草稿&gt;][-i&lt;文件&gt;][-m&lt;类型&gt;] [-s&lt;主题&gt;][邮件地址] 参数 描述 -a &lt;文件&gt; 在邮件中加上附加文件。 -b &lt;地址&gt; 指定密件副本的收信人地址。 -c &lt;地址&gt; 指定副本的收信人地址。 -f &lt;邮件文件&gt; 指定要载入的邮件文件。 -F &lt;配置文件&gt; 指定mutt程序的设置文件，而不读取预设的.muttrc文件。 -h 显示帮助。 -H &lt;邮件草稿&gt; 将指定的邮件草稿送出。 -i &lt;文件&gt; 将指定文件插入邮件内文中。 -m &lt;类型&gt; 指定预设的邮件信箱类型。 -n 不要去读取程序培植文件(/etc/Muttrc)。 -p 在mutt中编辑完邮件后，而不想将邮件立即送出，可将该邮件暂缓寄出。 -R 以只读的方式开启邮件文件。 -s &lt;主题&gt; 指定邮件的主题。 -v 显示mutt的版本信息以及当初编译此文件时所给予的参数。 -x 模拟mailx的编辑方式。 -z 与-f参数一并使用时，若邮件文件中没有邮件即不启动mutt。 安装1yum -y install mutt 创建或编辑配置文件/root/.muttrc 12345678# 如果你收到的邮件乱码，设置以下信息set charset="utf-8"set rfc2047_parameters=yes# 如果你想自定义发件人信息，需要进行如下设置#set envelope_from=yes#set use_from=yes#set from=root@itdhz.com#set realname="itdhz" FAQ 邮件发出去，但收不到；默认情况下mutt的发件人格式是用户名@主机名.主机域名，如`root@pr.net`，这种格式有可能被邮件服务器认为是垃圾邮件。可以通过修改发件人信息，来避免被误认为是垃圾邮件。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux Tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git 回退提交的错误]]></title>
    <url>%2F2017%2F09%2F27%2Fgit-reset%2F</url>
    <content type="text"><![CDATA[本地分支在本地分支上进行回退操作，回退的内容分三部分，commit信息、index file（暂存区域）和源代码； 回退commit, index file, 本地源码 123456# 回滚到哪次commit，根据commitidgit reset --hard &lt;commitid&gt;# 回滚到最近的几次（n）git reset --hard HEAD~&lt;n&gt;# 回滚到和远程dev分支一样git reset --hard origin/dev 回退commit, index file， 保留本地源码；此为git默认方式 1git reset --mixed &lt;commitid&gt; 回退commit信息，保留index file 和 本地源码 1git reset --soft &lt;commitid&gt; 远程分支 删除远程分支上的最后一次提交 12git revert HEADgit push origin master]]></content>
      <categories>
        <category>Version Management</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git 日常操作]]></title>
    <url>%2F2017%2F09%2F27%2Fgit-command%2F</url>
    <content type="text"><![CDATA[分支本地分支 查看本地分支 1git branch 删除本地分支 1git branch -d ~分支名 重命名本地分支 1git branch -m &lt;old_branch_name&gt; &lt;new_branch_name&gt; 查看分支最新的修改 1git branch -v 合并分支将B分支合并到A分支上 12git checkout &lt;想合并入的分支A&gt; git merge &lt;合并分支B&gt; 创建指定远程跟踪分支(origin/serverfix)的本地跟踪分支(serverfix) 1git checkout --track origin/serverfix 本地分支 关联 远程分支本地dev分支关联到远程dev分支 1git branch --set-upstream dev origin/dev 远程分支 查看远程分支 1git branch -r 删除远程分支 123 git push origin :&lt;branch_name&gt;或 git push origin --delete &lt;branch_name&gt; 显式获取远程引用的完整列表 1git ls-remote (remote) 更新本地远程分支 1git pull origin 获取远程分支的最新信息 1git remote show origin 删除本地远程跟踪分支 1git remote prune origin 获取本地没有的远程分支 1git fetch 本地分支和远程分支 查看远程分支和本地分支 1git branch -a 查看本地分支对应的远程分支 1git branch -vv 提交分支 提交本地分支A到远程分支B 1git push origin A:B 文件跟踪与取消跟踪取消跟踪1git update-index --assume-unchanged your_file_path 继续跟踪1git update-index --no-assume-unchanged your_file_path 子模块添加子模块项目当前未引入子模块，引入子模块： 1234git submodule add [url] [path]# 例如：# git submodule add git@git.aimoge.com:ncshop/ncshop-admin-foreign.git foreign 删除子模块项目当前存在一个要删除的子模块，目录是foreign，有 4 个步骤： 移出git管理：git rm --cached foreign 手动删除子模块所在目录：rm -rf foreign 编辑 .gitmodules 文件，将子模块的相关配置节点删除掉 编辑 .git/config 文件，将子模块的相关配置节点删除掉 初始化子模块当使用 git clone 下来的工程中带有 submodule 时，初始的时候，submodule 的内容并不会自动下载下来的，此时，要执行以下命令 1git submodule update --init --recursive 更新子模块1git submodule update 标签列出所有标签1git tag 推送标签1git push origin 标签名 删除本地标签1git tag -d 标签名 删除远程标签1git push origin :refs/tags/标签名 检索标签取指定tag标签代码，到新创建的分支上1git checkout -b branch_name tag_name 如果存在tag名和branch名相同，则1git checkout -b branch_name tags/tag_name 配置修改配置信息 修改git commit时的编辑器 1git config core.editor vim 修改不带任何参数的push为simple 1git config push.default simple 颜色 1git config color.ui auto 中文文件名乱码git 默认中文文件名是 \xxx\xxx 等八进制形式，是因为对 0x80 以上的字符进行 quote，执行以下命令： 1git config --global core.quotepath false 历史提交历史1234# git log 会按提交时间列出所有的更新， -p 选项展开显示每次提交的内容差异，用 -2 则仅显示最近的两次更新git log -p -2 # 仅显示简要的增改行数统计git log --stat 命令历史 查看命令历史 1git reflog 提交强制提交覆盖远程1git push -f origin 远程分支名 修改上一次提交的author及邮箱1git commit --amend --author='Redgo Hong &lt;redgo_hong@qq.com&gt;' 修改最近一次提交的commit注释1git commit --amend 提交时，指定时间1git commit --date="时间" 这里的时间格式与date -R相同；假如是第二天的时间,可以先通过date -d &quot;$(date -R) 1 day&quot; +&#39;%a, %d %b %Y %T %z&#39; 得出具体时间; 撤销提交撤销某次提交，不影响之前或之后的1git revert 提交ID]]></content>
      <categories>
        <category>Version Management</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssh 公密钥设置标准步骤]]></title>
    <url>%2F2017%2F09%2F26%2Fssh-setkey%2F</url>
    <content type="text"><![CDATA[标题： 功能介绍通过ssh-keygen命令来生成ssh公钥密钥，帮助我们可以免密进行ssh连接别的主机或者进行认证注册操作（比如github，这样后续一些需要权限的操作，可以不需要密码确认）； 应用：单向登录以免密登录A服务器为例； 第一步，执行以下命令，生成公密钥文件 1ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa_192.168.1.169 说明，-t参数是指定密钥类型，如果没有指定则默认生成用于SSH-2的RSA密钥；-P提供密语（我们希望是免密登录，所以置空）；-f参数指定密钥文件名（建议命名上采用id_rsa_&lt;对方的IP地址或HostName&gt;）； 第二步，配置如果文件名不是采用默认的id_rsa，都需要在~/.ssh/config文件中进行配置；12345Host 192.168.1.169 HostName 192.168.1.169 User root PubkeyAuthentication yes IdentityFile ~/.ssh/id_rsa_192.168.1.169 说明, Host：别名，默认是同HostName一致 HostName：服务器的IP地址 User：登录的用户名 PubkeyAuthentication：是否允许客户端通过public-key authentication来登陆 IdentityFile：密钥的路径 第三步，将id_rsa_192.168.1.169.pub文件中的内容追加到A服务器上的~/.ssh/authorized_keys文件中 先scp到A服务器的tmp目录下，再进行追加操作；12345// 本地服务器上执行 scpscp ~/.ssh/id_rsa_192.168.1.169.pub 192.168.1.169:/tmp// A 服务器执行追加操作cat 192.168.1.169:/tmp/id_rsa_192.168.1.169.pub &gt;&gt; ~/.ssh/authorized_keys 第四步，验证1ssh root@192.168.1.169 登录成功！ 应用：认证以认证github为例； 第一步，执行以下命令，生成公密钥文件 1ssh-keygen -t rsa -P '' -C "your_email@example.com" -f ~/.ssh/id_rsa_github 说明，-t参数是指定密钥类型，如果没有指定则默认生成用于SSH-2的RSA密钥；-P提供密语（我们希望是免密登录，所以置空）；-f参数指定密钥文件名（建议命名上采用id_rsa_&lt;平台名&gt;）；-C参数 这时候会生成两个文件，id_rsa_github和id_rsa_github.pub； 第二步，配置如果文件名不是采用默认的id_rsa，都需要在~/.ssh/config文件中进行配置；12345Host github.com HostName github.com User git PubkeyAuthentication yes IdentityFile ~/.ssh/id_rsa_github 说明, Host：别名，默认是同HostName一致 HostName：平台的域名 User：登录的用户名，认证一般是git PubkeyAuthentication：是否允许客户端通过public-key authentication来登陆 IdentityFile：密钥的路径 第三步，将id_rsa_coding.pub中的文件内容，放到github平台上的SSH and GPG keys上 用cat命令直接输出文件内容，方便复制粘贴1cat ~/.ssh/id_rsa_github.pub 第四步，验证 1ssh -T git@github.com 说明，-T参数用于测试连接，并不真正登录；]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux Tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[练习 MongoDB 操作 —— 分片篇（五）]]></title>
    <url>%2F2017%2F09%2F25%2Fmongo-exer5%2F</url>
    <content type="text"><![CDATA[分片（sharding）是指将数据拆分，将其分散存在不同的机器上的过程。在关系型数据库中，当一个表太大（超过几亿行数据）时，我们也有分表的做法，和这里的分片是类似的概念。 术语 “片”：一个独立的MongoDB服务（即mongod服务进程，在开发测试环境中）或一个副本集（在生产环境中）。 “片键”：在路由服务器上设置分片时，需要从开启分片的集合中选取一个键，用该键作为数据存放在哪个片的依据。这个键就称为“片键”。对于选择哪个键作为片键？有个原则就是，片键应该有较多变化的值。 “配置服务器”：一个mongod服务进程，但这个数据库服务仅仅是为mongos路由服务提供配置信息存储的位置！启动mongos服务时，需要提供一个mongod服务器，以便路由服务访问或存储相关的配置信息。配置信息主要包括：分片与数据的对应关系！（配置服务器必须开启1个或则3个，开启2个则会报错（ “mongos”服务：MongoDB自带的路由服务进程，它路由所有的客户端请求，并将各个片的结果进行汇聚返回。这个服务进程本身不会存储任何数据或配置信息（有时会缓存配置服务器的相关配置信息）。 示例环境搭建启动两台mongodb服务器（27017和27018），一台配置服务器（27019）和一个路由服务（27020）； 注意： Mongodb3.4版本开始要求配置服务器要是复制集 123456789// 启动分片服务器，注意要加 --shardsvr./bin/mongod --dbpath shard1/data --logpath shard1/log/0924.log --fork --port 27017 --shardsvr./bin/mongod --dbpath shard2/data --logpath shard2/log/0924.log --fork --port 27018 --shardsvr// 配置服务器， 注意要加 --configsvr./bin/mongod --dbpath shard_router_server/data --logpath shard_router_server/log/0924.log --fork --port 27019 --configsvr --replSet config// 启动路由服务./bin/mongos --port 27020 --configdb config/localhost:27019 --logpath shard_router/log/0924.log --fork 进入路由服务，注册参与分片的节点 123mongos&gt; use adminmongos&gt; db.runCommand(&#123;"addshard" : "192.168.1.168:27017"&#125;);mongos&gt; db.runCommand(&#123;"addshard" : "192.168.1.168:27018"&#125;); 查看分片信息1mongos&gt; sh.status() 查看分片成员1234mongos&gt; db.runCommand(&#123;listshards: 1&#125;)// 或切换到 config 数据库，查看 shards 集合mongos&gt; use configmongos&gt; db.shards.find() 删除分片1mongos&gt; db.runCommand(&#123;"removeshard":"192.168.1.168:27017"&#125;) 此时后台会自动开启分片数据库的数据迁移；然后需要手动迁移未开启分片数据库的数据； 手动迁移命令，可以参考1mongos&gt; db.runCommand(&#123; movePrimary: "school", to: "192.168.1.168:27018" &#125;) 开启分片如果对应的数据库没有开启分片功能，则通过路由服务新增数据，是会报错的； 笔者开启school数据库的分片功能；123mongos&gt; db.runCommand(&#123;"enablesharding" : "school"&#125;);// 或mongos&gt; sh.enableSharding("school") 那么，如果 school 数据库下的集合没有开启分片功能，那么所有对school数据库下集合的操作都会在school数据库所在的分片上执行； 查看已经在片系统上的数据库列表：1mongos&gt; db.databases.find() 集合开启分片school数据库下的demo集合开启分片功能；1mongos&gt; sh.shardCollection("school.demo", &#123;"name":1&#125;) 开启分片的集合，是以 chunks（块） 为单位；块（chunk）是由多个doc组成的一个分组，在某个索引字段（片键）上是连续的，每个chunk的片键是有一定范围的。块的默认大小是 64 MB。有些chunk会非常大，包含的doc数量非常多，但是，在MongoDB看来，仍然是一个chunk，和没有任何doc的空chunk没有区别。均衡分发保证每个shard的chunk数量是大致相同的。因此，片键的选择直接影响分片的好坏。 测试分片效果因为chunk默认大小是 64 MB（取值范围是 1 MB 到 1024 MB）， 不方便查看效果（chunk数目差异较大时的拆分与平衡）； 修改chunk块的大小：12mongos&gt; use configmongos&gt; db.settings.save( &#123; _id:"chunksize", value: 1 &#125; ) 此时批量向school数据库下的 demo插入 60W 条数据12mongos&gt; use schoolmongos&gt; for(i=0;i&lt;600000;i++)&#123; db.demo.insert(&#123;"uid":i,"name":"zhanjindong"+i,"age":13,"data":new Date()&#125;); &#125; 通过命令sh.status()，可以实时查看各片上的chunk数目多少； 附录参考阅读 悦光阴的博客 DrifterJ’s Stash的博客]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>MongoDB3.x</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[练习 MongoDB 操作 —— 复制集篇（四）]]></title>
    <url>%2F2017%2F09%2F24%2Fmongo-exer4%2F</url>
    <content type="text"><![CDATA[复制集（Replication Set），也叫副本集；作用是把一份数据同时保存在多台服务器上，保证数据的安全，不发生丢失； 示例启动服务器通过指定 replSet选项启动三台Mongo服务器，端口号是 27017， 27018， 27019；指定加入的复制集名称为 demo； 12345./bin/mongod --dbpath master/data --logpath master/log/0923.log --port 27017 --fork --replSet demo./bin/mongod --dbpath slave1/data --logpath slave1/log/0923.log --port 27018 --fork --replSet demo./bin/mongod --dbpath slave2/data --logpath slave2/log/0923.log --port 27019 --fork --replSet demo 此时，在三台服务器上分别键入rs.status()命令，均报“未初始化”的错误； 启动服务器的另外一种方式是通过配置文件启动；举个例子，这里的27018以配置文件启动； 配置文件如下所示：123456789101112dbpath=/home/mongodb/slave1/data # 数据存放目录logpath=/home/mongodb/slave1/log/0923.log # 日志存放路径pidfilepath=/home/mongodb/slave1/slave1.pid # 进程文件，方便停止mongodbdirectoryperdb=false # 为每一个数据库按照数据库名建立文件夹存放logappend=true # 以追加的方式记录日志replSet=demo # Replication Set 的名称#bind_ip=127.0.0.1 # 限制只允许某一特定IP来访问，逗号隔开port=27018 # 进程所使用的端口号，默认为27017oplogSize=10000 # mongodb操作日志文件的最大大小。单位为Mb，默认为硬盘剩余空间的5%fork=true # 以后台方式运行进程 noprealloc=false # 不预先分配存储 smallfiles=false # 当提示空间不够时添加此参数 初始化登入任意一台机器的 MongoDB 执行，因为是全新的复制集，所以可以任意进入一台执行；要是一台有数据，则需要在有数据上执行；要多台有数据则不能初始化。 笔者选择在27017这台MongoDB服务器进行初始化 123456789101112131415161718rs.initiate(&#123; _id:'demo', // 复制集名称 members: // 复制集服务器列表 [ &#123; _id:0, // 服务器的唯一 ID host:'192.168.1.168:27017' // 服务器的地址 &#125;, &#123; _id:1, host:'192.168.1.168:27018' &#125;, &#123; _id:2, host:'192.168.1.168:27019' &#125;, ]&#125;); 这样，三台服务器都加入了demo复制集；此时主节点27017可以进行读写，从节点27018和27019不可以读写；所有的写操作只能在主节点上进行； 那如何才能在从节点27018上读数据呢？在27018上键入rs.slaveOk()， 这样就可以进行读操作； 注：可以通过rs.status()查看复制集状态；通过rs.config()查看复制集的配置信息；通过db.isMaster()查看是否是主节点信息； 添加从节点先启动想要添加的从节点服务器，笔者是本地的27020服务器，同时指定相要加入的复制集名称； 1./bin/mongod --dbpath slave3/data --logpath slave3/log/0923.log --port 27020 --fork --replSet demo 主节点27017配置添加： 1rs.add('192.168.1.168:27020'); 此时，通过键入rs.status()可以看到members成员有四位，包括这台新的27020从节点服务器； 如果想要移除27020从节点服务器，即可成功从demon复制集中移除该服务器； 1rs.remove('192.168.1.168:27020'); 模拟主服务器故障目前环境： 27017: Primary主服务器 27018: SECONDARY从服务器 27019: SECONDARY从服务器 在系统命令行上，手动drop掉主服务器 1234lsof -i:27017 | sed '1d' | while read linedo echo $line | awk '&#123;print $2&#125;' | xargs kill -9done 或者在主服务器上执行下面的语句1db.shutdownServer() 此时，在通过rs.status()查看环境 27017: 离线（not reachable/healthy） 27018: SECONDARY从服务器 27019: Primary主服务器 这里，为什么在主服务器27017服务器挂了之后，会选择27019做新的主服务器呢，这是由MongoDB服务器内部的多数投票算法，即每台服务器会为secondary从节点服务器进行投票，票数多的从节点服务器会成为新的Primary服务器； 笔者这里很幸运，两台从节点服务器27018和27019都选择了27019作为新的从节点服务器；另外一种可能是 27018和27019各得一票，这样会导致无法选举出新Primary服务器; 所以建议复制集的服务器数目为奇数，如果碰巧是偶数，可以添加一台仲裁节点服务器； 添加仲裁节点仲裁节点是一种特殊的节点，它本身并不存储数据，主要的作用是决定哪一个从节点在主节点挂掉之后提升为主节点，所以客户端不需要连接此节点。 仲裁节点服务器启动， 1./bin/mongod --dbpath arbiter/data --logpath arbiter/log/0923.log --port 27021 --fork --replSet demo 主服务器的配置上添加仲裁节点信息： 1demo:PRIMARY&gt; rs.addArb('192.168.1.168:27021') 手动设置Primay服务器 将27017服务器重启； 此时，在通过rs.status()查看环境 27017: SECONDARY从服务器 27018: SECONDARY从服务器 27019: Primary主服务器 27021: Arbiter仲裁服务器 如何能将当前的服务器从27019切换回27017服务器呢？ 通过修改priority的值来实现（默认的优先级是1（0-100），priority的值设的越大，就优先成为主）； 在27019主节点上执行123Primary &gt; config=rs.conf()Primary &gt; config.members[0].priority = 3Primary &gt; rs.reconfig(config) 注意：第2步members大括号里面的成员和_id是没有关系的，而是rs.conf查出来节点的数值的顺序； 原理主节点的操作记录成为oplog（operation log）。 oplog存储在一个系统数据库local的集合oplog.rs中，这个集合的每个文档都代表主节点上执行的一个操作。我们重新向主数据库服务器中插入一条数据，然后查看这个集合可以看到： 12use localdb.getCollection('oplog.rs').find(&#123;&#125;) 文档中的字段含义： ts：8字节的时间戳，由4字节 unix timestamp + 4字节自增计数表示 h： 未知 v： 未知 op：操作类型，i表示insert；u表示update；d表示delete；c表示db cmd；n表示no op, 空操作，其会定期执行以确保时效性； ns：操作所在的namespace o：操作所对应的document,即当前操作的内容（比如更新操作时要更新的的字段和值） 从服务器会定期从主服务器中获取oplog记录，然后在本机上执行！ 对于存储oplog的集合，MongoDB采用的是固定集合，也就是说随着操作过多，新的操作会覆盖旧的操作！这样做也是有道理的，不然，这个集合占用的空间就无法估算了！我们在启动服务时，可以通过选项--oplogSize来指定这个集合的大小，单位是MB，在Windows平台下，默认MongoDB会使用数据库安装分区可用空间的5%作为这个集合的大小！ 附录属性说明 ‘ 成为Primary 对客户端可见 参与同步 延迟同步 复制数据 Primary √ √ √ √ Secondary √ √ √ Hidden √ √ Delayed √ √ √ √ Arbiters √ Non-Voting √ √ √ 参考阅读 DrifterJ’s Stash的博客]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>MongoDB3.x</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[练习 MongoDB 操作 —— 备份篇（三）]]></title>
    <url>%2F2017%2F09%2F23%2Fmongo-exer3%2F</url>
    <content type="text"><![CDATA[导入与导入导入与导出是针对集合，对集合上的文档数据经过”查询条件”后导出； 导出MongoDB的导出是利用mongoexport命令；同时列举常用的参数： -h：数据库宿主机的IP -u：数据库用户名 -p：数据库密码 -d：数据库名字 -c：集合的名字 -f：导出的列名 -q：导出数据的过滤条件 -o：导出文件的目录及文件名（/xx/xx/xx.json） --type：json 或 csv（默认是 json） 示例： 导出本地Mongodb服务器上school数据库grade_1_5集合上的数据（必须指定集合名）；默认导出的文件是json格式； 1mongoexport -d school -c grade_1_5 -o /tmp/school.json 导出本地Mongodb服务器上school数据库grade_1_5集合上的数据（必须指定集合名），csv格式的文件(csv文件必须指定导出哪些列) 1mongoexport -d school -c grade_1_5 -o /tmp/school.csv --type=csv -f name,sex,age mongoexport不能导出文档中的数组信息；导出 csv 文件的好处在于可以导入mysql； 导出本地Mongodb服务器上school数据库grade_1_5集合上的数据（必须指定集合名）；只导出 sex 为 1 的文档； 1mongoexport -d school -c grade_1_5 -o /tmp/school.json -q "&#123;"sex": 1&#125;" 导入MongoDB的导出是利用mongoimport命令；同时列举常用的参数： --host：数据库宿主机的IP --port：端口号 -d： 待导入的数据库 -c： 待导入的表 --type： json 或 csv（默认是 json） --file： ./xx/xx.json 示例： 把之前导出的school.csv文件，导入到本地Mongodb中school数据库的grade_1_6集合 1mongoimport -d school -c grade_1_6 --file /tmp/school.json 备份与恢复备份与恢复主要面向数据库，也可以对集合进行这类操作； 备份MongoDB的备份是利用mongodump命令；同时列举常用的参数： -h：MongDB所在服务器地址，例如：127.0.0.1，当然也可以指定端口号：127.0.0.1:27017 -d：需要备份的数据库实例，例如：school、test -c：需要备份的集合名 -o：备份的数据存放位置，例如：/home/mongodb/dump 示例： 备份本地MongoDb的school数据库，数据存放在/home/mongodb/dump 1mongodump -d school -o /home/mongodb/dump 备份本地MongoDb的school数据库中的grade_1_5集合，数据存放在/home/mongodb/dump 1mongodump -d school -c grade_1_5 -o /home/mongodb/dump 恢复MongoDB的恢复是利用mongorestore命令；同时列举常用的参数： -h：MongDB所在服务器地址，例如：127.0.0.1，当然也可以指定端口号：127.0.0.1:27017 -d：需要备份的数据库实例，例如：school、test -c：需要备份的集合名 --drop : 恢复的时候，先删除当前数据，然后恢复备份的数据。就是说，恢复后，备份后添加修改的数据都会被删除，慎用! 示例： 恢复本地MongoDb的school数据库中的grade_1_5集合 1./bin/mongorestore -d school -c grade_1_5 /home/mongodb/dump/school/grade_1_5.bson]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>MongoDB3.x</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[练习 MongoDB 操作 —— 索引篇（二）]]></title>
    <url>%2F2017%2F09%2F20%2Fmongo-exer2%2F</url>
    <content type="text"><![CDATA[本文围绕索引、游标两部分进行探索，对MongoDB数据库的索引部分有一个大概的了解； 索引索引通常能够极大的提高查询的效率，如果没有索引，MongoDB在读取数据时必须扫描集合中的每个文件并选取那些符合查询条件的记录。这种扫描全集合的查询效率是非常低的，特别在处理大量的数据时，查询可以要花费几十秒甚至几分钟，这对网站的性能是非常致命的。 索引是特殊的数据结构，索引存储在一个易于遍历读取的数据集合中，索引是对数据库表中一列或多列的值进行排序的一种结构。索引，从创建的形式上可以分为普通索引、复合索引、数组索引、子文档索引； 应该了解的索引限制， 开销：每个索引占据一定的存储空间，在进行插入，更新和删除操作时也需要对索引进行操作。所以，如果你很少对集合进行读取操作，建议不使用索引； 内存（RAM）使用：由于索引是存储在内存中,你应该确保该索引的大小不超过内存的限制。如果索引的大小大于内存的限制，MongoDB会删除一些索引，这将导致性能下降。 最大范围： （1）集合中索引不能超过 64 个； （2）索引名的长度不能超过 125 个字符； （3）一个复合索引最多可以有 31 个字段 索引不能被以下的查询使用；可以调用explain()方法查看是否使用索引； （1）正则表达式及非操作符，如 $nin， $not， 等 （2）算术运算符，如 $mod 等 （3）$where 子句 操作创建索引为集合grade_1_4根据性别和年龄创建复合索引： 1db.getCollection('grade_1_4').ensureIndex(&#123;"sex": 1, "age": 1&#125;) 会得到结果： 123456789&#123; "v" : 2, // 索引的版本号。默认的索引版本取决于mongod创建索引时运行的版本 "key" : &#123; "sex" : 1, "age" : 1 &#125;, "name" : "sex_1_age_1", "ns" : "school.grade_1_4"&#125; 说明：基于sex和age的查询将会用到该复合索引，或者是基于sex的查询也会用到该索引，但是只是基于age的查询将不会用到该复合索引。因此可以说，如果想用到复合索引，必须在查询条件中包含复合索引中的前N个索引列。然而如果查询条件中的键值顺序和复合索引中的创建顺序不一致的话，MongoDB可以智能的帮助我们调整该顺序，以便使复合索引可以为查询所用 如果分别为性别和年龄创建索引： 12db.getCollection('grade_1_4').ensureIndex(&#123;"sex": 1&#125;)db.getCollection('grade_1_4').ensureIndex(&#123;"age": 1&#125;) 会得到这样的结果： 12345678910111213141516&#123; "v" : 2, "key" : &#123; "sex" : 1 &#125;, "name" : "sex_1", "ns" : "school.grade_1_4"&#125;,&#123; "v" : 2, "key" : &#123; "age" : 1 &#125;, "name" : "age_1", "ns" : "school.grade_1_4"&#125; 查看索引查看集合grade_1_4已经创建的索引规则： 1db.getCollection('grade_1_4').getIndexes() 查看集合grade_1_4索引占用内存空间的大小，单位是字节： 1db.getCollection('grade_1_4').totalIndexSize() 删除索引删除集合grade_1_4中name为sex_1的索引规则： 1db.getCollection('grade_1_4').dropIndex(&#123;"sex": 1&#125;) 唯一索引创建唯一索引与普通索引的区别在于，多一个可选参数 unique；举个例子，根据姓名创建唯一索引：1db.getCollection('grade_1_4').ensureIndex(&#123;"name":1&#125;, &#123;"unique":true&#125;) 创建唯一索引能够保证每条记录的name字段值是不重复的； 当一个文档以唯一索引的方式保存到集合中去的时候，任何缺失的索引字段都会以null值代替，因此，不能在唯一索引上同时插入两条缺省的记录。 假设集合已经存在一些记录，在些基础上创建唯一索引；此时，对这些已经存在的记录，如果索引项值是存在重复的，则创建索引时会报错；如果一定要在这样的键上创建唯一索引，那么系统将保存第一条记录，剩下的记录会被删除，结合dropDups参数使用（此参数只能在mongodb 3.0版本之前使用）： 1db.getCollection('grade_1_4').ensureIndex(&#123;"name":1&#125;, &#123;unique:true, dropDups: true&#125;) 稀疏索引稀疏索引的创建和完全索引的创建没有什么不同。使用稀疏索引进行查询的时候，某些由于缺失了字段的文档记录可能不会被返回，这是由于稀疏索引子返回被索引了的字段。 示例：12345678910111213141516&gt; db.people.ensureIndex(&#123;title:1&#125;,&#123;sparse:true&#125;) //在title字段上建立稀疏索引&gt; db.people.save(&#123;name:"Jim"&#125;)&gt; db.people.save(&#123;name:"yang",title:"prince"&#125;)&gt; db.people.find();&#123; "_id" : ObjectId("4e244dc5cac1e3490b9033d7"), "name" : "Jim" &#125;&#123; "_id" : ObjectId("4e244debcac1e3490b9033d8"), "name" : "yang", "title" : "prince" &#125;&gt; db.people.find().sort(&#123;title:1&#125;)//自有包含有索引字段的记录才被返回&#123; "_id" : ObjectId("4e244debcac1e3490b9033d8"), "name" : "yang", "title" : "prince" &#125;&gt; db.people.dropIndex(&#123;title:1&#125;)//删除稀疏索引之后，所有的记录均显示&#123; "nIndexesWas" : 2, "ok" : 1 &#125;&gt; db.people.find().sort(&#123;title:1&#125;)&#123; "_id" : ObjectId("4e244dc5cac1e3490b9033d7"), "name" : "Jim" &#125;&#123; "_id" : ObjectId("4e244debcac1e3490b9033d8"), "name" : "yang", "title" : "prince" &#125; 性能示例创建三十万条数据 1234567for (var i = 1; i &lt;= 300000; i++) &#123; db.getCollection('grade_1_5').insert(&#123; "name": "zhangsan" + i, "sex": Math.round(Math.random() * 10) % 2, "age": Math.round(Math.random() * 6) + 3 &#125;);&#125; 根据姓名查一些特定的人 123456789db.getCollection('grade_1_5').find( &#123; $or: [&#123;"name":"zhangsan10000"&#125;,&#123;"name":"zhangsan14000"&#125;,&#123;"name":"zhangsan9000"&#125;,&#123;"name":"zhangsan23000"&#125;,&#123;"name":"zhangsan24050"&#125;, &#123;"name":"zhangsan12000"&#125;,&#123;"name":"zhangsan14300"&#125;,&#123;"name":"zhangsan9300"&#125;,&#123;"name":"zhangsan23300"&#125;,&#123;"name":"zhangsan24350"&#125;, &#123;"name":"zhangsan11100"&#125;,&#123;"name":"zhangsan15200"&#125;,&#123;"name":"zhangsan8100"&#125;,&#123;"name":"zhangsan22100"&#125;,&#123;"name":"zhangsan26150"&#125;, &#123;"name":"zhangsan10200"&#125;,&#123;"name":"zhangsan14020"&#125;,&#123;"name":"zhangsan9020"&#125;,&#123;"name":"zhangsan23020"&#125;,&#123;"name":"zhangsan24070"&#125;, &#123;"name":"zhangsan10300"&#125;,&#123;"name":"zhangsan14030"&#125;,&#123;"name":"zhangsan9030"&#125;,&#123;"name":"zhangsan23030"&#125;,&#123;"name":"zhangsan24080"&#125;] &#125;) 对姓名建立索引，会占用5873664字节 1db.getCollection('grade_1_5').ensureIndex(&#123;"name": 1&#125;) 对于上面的命令，通过调整顺序，观察时间，对性能有一些大概的了解； 行为 创建-查询-建索引 创建-建索引-查询 建索引-创建-查询 创建时间 150.957s 150.957s 159.967s 查询时间 1.024s 0.005s 0.005s 建立索引时间 0.527s 0.527s 0.009s 游标直接对一个集合调用find()方法时，我们会发现，如果查询结果超过二十条，只会返回二十条的结果，这是因为Mongodb会自动递归find()返回的是游标。 1var cursor = db.getCollection('grade_1_4').find(&#123;&#125;); 执行上述命令时，shell并不会真正地访问数据库，而是等待开始要求获得结果的时候才向数据库发送查询请求。 此时可以对这个游标进行各种设置，然后调用游标的hashNext()或next()方法，这样就会真正访问数据库，这是一个懒加载的过程，如下 123456var cursor = db.getCollection('grade_1_4').find(&#123;&#125;);while(cursor.hasNext())&#123; var doc = cursor.next(); // do stuff with doc &#125;; 可以基于游标，进行limit、skip、sort操作，一般应用于分页场景； limit：限制游标返回的数量，指定了上限； skip ：忽略前面的部分文档，如果文档总数量小于忽略的数量，则返回空集合； sort ：对得到的子集合进行排序，可以按照多个键进行正反排序； 上述三个命令可以进行链式操作； 附录以下是文章会用到的参考，及有意义的扩展阅读； DrifterJ’s Stash的博客 - 学习MongoDB–（4-3）：MongoDB查询(游标使用) MongoDB使用小结：一些不常见的经验分享]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>MongoDB3.x</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel 大将之 View 模块]]></title>
    <url>%2F2017%2F09%2F17%2Flaravel-view%2F</url>
    <content type="text"><![CDATA[本文是基于Laravel 5.4版本的View模块代码进行分析书写； 官方 API 地址 https://laravel.com/api/5.4/Illuminate/View.html 文件结构View模块的文件格局及功能如下图所示： 视图化呈现时的大概流程： 通过view()方法的调用，开始视图的呈现； 首先，查找视图文件； （1）依次遍历路径，如果文件名带命名空间（也就是::之前的部分），则采用命名空间对应注册的路径数组，否则采用全局路径数组（在Illuminate\View\FileViewFinder类中的paths变量）； （2）结合当前路径，文件名，后缀名（默认顺序是blade.php、php、css），判断文件是否存在； （3）如果文件不存在，报异常：对应的view文件不存在；如果文件存在，则根据后缀名调用对应的引擎进行解析； 如果是css后缀，采用file引擎，核心调用方法是file_get_contents; 如果是php后缀，采用php引擎，核心调用方法是 123ob_start();include $__path;ob_get_clean(); 如果是blade.php后缀，采用blade引擎； 这个引擎会主动作缓存处理，如果缓存文件未过期，则直接调用缓存文件，否则重新编译，并通过sha1生成缓存文件（位于storage/framework/views目录下）； Blade 引擎编译Blade引擎对文件的编译，是通过大量的正则匹配和替换实现的； 12345678910111213141516protected $compilers = [ 'Comments', // 注释部分 'Extensions', // 扩展部分 'Statements', // 语句块 （@ 开头的指令） 'Echos', // 输出];protected function parseToken($token) &#123; list($id, $content) = $token; if ($id == T_INLINE_HTML) &#123; foreach ($this-&gt;compilers as $type) &#123; $content = $this-&gt;&#123;"compile&#123;$type&#125;"&#125;($content); &#125; &#125;&#125; 在解析的过程中，Blade会先使用token_get_all函数获取视图文件中的被PHP解释器认为是HTML（T_INLINE_HTML）的部分，然后依次进行Comments、Extensions、Statements 和 Echos部分的正则替换； 注释部分核心代码如下，将注释符号“{{-- --}}”包裹的代码替换为空字符串；1preg_replace("/&#123;&#123;--(.*?)--&#125;&#125;/s", '', $value); 扩展部分通过extend方法向BladeCompiler添加自定义处理的回调函数，对模板内容进行自定义的文本匹配替换； 核心代码在Illuminate\View\BladeCompiler文件中，如下：12345678910// 自定义的文本替换扩展 数组protected $extensions = [];protected function compileExtensions($value) &#123; foreach ($this-&gt;extensions as $compiler) &#123; $value = call_user_func($compiler, $value, $this); &#125; return $value;&#125; 指令替换这部分就是将类似@if这种框架自带的指令和通过directive方法注册的指令进行文本替换； 框架提供的指令有以下十部分： View\Compilers\Concerns\CompilesAuthorizations: 权限检查指令包括：@can、@cannot、@elsecan、@elsecannot、@endcan、@endcannot Concerns\CompilesComponents：与组件、插槽相关指令包括：@component、@endcomponent、@slot、@endslot Concerns\CompilesConditionals：与判断语句相关指令包括：@if、@unless、@else、@elseif、@endif、@endunless、@isset、@endisset、@hassection Concerns\CompilesIncludes：嵌入文件指令包括：@each、@include、@includeif、@includewhen Concerns\CompilesInjections：服务注入指令包括：@inject Concerns\CompilesLayouts：和布局相关指令包括：@extends、@section、@parent、@yield、@show、@append、@overwrite、@stop、@endsection Concerns\CompilesLoops：与循环相关指令包括：@forelse、@empty、@endforelse、@endempty、@for、@foreach、@break、@continue、@endfor、@endforeach、@while、@endwhile Concerns\CompilesRawPhp：与原生PHP语句相关指令包括：@php、 @endphp、 @unset Concerns\CompilesStacks：和堆栈相关指令包括：@stack、@push、@endpush、@prepend、@endprepend Concerns\CompilesTranslations：与本地化翻译相关指令包括：@lang、@endlang、@choice Echo 替换echo输出是针对{!! !!}、{{ }}、{{{ }}}三种括号进行正则替换； {!! !!}输出未转义字符，用于输出原生带html标签的值； {{ }}正常输出，支持三目运算符替换； {{{ }}}输出转义字符，支持三目运算符替换； 三目运算符替换是指：{{ $a ?: "默认值" }} (或者 {{$a or "默认值"}}) 换成 {{ isset($a) ? $a : "默认值"}} 参考文章 Laravel 模板引擎（Blade）原理简析 Laravel 5.4 文档 前端 —— Blade模板]]></content>
      <categories>
        <category>Laravel</category>
      </categories>
      <tags>
        <tag>Laravel-5.4</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[练习 MongoDB 操作 —— 数据操作（一）]]></title>
    <url>%2F2017%2F09%2F14%2Fmongo-exer1%2F</url>
    <content type="text"><![CDATA[本文的目标是通过大量的示例，来更好的理解如果在Mongodb中进行数据操作； 初入客户端刚利用 mongod命令进入客户端环境，此时对数据库一无所知； 举目四望，想知道现在有哪些数据库，1show dbs; 因为是新装的mongodb环境，所以只看到了admin和local两个默认就存在的数据库；目光慢慢收回，那么当前是处于哪个数据库上呢？1db; 通过上述这个命令，不仅可以知道当前在哪个数据库上；现在切换到admin数据库上，转一圈；1use admin; 数据库这时候，笔者想要创建自己应用的数据库school, 用来存放一些班级学生信息；1use school; use命令：如果数据库不存在，则创建数据库，否则切换到指定数据库； 突然发现刚才敲命令，写错了，写成了use school1；这时候，希望删除school1这个数据库，就切换到该数据库下，再键入删除命令；12use school1;db.dropDatabase(); 集合Mongodb中的集合相当于Mysql中的表； 作为一名优秀的“校长”，能适应高信息化社会发展，笔者需要为学校下的各个年级、班级建立集合；创建集合可以是显式的，也可以是隐式的； 通过show tables，看到数据库下没有任何集合；笔者显式地创建“一年级一班的”集合；1db.createCollection("grade_1_1"); 再次通过show tables就可以看到列表中有grade_1_1这个集合； 当然，也可以隐式地创建，当为集合插入数据，集合不存在，这时候集合会自动创建；现在，不存在grade_1_2“一年级二班”这个集合，执行下面语句，为“一年级二班”加入一个学生；1db.grade_1_2.insert(&#123;"name": 'zhangsan', "age": '7', "sex": "0"&#125;); 通过show tables就可以看到grade_1_2这个集合了； 因为一些特殊原因，要解散一年级二班，那笔者这儿就不用继续维护grade_1_2集合， 1db.grade_1_2.drop(); 练习增查 清空上面的school数据库 1234use school;db.dropDatabase();use school;show tables; 创建一年级的3个班，并随机添加 10 名学生； 12345678910for(grade_index in (grade = ['grade_1_1', 'grade_1_2', 'grade_1_3'])) &#123; for (var i = 1; i &lt;= 10; i++) &#123; db[grade[grade_index]].insert(&#123; "name": "zhangsan" + i, "sex": Math.round(Math.random() * 10) % 2, "age": Math.round(Math.random() * 6) + 3, "hobby": [] &#125;); &#125;&#125; 查看一年级二班grade_1_2中的所有学生 1db.getCollection('grade_1_2').find(&#123;&#125;) 查看一年级二班grade_1_2中所有年龄是 4 岁的学生 1db.getCollection('grade_1_2').find(&#123;"age": 4&#125;) 查看一年级二班grade_1_2中所有年龄大于 4 岁的学生 1db.getCollection('grade_1_2').find(&#123;"age": &#123;$gt: 4&#125;&#125;) 查看一年级二班grade_1_2中所有年龄大于 4 岁并且小于 7 岁的学生 1db.getCollection('grade_1_2').find(&#123;"age": &#123;$gt: 4, $lt: 7&#125;&#125;) 查看一年级二班grade_1_2中所有年龄大于 4 岁并且性别值为0的学生 1db.getCollection('grade_1_2').find(&#123;"age": &#123;$gt: 4&#125;, "sex": 0&#125;) 查看一年级二班grade_1_2中所有年龄小于 4 岁并且大于 7 岁的学生 1db.getCollection('grade_1_2').find(&#123;$or: [&#123;"age": &#123;$lt: 4&#125;&#125;, &#123;"age": &#123;$gt: 6&#125;&#125;]&#125;) 查看一年级二班grade_1_2中所有年龄是 4 岁或 6 岁的学生 1db.getCollection('grade_1_2').find(&#123;"age": &#123;$in: [4, 6]&#125;&#125;) 查看一年级二班grade_1_2中所有姓名带zhangsan1的学生 1db.getCollection('grade_1_2').find(&#123;"name": &#123;$regex: "zhangsan1"&#125;&#125;) 查看一年级二班grade_1_2中所有姓名带zhangsan1和zhangsan2的学生 123db.getCollection('grade_1_2').find(&#123;"name": &#123; $in: [new RegExp(""zhangsan1"), new RegExp(""zhangsan2")]&#125;&#125;) 查看一年级二班grade_1_2中所有兴趣爱好有三项的学生 1db.getCollection('grade_1_2').find(&#123;"hobby": &#123;$size: 3&#125;&#125;) 查看一年级二班grade_1_2中所有兴趣爱好包括画画的学生 1db.getCollection('grade_1_2').find(&#123;"hobby": "drawing"&#125;) 查看一年级二班grade_1_2中所有兴趣爱好既包括画画又包括跳舞的学生 1db.getCollection('grade_1_2').find(&#123;"hobby": &#123;$all: ["drawing", "dance"]&#125;&#125;) 查看一年级二班grade_1_2中所有兴趣爱好有三项的学生的学生数目 1db.getCollection('grade_1_2').find(&#123;"hobby": &#123;$size: 3&#125;&#125;).count() 查看一年级二班的第二位学生 1db.getCollection('grade_1_2').find(&#123;&#125;).limit(1).skip(1) 查看一年级二班的学生，按年纪升序 1db.getCollection('grade_1_2').find(&#123;&#125;).sort(&#123;"age": 1&#125;) 查看一年级二班的学生，按年纪降序 1db.getCollection('grade_1_2').find(&#123;&#125;).sort(&#123;"age": -1&#125;) 查看一年级二班的学生，年龄值有哪些 1db.getCollection('grade_1_2').distinct('age') 查看一年级二班的学生，兴趣覆盖范围有哪些 1db.getCollection('grade_1_2').distinct('hobby') 查看一年级二班的学生，男生（sex为 0）年龄值有哪些 1db.getCollection('grade_1_2').distinct('age', &#123;"sex": 0&#125;) 练习删除 一年级二班grade_1_2， 删除所有 4 岁的学生 1db.getCollection('grade_1_2').remove(&#123;"age": 4&#125;) 一年级二班grade_1_2， 删除第一位 6 岁的学生 1db.getCollection('grade_1_2').remove(&#123;"age": 6&#125;, &#123;justOne: 1&#125;) 练习修改 一年级二班grade_1_2中，修改名为zhangsan7的学生，年龄为 8 岁，兴趣爱好为 跳舞和画画； 1db.getCollection('grade_1_2').update(&#123;"name": "zhangsan7"&#125;, &#123;$set: &#123;"age": 8, "hobby": ["dance", "drawing"]&#125;&#125;) 一年级二班grade_1_2中，追加zhangsan7`学生兴趣爱好唱歌； 1db.getCollection('grade_1_2').update(&#123;"name": "zhangsan7"&#125;, &#123;$push: &#123;"hobby": "sing"&#125;&#125;) 一年级二班grade_1_2中，追加zhangsan7`学生兴趣爱好吹牛和打篮球； 1db.getCollection('grade_1_2').update(&#123;"name": "zhangsan7"&#125;, &#123;$push: &#123;"hobby": &#123;$each: ["brag", "play_basketball"]&#125;&#125;&#125;) 一年级二班grade_1_2中，追加zhangsan7学生兴趣爱好唱歌和打篮球，要保证hobby数组不重复； 1db.getCollection('grade_1_2').update(&#123;"name": "zhangsan7"&#125;, &#123;$addToSet: &#123;"hobby": &#123;$each: ["sing1", "play_basketball"]&#125;&#125;&#125;) 新学年，给一年级二班所有学生的年龄都增加一岁 1db.getCollection('grade_1_2').update(&#123;&#125;, &#123;$inc: &#123;"age": 1&#125;&#125;, &#123;multi: true&#125;) 一年级二班grade_1_2中，删除zhangsan7学生的sex属性 1db.getCollection('grade_1_2').update(&#123;"name": "zhangsan7"&#125;, &#123;$unset: &#123;"sex": 1&#125;&#125;) 一年级二班grade_1_2中，删除zhangsan7学生的hobby数组中的头元素 1db.getCollection('grade_1_2').update(&#123;"name": "zhangsan7"&#125;, &#123;$pop: &#123;"hobby": -1&#125;&#125;) 一年级二班grade_1_2中，删除zhangsan7学生的hobby数组中的尾元素 1db.getCollection('grade_1_2').update(&#123;"name": "zhangsan7"&#125;, &#123;$pop: &#123;"hobby": 1&#125;&#125;) 一年级二班grade_1_2中，删除zhangsan7学生的hobby数组中的sing元素 1db.getCollection('grade_1_2').update(&#123;"name": "zhangsan7"&#125;, &#123;$pull: &#123;"hobby": "sing"&#125;&#125;) 练习分组新建一个集合grade_1_4，记录一年级四班在期中考试时的成绩；123456789101112for (var i = 1; i &lt;= 10; i++) &#123; db.grade_1_4.insert(&#123; "name": "zhangsan" + i, "sex": Math.round(Math.random() * 10) % 2, "age": Math.round(Math.random() * 6) + 3, "score": &#123; "chinese": 60 + Math.round(Math.random() * 40), "math": 60 + Math.round(Math.random() * 40), "english": 60 + Math.round(Math.random() * 40) &#125; &#125;);&#125; 统计每名学生在考试中的总分 12345678db.grade_1_4.group(&#123; key: &#123;"name": 1&#125;, cond: &#123;&#125;, reduce: function(curr, result) &#123; result.total += curr.score.chinese + curr.score.math + curr.score.english; &#125;, initial: &#123; total : 0 &#125;&#125;) 统计每名男生在考试中的总分 12345678db.grade_1_4.group(&#123; key: &#123;"name": 1&#125;, cond: &#123;"sex": 0&#125;, reduce: function(curr, result) &#123; result.total += curr.score.chinese + curr.score.math + curr.score.english; &#125;, initial: &#123; total : 0 &#125;&#125;) 统计每名男生在考试中的总分及平均分 123456789101112db.grade_1_4.group(&#123; key: &#123;"name": 1&#125;, cond: &#123;"sex": 0&#125;, reduce: function(curr, result) &#123; result.total += curr.score.chinese + curr.score.math + curr.score.english; &#125;, initial: &#123; total : 0 &#125;, finalize: function(item) &#123; item.avg = (item.total / 3).toFixed(2); return item; &#125;&#125;) 练习聚合 根据姓名分组， 并统计人数 123db.getCollection('grade_1_4').aggregate([ &#123;$group: &#123;_id: "$name", num: &#123;$sum: 1&#125;&#125;&#125;]) 根据姓名分组， 并统计人数，过滤人数大于 1 的学生 1234db.getCollection('grade_1_4').aggregate([ &#123;$group: &#123;_id: "$name", num: &#123;$sum: 1&#125;&#125;&#125;, &#123;$match: &#123;num: &#123;$gt: 1&#125;&#125;&#125;]) 统计每名学生在考试中的总分 123 db.getCollection('grade_1_4').aggregate([ &#123;$group: &#123;_id: "$name", score: &#123;$sum: &#123;$sum: ["$score.chinese", "$score.math", "$score.english"]&#125;&#125;&#125;&#125;]) 统计每名男生在考试中的总分 1234 db.getCollection('grade_1_4').aggregate([ &#123;$match: &#123;sex: 0&#125;&#125;, &#123;$group: &#123;_id: "$name", score: &#123;$sum: &#123;$sum: ["$score.chinese", "$score.math", "$score.english"]&#125;&#125;&#125;&#125;]) 统计每名男生在考试中的总分， 总分降序 12345 db.getCollection('grade_1_4').aggregate([ &#123;$match: &#123;sex: 0&#125;&#125;, &#123;$group: &#123;_id: "$name", score: &#123;$sum: &#123;$sum: ["$score.chinese", "$score.math", "$score.english"]&#125;&#125;&#125;&#125;, &#123;$sort: &#123;score: 1&#125;&#125;]) 练习权限创建用户 要让权限生效，需要mongo服务器启动时添加--auth选项； 创建用户school_admin，只能对school数据库进行读写操作； 1234567use school;db.createUser(&#123; user: "school_admin", pwd: "school_admin", roles: [&#123;role: "readWrite", db: "school"&#125;]&#125;) 关于第三个参数角色，看下表： 角色名 描述 Read 允许用户读取指定数据库 readWrite 允许用户读写指定数据库 dbAdmin 允许用户在指定数据库中执行管理函数，如索引创建、删除，查看统计或访问system.profile userAdmin 允许用户向system.users集合写入，可以找指定数据库里创建、删除和管理用户 clusterAdmin 只在admin数据库中可用，赋予用户所有分片和复制集相关函数的管理权限 readAnyDatabase 只在admin数据库中可用，赋予用户所有数据库的读权限 readWriteAnyDatabase 只在admin数据库中可用，赋予用户所有数据库的读写权限 userAdminAnyDatabase 只在admin数据库中可用，赋予用户所有数据库的userAdmin权限 dbAdminAnyDatabase 只在admin数据库中可用，赋予用户所有数据库的dbAdmin权限 root 只在admin数据库中可用。超级账号，超级权限 验证用户如果未通过验证，进行查询， 会得到如下的提示：123456Error: error: &#123; "ok" : 0, "errmsg" : "not authorized on school to execute command &#123; find: \"grade_1_2\", filter: &#123;&#125; &#125;", "code" : 13, "codeName" : "Unauthorized"&#125; 如果执行验证代码：注意，要在注册时所在的数据库中验证 123use school;db.auth('用户名', '密码') 查看所有用户1db.getUsers() 删除用户先移到用户注册的数据库，然后移除指定用户 school_admin1db.dropUser('school_admin') 关于用户的注册位置，笔者的理解是在admin下创建其他数据库的管理者，再由这些管理者在对应的数据库下创建“可读”或“可写”的用户；]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>MongoDB3.x</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel 大将之 服务容器 模块]]></title>
    <url>%2F2017%2F08%2F31%2Flaravel-container%2F</url>
    <content type="text"><![CDATA[简介官方 API 地址 https://laravel.com/api/5.4/Illuminate/Container/Container.html 服务容器是一个用于管理类依赖和执行依赖注入的强大工具。是整个框架的核心； 几乎所有的服务容器绑定都是在服务提供者中完成。 框架调用分析在框架直接生成服务容器的只有一处，在bootstrap/app.php，通过require引用会返回服务容器实例。通过require引用有两处，一处是public/index.php，服务器访问的入口；另一处是tests/CreatesApplication.php，是单元测试的入口； 如果想在项目各处中调用，可以调用$app = Illuminate\Container\Container::getInstance()或者全局帮助函数app()获取服务容器实例（也就是Illuminate\Foundation/Application实例）； Illuminate\Foundation/Application是对Illuminate\Container\Container的又一层封装； Application初始化那么实例化Illuminate\Foundation/Application时，做了什么呢？ 第一步，设置应用的根目录，并同时注册核心目录到服务容器中；核心的目录有以下 path：目录app的位置 path.base：项目根目录的位置 path.lang：目录resources/lang的位置 path.config：目录config的位置 path.public：目录public的位置 path.storage：目录storage的位置 path.database：目录database的位置 path.resources：目录resources的位置 path.bootstrap：目录bootstrap的位置 第二步，将当前Illuminate\Foundation/Application实例保存到$instance类变量，并同时绑定到服务容器作单例绑定，绑定名为app或Container::class； 第三步，顺序分别执行注册Illuminate\Events\EventServiceProvider、Illuminate\Log\LogServiceProvider和Illuminate\Routing\RoutingServiceProvider三个服务提供者； 注册服务提供者的顺序如下： 如果类变量$serviceProviders已经存在该服务提供者并且不需要强制重新注册，则返回服务提供者实例$provider； 未注册过当前服务提供者，则继续执行以下； 如果存在register方法，执行服务提供者的register方法； 将当前服务提供者$provider实例保存到类变量$serviceProviders数组中，同时标记类变量$loadedProviders[get_class($provider)]的值为true； 判断类变量$booted是否为true，如果是true，则执行服务提供者的boot方法；（类变量$booted应该是标志是否所有服务提供者均注册，框架是否启动） 第四步，注册核心类别名；比如\Illuminate\Foundation\Application::class、\Illuminate\Contracts\Container\Container::class起别名为app； 单元测试Application的bootstrap启动分析启动代码很简洁，1234567public function createApplication() &#123; // require 初始化分析上面已经介绍了 $app = require __DIR__.'/../bootstrap/app.php'; // 生成`Illuminate\Foundation\Console\Kernel`实例，执行bootstrap方法，完成启动 $app-&gt;make(Kernel::class)-&gt;bootstrap(); return $app;&#125; 构造函数主要干了一件事，注册一个booted完成后的回调函数，函数执行的内容为“注册 Schedule实例到服务提供者，同时加载用户定义的Schedule任务清单”； bootstrap方法的执行内容如下： 加载Illuminate/Foundation/Console/Kernel中$bootstrappers变量数组中的类，执行它们的bootstrap方法； 12345678910111213141516protected $bootstrappers = [ // 加载 .env 文件 \Illuminate\Foundation\Bootstrap\LoadEnvironmentVariables::class, // 加载 config 目录下的配置文件 \Illuminate\Foundation\Bootstrap\LoadConfiguration::class, // 自定义错误报告，错误处理方法及呈现 \Illuminate\Foundation\Bootstrap\HandleExceptions::class, // 为 config/app.php 中的 aliases 数组注册类别名 \Illuminate\Foundation\Bootstrap\RegisterFacades::class, // 在服务容器中单例绑定一个 request 对象，控制台命令会用到 \Illuminate\Foundation\Bootstrap\SetRequestForConsole::class, // 注册 config\app.php 中的 providers 服务提供者 \Illuminate\Foundation\Bootstrap\RegisterProviders::class, // 项目启动，执行每个 ServiceProvider 的 boot 方法， \Illuminate\Foundation\Bootstrap\BootProviders::class,]; 加载延迟的服务提供者； Http访问Application的bootstrap启动分析启动入口文件在public\index.php123456789101112131415$app = require_once __DIR__.'/../bootstrap/app.php';// 实例化 Illuminate/Foundation/Http/Kernel 对象$kernel = $app-&gt;make(Illuminate\Contracts\Http\Kernel::class);// 中间件处理、业务逻辑处理$response = $kernel-&gt;handle( // 根据 Symfony 的 request 对象封装出 Illuminate\Http\Request $request = Illuminate\Http\Request::capture() );$response-&gt;send();// 执行所有中间件的 terminate 方法，执行 Application 中的 terminatingCallbacks 回调函数$kernel-&gt;terminate($request, $response); 重要的类变量数组aliases数组维护 类与别名 的数组；键名为 类的全限定类名，键值为 数组，每一个元素都是该类的别名； 判断指定类是否有别名：app()-&gt;isAlias($name)； 获取指定类的别名：app()-&gt;getAlias($abstract)； abstractAliases数组维护 类与别名 的数组；键名为 别名，键值为 类的全限定类名； instances数组维护 类与实例的数组；键名为 类的全限定类名，键值为该类的实例； 移除绑定类：app()-&gt;forgetInstance($abstract);移除所有绑定类：app()-&gt;forgetInstances(); bindings数组通过 bind 方法实现 接口类与实现的绑定； 获取bindings数组中的内容：app()-&gt;getBindings() resolved数组键名为 类的全限定类名，键值为布尔值类型（true表示已解析过，false表示未解析过）； with数组在resolved过程中，会有一些参数；with数组就是参数栈，开始解析时将参数入栈，结束解析时参数出栈； contextual数组上下文绑定数组；第一维数组键名为 场合类（比如某个Controller类的类名），第二维数组键名为 抽象类（需要实现的接口类），键值为 Closure 或 某个具体类的类名； tags数组维护 标签与类 的数组；键名是 标签名，键值是 对应要绑定的类的名称； 如果调用tagged方法，会将键值数组中的类都make出来，并以数组形式返回； extenders数组在make或resolve出对象的时候，会执行123foreach ($this-&gt;getExtenders($abstract) as $extender) &#123; $object = $extender($object, $this);&#125; 能对解析出来的对象进行修饰； methodBindings数组可以绑定类的一个方法到自定义的函数；用法可以参考Laravel核心——Ioc服务容器 中的相关章节； 向容器绑定方法与及实现：app()-&gt;bindMethod($method, $callback) 判断容器内是否有指定方法的实现：app()-&gt;hasMethodBinding($method) 执行方法的实现：app()-&gt;callMethodBinding($method, $instance)或者app()-&gt;call($method) buildStack数组调用build方法时维护的栈，栈中存放的是当前要new的类名； reboundCallbacks数组当调用rebound函数时，会触发rebound中为此$abstract设置的回调函数； 注册入口：app()-&gt;rebinding($abstract, Closure $callback); serviceProviders数组已在系统注册的服务提供者ServiceProvider； 数组内存放的是loadedProviders键名对应类的实例； loadedProviders数组系统已加载的ServiceProvider的集合；键名为ServiceProvider的全限定类名，键值为布尔值（true表示已加载，false表示未加载）； 获取延迟加载对象：app()-&gt;getLoadedProviders(); deferredServices数组有些服务提供者是会延迟加载的；这时候会将这些服务提供者声明的服务登录在deferredServices数组，键名为延迟加载对象名 ，键值为该延迟加载对象所在的ServiceProvider； 获取延迟加载对象：app()-&gt;getDeferredServices(); bootingCallbacks数组项目启动前执行的回调函数；（项目启动是在执行\Illuminate\Foundation\Bootstrap\BootProviders::class的时候） 注册入口：app()-&gt;booting($callback); bootedCallbacks数组项目启动后执行的回调函数；（项目启动是在执行\Illuminate\Foundation\Bootstrap\BootProviders::class的时候） 注册入口：app()-&gt;booted($callback); resolvingCallbacks数组解析时回调函数集合；键名为 类名， 键值为 回调函数数组，每一个元素都是回调函数； 注册入口：app()-&gt;resolving($abstract, $callback); afterResolvingCallbacks数组解析后回调函数集合；键名为 类名， 键值为 回调函数数组，每一个元素都是回调函数； 注册入口：app()-&gt;afterResolving($abstract, $callback); globalResolvingCallbacks数组全局解析时回调函数集合；每一次resolve方法调用时都会执行的回调函数集合； 注册入口：app()-&gt;resolving($callback); globalAfterResolvingCallbacks数组全局解析后回调函数集合；每一次resolve方法调用后都会执行的回调函数集合； 注册入口：app()-&gt;afterResolving($callback); terminatingCallbacks数组系统在返回response之后，会执行terminate方法，来做应用结束前的扫尾处理； 这个数组就是执行terminate方法时会执行的回调函数集合； 注册入口：app()-&gt;terminating(Closure $callback); 常用方法的解析bind方法1public function bind($abstract, $concrete = null, $shared = false) 第一个参数是要注册的类名或接口名，第二个参数是返回类的实例的闭包（或类的实例类名），第三个参数是否是单例； 方法内部流程： unset 掉 instances 和 aliases 数组中键值为 $abstract 的元素； 如果 $concrete 值为 null ，将 $abstract 赋值给 $concrete； 如果 $concrete 不是 Closure 对象，则封装成闭包； 将 $concrete 和 $shared 通过 compact，添加进 bindings 数组，键名为 $abstract； 判断 $abstract 在 resolved 和 instances 数组中是否存在，如果存在，则执行第 6 步； 触发 rebound回调函数；如果 reboundCallbacks 数组中注册以 $abstract 为键名的回调函数，则执行这些回调函数； 涉及数组：instances和aliases（unset 操作）、bindings（add 操作） singleton方法单例绑定；123public function singleton($abstract, $concrete = null) $this-&gt;bind($abstract, $concrete, true);&#125; 涉及数组：instances和aliases（unset 操作）、bindings（add 操作） bindIf方法单例绑定；12345public function bindIf($abstract, $concrete = null, $shared = false) &#123; if (! $this-&gt;bound($abstract)) &#123; $this-&gt;bind($abstract, $concrete, $shared); &#125;&#125; 涉及数组：instances和aliases（unset 操作）、bindings（add 操作） instance方法绑定实例；1public function instance($abstract, $instance) 方法内部流程： 如果$abstract在aliases数组中存在，则从abstractAliases中所有的值数组中移除该类； unset 掉 aliases 数组中键名为 $abstract的元素； 赋值操作：$this-&gt;instances[$abstract] = $instance; 判断 $abstract 在 resolved 和 instances 数组中是否存在，如果存在，则执行第 5 步； 触发 rebound回调函数；如果 reboundCallbacks 数组中注册以 $abstract 为键名的回调函数，则执行这些回调函数； 涉及数组：instances（add 操作）、aliases 和 abstractAliases（unset 操作） make方法123public function make($abstract) &#123; return $this-&gt;resolve($abstract);&#125; alias方法给类起别名；12345public function alias($abstract, $alias) &#123; $this-&gt;aliases[$alias] = $abstract; $this-&gt;abstractAliases[$abstract][] = $alias;&#125; 涉及数组：aliases和abstractAliases（add 操作） 扩展阅读 leoyang90博客 - Laravel核心——Ioc服务容器]]></content>
      <categories>
        <category>Laravel</category>
      </categories>
      <tags>
        <tag>Laravel-5.4</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel 大将之 广播 模块]]></title>
    <url>%2F2017%2F08%2F21%2Flaravel-broadcast%2F</url>
    <content type="text"><![CDATA[本文是基于Laravel 5.4版本的广播模块代码进行分析书写； 官方 API 地址 https://laravel.com/api/5.4/Illuminate/Broadcasting.html 简介广播是指发送方发送一条消息，订阅频道的各个接收方都能及时收到消息；比如 A同学写了一篇文章，这时候 B同学在文章底下评论了，A同学在页面上是不用刷新就能收到提示有文章被评论了，这个本质上就是A同学收到了广播消息，这个广播消息是由B同学评论这个动作触发了发送广播消息； 在整个广播行为中，有一个重要的概念叫频道channel，频道的类型有 公共频道public 私有频道private 存在频道presence 移动端订阅了公共频道public，会直接提示成功；私有频道private和存在频道presence在进行订阅的过程中，会向服务器端发送权限验证，看是不是有权限可以订阅该频道；私有频道private和存在频道presence的区别在于，私有频道private能够接收其他成员发送的消息，而存在频道presence除此之外，还能够在用户的加入与离开时接收信息； 广播适合以下场景（此小部分摘自基于 Pusher 驱动的 Laravel 事件广播（上））： 通知（Notification） 或 信号（Signal）通知是最简单的示例，也最经常用到。信号也可看作是通知的一种展现形式，只不过信号没有UI而已。 Activity StreamsActivity Streams(feeds)是社交网络的核心。如微信朋友圈的点赞和评论，A可以实时看到B的点赞，B可以实时看到A的评论。 聊天聊天信息的实时显示 模块组成 Demo日志驱动配置.env文件修改或添加一行：BROADCAST_DRIVER=log； 广播直接调用1234$manager = app(Illuminate\Broadcasting\BroadcastManager::class);$driver = $manager-&gt;connection();// 第一个参数是频道名，第二个参数是事件名，第三个参数是广播内容$driver-&gt;broadcast(['channel_1', 'channel_2'], 'login', ['message' =&gt; 'hello world']); 因为是日志驱动，所以广播内容会写到框架配置的日志文件中，输出消息如下所示1234[2017-08-18 20:45:49] local.INFO: Broadcasting [login] on channels [channel_1, channel_2] with payload:&#123; "message": "hello world"&#125; 监听事件广播这种调用方式，是当实现ShouldBroadcast接口的事件被触发时，则会进行广播操作；（同时，还有一个接口叫ShouldBroadcastNow，与ShouldBroadcast接口的不同在于，将实现ShouldBroadcastNow接口的事件放入队列中时，会被放入叫sync的队列中） 举个例子， 第一步，Illuminate\Auth\Events\Login事件是用户登录成功后会触发的事件，略作改动，让其实现广播功能；123456789101112131415class Login implements ShouldBroadcast &#123; ...... // 定义事件被触发时，广播频道；此处定义名为 first-channel 的私有频道 public function broadcastOn() &#123; return [ new PrivateChannel('first-channel'), ]; &#125; // 自定义广播名称；如果方法未定义，默认以类名为事件名，此处的默认值是 Illuminate\Auth\Events\Login public function broadcastAs() &#123; return 'login'; &#125;&#125; 第二步，注册事件监听；在app/Providers/EventServiceProvider.php中修改：123456protected $listen = [ ...... 'Illuminate\Auth\Events\Login' =&gt; [ 'App\Listeners\UserLogin', ],]; 文件app/Listeners/UserLogin.php粗糙地实现了一下：1234567class UserLogin &#123; public function __construct() &#123;&#125; public function handle(Login $event)&#123; \Log::info('Do UserLogin Listener: I was Login'); &#125;&#125; 第三步，触发事件，发送广播；有好几种触发广播方式： 直接事件触发 1event(new Illuminate\Auth\Events\Login($user, true)); 帮助函数broadcast，间接触发事件 1broadcast(new Illuminate\Auth\Events\Login($user, true)); 广播管理类，间接触发事件，直接广播 12$manager = app(Illuminate\Broadcasting\BroadcastManager::class);$manager-&gt;event(new Illuminate\Auth\Events\Login($user, true)); 广播管理类，间接触发事件，放入队列 12$manager = app(Illuminate\Broadcasting\BroadcastManager::class);$manager-&gt;queue(new Illuminate\Auth\Events\Login($user, true)); Pusher驱动Pusher是一个第三方服务，服务器发送广播时，会向Pusher发送请求，再通过Pusher与浏览器或移动端保持的长连接进行数据交互； 配置通过Pusher官网注册用户信息，获取属于自已的一套密钥信息，修改.env的配置文件；1234BROADCAST_DRIVER=pusherPUSHER_APP_ID=xxxxxxxxxxxxxxxxxxxxxxPUSHER_APP_KEY=xxxxxxxxxxxxxxxxxxxxxxPUSHER_APP_SECRET=xxxxxxxxxxxxxxxxxxxxxx 准备工作事件监听后台的事件监听还是采用”日志驱动”部分的登录例子； 前端前端页面引入以下代码：123456789101112131415161718&lt;script src="https://js.pusher.com/4.1/pusher.min.js"&gt;&lt;/script&gt;&lt;script&gt;// 打开 Pusher 的调试日志Pusher.logToConsole = true;// 定义 Pusher 变量var pusher = new Pusher('PUSHER_APP_KEY的值', &#123; cluster: 'ap1', encrypted: true&#125;);// 定义频道，绑定事件var channel = pusher.subscribe('private-first-channel');channel.bind('login', function(data) &#123; alert(data);&#125;);&lt;/script&gt; 如果订阅的是公共频道，则不会向服务器端请求权限检查；如果是私有频道（频道名是以private-开头）或存在频道（频道名是以presence-开头），则会发出权限检查请求；对应的后端需要定义私有频道和存在频道的权限； 频道权限定义频道的权限定义是在routes/channels.php里；此处笔者为first-channel频道定义权限回调函数：123Broadcast::channel('first-channel', function ($user) &#123; return (int) $user-&gt;id === 1;&#125;); 有读者会疑问，前端页面订阅的频道不是private-first-channel吗？怎么后端只定义first-channel频道的权限呢？那是因为，后端定义的频道假设是A，那么在Pusher及浏览器端或移动端传递的私有频道名为private-A，存在频道则会是presence-A； 广播直接广播1234$manager = app(Illuminate\Broadcasting\BroadcastManager::class);$driver = $manager-&gt;connection();// socket 参数是广播私有频道时排除的 socket， 每个浏览器端或者移动端在建立 websocket 时都会被分配一个 socket_id$driver-&gt;broadcast(['private-first-channel'], 'login', ['user' =&gt; ['name' =&gt; 'hello'], 'socket' =&gt; '5395.4377611']); 间接广播参考“日志驱动”提及的间接广播方式； 如果要发送排我广播（也就是除了当前请求的这个客户端不收到广播消息），则需要以下条件： 事件使用Illuminate\Broadcasting\InteractsWithSockets trait； 前端发送过来的请求头部要携带X-Socket-ID信息； 事件触发执行broadcast(new Illuminate\Auth\Events\Login($user, true))-&gt;toOthers(); Redis驱动配置.env文件修改或添加一行：BROADCAST_DRIVER=redis； 广播原理是同样在后端部署一个Socket.IO服务器，Laravel框架会发布消息到Socket.IO服务器上，由Socket.IO服务器同浏览器端或者移动端保持长连接； 这部分笔者尚未demo，网上入门资料还是挺多的，知道原理，这部分动作上手就容易多了； 附录同类型的文章可参考以下，加深了解： Laravel学院 事件广播基础知识 Pusher 的认识]]></content>
      <categories>
        <category>Laravel</category>
      </categories>
      <tags>
        <tag>Laravel-5.4</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel 大将之 Auth 模块]]></title>
    <url>%2F2017%2F08%2F16%2Flaravel-auth%2F</url>
    <content type="text"><![CDATA[本文是基于Laravel 5.4 版本的Auth模块代码进行分析书写； 官方 API 地址 https://laravel.com/api/5.4/Illuminate/Auth.html 模块组成Auth模块从功能上分为用户认证和权限管理两个部分；从文件组成上，Illuminate\Auth\Passwords目录下是密码重置或忘记密码处理的小模块，Illuminate\Auth是负责用户认证和权限管理的模块，Illuminate\Foundation\Auth提供了登录、修改密码、重置密码等一系统列具体逻辑实现；下图展示了Auth模块各个文件的关系，并进行简要说明； 用户认证HTTP本身是无状态，通常在系统交互的过程中，使用账号或者Token标识来确定认证用户； 配置文件解读1234567891011121314151617181920212223return [ 'defaults' =&gt; [ 'guard' =&gt; 'web', ... ], 'guards' =&gt; [ 'web' =&gt; [ 'driver' =&gt; 'session', 'provider' =&gt; 'users', ], 'api' =&gt; [ 'driver' =&gt; 'token', 'provider' =&gt; 'users', ], ], 'providers' =&gt; [ 'users' =&gt; [ 'driver' =&gt; 'eloquent', 'model' =&gt; App\User::class, ], ],], ]; 从下往上，理解； providers是提供用户数据的接口，要标注驱动对象和目标对象；此处，键名users是一套provider的名字，采用eloquent驱动，modal是App\User::class； guards部分针对认证管理部分进行配置；有两种认证方式，一种叫web，还有一种是api；web认证是基于Session交互，根据sessionId获取用户id，在users这个provider查询出此用户；api认证是基于token值交互，也采用users这个provider； defaults项显示默认使用web认证； 认证 Session绑定认证信息： 1234567// $credentials数组存放认证条件，比如邮箱或者用户名、密码// $remember 表示是否要记住，生成 `remember_token`public function attempt(array $credentials = [], $remember = false) public function login(AuthenticatableContract $user, $remember = false) public function loginUsingId($id, $remember = false) HTTP基本认证，认证信息放在请求头部；后面的请求访问通过sessionId； 1public function basic($field = 'email', $extraConditions = []) 只在当前会话中认证，session中不记录认证信息： 12345public function once(array $credentials = [])public function onceUsingId($id)public function onceBasic($field = 'email', $extraConditions = []) 认证过程中（包括注册、忘记密码），定义的事件有这些： 事件名 描述 Attempting 尝试验证事件 Authenticated 验证通过事件 Failed 验证失败事件 Lockout 失败次数超过限制，锁住该请求再次访问事件 Logi 通过‘remember_token’成功登录时，调用的事件 Logout 用户退出事件 Registered 用户注册事件 还有一些其他的认证方法： 检查是否存在认证用户：Auth::check() 获取当前认证用户：Auth::user() 退出系统：Auth::logout() 密码处理配置解读1234567891011121314return [ 'defaults' =&gt; [ 'passwords' =&gt; 'users', ... ], 'passwords' =&gt; [ 'users' =&gt; [ 'provider' =&gt; 'users', 'table' =&gt; 'password_resets', 'expire' =&gt; 60, ], ],] 从下往上，看配置； passwords数组是重置密码的配置；users是配置方案的别名，包含三个元素：provider（提供用户的方案，是上面providers数组）、table（存放重置密码token的表）、expire（token过期时间） default 项会设置默认的 passwords 重置方案； 重置密码的调用与实现先看看Laravel的重置密码功能是怎么实现的：12345678910111213141516public function reset(array $credentials, Closure $callback) &#123; // 验证用户名、密码和 token 是否有效 $user = $this-&gt;validateReset($credentials); if (! $user instanceof CanResetPasswordContract) &#123; return $user; &#125; $password = $credentials['password']; // 回调函数执行修改密码，及持久化存储 $callback($user, $password); // 删除重置密码时持久化存储保存的 token $this-&gt;tokens-&gt;delete($user); return static::PASSWORD_RESET;&#125; 再看看Foundation\Auth模块封装的重置密码模块是怎么调用的：123456789101112131415161718192021222324252627282930313233// 暴露的重置密码 APIpublic function reset(Request $request) &#123; // 验证请求参数 token、email、password、password_confirmation $this-&gt;validate($request, $this-&gt;rules(), $this-&gt;validationErrorMessages()); // 调用重置密码的方法，第二个参数是回调，做一些持久化存储工作 $response = $this-&gt;broker()-&gt;reset( $this-&gt;credentials($request), function ($user, $password) &#123; $this-&gt;resetPassword($user, $password); &#125; ); // 封装 Response return $response == Password::PASSWORD_RESET ? $this-&gt;sendResetResponse($response) : $this-&gt;sendResetFailedResponse($request, $response);&#125;// 获取重置密码时的请求参数protected function credentials(Request $request) &#123; return $request-&gt;only( 'email', 'password', 'password_confirmation', 'token' );&#125;// 重置密码的真实性验证后，进行的持久化工作protected function resetPassword($user, $password) &#123; // 修改后的密码、重新生成 remember_token $user-&gt;forceFill([ 'password' =&gt; bcrypt($password), 'remember_token' =&gt; Str::random(60), ])-&gt;save(); // session 中的用户信息也进行重新赋值 $this-&gt;guard()-&gt;login($user);&#125; “忘记密码 =&gt; 发邮件 =&gt; 重置密码” 的大体流程如下： 点击“忘记密码”，通过路由配置，跳到“忘记密码”页面，页面上有“要发送的邮箱”这个字段要填写； 验证“要发送的邮箱”是否是数据库中存在的，如果存在，即向该邮箱发送重置密码邮件； 重置密码邮件中有一个链接（点击后会携带 token 到修改密码页面），同时数据库会保存这个 token 的哈希加密后的值； 填写“邮箱”，“密码”，“确认密码”三个字段后，携带 token 访问重置密码API，首页判断邮箱、密码、确认密码这三个字段，然后验证 token是否有效；如果是，则重置成功； 登录次数限制这部分的代码逻辑实现在 Illuminate\Foundation\Auth\ThrottlesLogins 页面中； 主要涉及以下因素： 限制的登录次数阅读源代码中的 maxLoginAttempts 方法，可以获悉如果引用此 ThrottlesLogins 的 AuthController没有定义 maxLoginAttempts 属性，则默认值为 5； 超出登录次数的封锁时间阅读源代码中的 lockoutTime 方法，可以获悉如果引用此 ThrottlesLogins 的 AuthController没有定义 lockoutTime 属性，则默认值为 60，（隐藏单位为秒）； 如果要清除之前的登录限制，可在 AuthController 处理登录请求开始处执行以下语句： 1$this-&gt;clearLoginAttempts($request); 权限管理权限管理是依靠内存空间维护的一个数组变量abilities来维护，结构如下：1234567$abilities = array( '定义的动作名，比如以路由的 as 名(common.dashboard.list)' =&gt; function($user) &#123; // 方法的参数，第一位是 $user, 当前 user, 后面的参数可以自行决定 return true; // 返回 true 意味有权限， false 意味没有权限 &#125;, ......); 但只用 $abilities，会使用定义的那部分代码集中在一起太烦索，所以有policy策略类的出现； policy策略类定义一组实体及实体权限类的对应关系，比如以文章举例： 有一个 Modal实体类叫 Post，可以为这个实体类定义一个PostPolicy权限类，在这个权限类定义一些动作为方法名；123456class PostPolicy &#123; // update 权限，文章作者才可以修改 public function update(User $user, Post $post) &#123; return $user-&gt;id === $post-&gt;user_id; &#125;&#125; 然后在ServiceProvider中注册，这样系统就知道，如果你要检查的类是Post对象，加上你给的动作名，系统会找到PostPolicy类的对应方法；123protected $policies = [ Post::class =&gt; PostPolicy::class,]; 怎么调用呢？ 对于定义在abilities数组的权限： 当前用户是否具备common.dashboard.list权限：Gate::allows(&#39;common.dashboard.list&#39;) 当前用户是否具备common.dashboard.list权限：! Gate::denies(&#39;common.dashboard.list&#39;) 当前用户是否具备common.dashboard.list权限：$request-&gt;user()-&gt;can(&#39;common.dashboard.list&#39;) 当前用户是否具备common.dashboard.list权限：! $request-&gt;user()-&gt;cannot(&#39;common.dashboard.list&#39;) 指定用户是否具备common.dashboard.list权限：Gate::forUser($user)-&gt;allows(&#39;common.dashboard.list&#39;) 对于policy策略类调用的权限： 当前用户是否可以修改文章（Gate 调用）：Gate::allows(&#39;update&#39;, $post) 当前用户是否可以修改文章（user 调用）：$user-&gt;can(&#39;update&#39;, $post) 当前用户是否可以修改文章（用帮助函数）：policy($post)-&gt;update($user, $post) 当前用户是否可以修改文章（Controller 类方法中调用）：$this-&gt;authorize(&#39;update&#39;, $post); 当前用户是否可以修改文章（Controller 类同名方法中调用）：$this-&gt;authorize($post); 指定用户是否可以修改文章（Controller 类方法中调用）：$this-&gt;authorizeForUser($user, &#39;update&#39;, $post); 有用的技巧获取当前系统注册的权限，包括两部分abilities和policies数组内容，代码如下：123456789101112$gate = app(\Illuminate\Contracts\Auth\Access\Gate::class);$reflection_gate = new ReflectionClass($gate);$policies = $reflection_gate-&gt;getProperty('policies');$policies-&gt;setAccessible(true);// 获取当前注册的 policies 数组dump($policies-&gt;getValue($gate)); $abilities = $reflection_gate-&gt;getProperty('abilities'); $abilities-&gt;setAccessible(true);// 获取当前注册的 abilities 数组dump($abilities-&gt;getValue($gate));]]></content>
      <categories>
        <category>Laravel</category>
      </categories>
      <tags>
        <tag>Laravel-5.4</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel 大将之 路由 模块]]></title>
    <url>%2F2017%2F08%2F01%2Flaravel-router%2F</url>
    <content type="text"><![CDATA[本文是基于Laravel 5.4版本的路由模块代码进行分析书写； 官方 API 地址 https://laravel.com/api/5.4/Illuminate/Routing.html 模块组成下图展示了路由模块中各个文件的关系，并进行简要说明； 剖析服务提供者看Laravel模块，首先找ServiceProvider文件，这是模块与IOC容器交互的入口，从这个文件，可以看出该模块提供向系统提供了哪些服务； 1234567891011121314public function register() &#123; // 注册路由管理，提供路由注册，路由匹配的功能 $this-&gt;registerRouter(); // 注册 Url 生成器实例 $this-&gt;registerUrlGenerator(); // 注册跳转器 $this-&gt;registerRedirector(); // 绑定 PSR-7 请求实现到 ServerRequestInterface 接口 $this-&gt;registerPsrRequest(); // 绑定 PSR-7 Response 实现到 ResponseInterface 接口 $this-&gt;registerPsrResponse(); // 注册 ReponseFactory，提供各式各样的 Response，比如视图响应、Json响应、Jsonp响应、文件下载等 $this-&gt;registerResponseFactory();&#125; 路由管理“路由管理”服务有以下元素需要了解： Route：路由；会记录 Url、Http 动作、Action (路由要执行的具体对象，可能是 Closure，也可以是某个 Controller 中的方法)，路由参数，路由参数的约束； RouteCollection：路由集，用来存储所有Route对象的“盒子”； RouteGroup：路由组；只有路由注册过程中会临时用到；存储一批路由公共的一些属性，属性包括domain、prefix、as、middleware、namespace、where； Resource：资源路由；资源路由是一套路由的统称，包含列表（index）、显示增加（create）、保存增加（store）、显示详情（show）、显示编辑详情（edit）、更新编辑（update）、删除详情（destory）；同时可以通过调用only或except方法或参数的形式只生成部分路由； Action：路由要执行的对象；有两种表现形式，一是Closure函数，二是类似[&#39;uses&#39; =&gt; &#39;FooController@method&#39;, &#39;as&#39; =&gt; &#39;name&#39;]这样的字符串；对于不同的表现形式，路由在执行时会调用不同的处理； 注册流程在项目启动后，会执行所有ServiceProvider的loadRoutes方法，也就是调用map方法，一般情况下map方法如下123public function map(Router $router)&#123; require __DIR__.'/routes.php';&#125; 这时候，项目就会执行很多Route::get、Route::post、Route::group方法； 当遇到Route::group方法时，会实例化一个RouteGroup对象，put进Router管理类的路由组栈头部；而后当执行get、post这类具体的注册路由方法时，会把当前路由组栈中所有组的属性合并进新路由中，将新路由存储在RouteCollection这个大盒子里；当Route::group的Closure执行完毕时，会把头部的RouteGroup实例pull出去； 当执行Route::resource时，Router管理类会调用ResourceRegister类来完成批量注册路由； 对于 Router::get这类注册方法，Illuminate\Foudation\helpers提供了简写；Router::get 简化成 get，Router::post 简化成 post，Router::put 简化成 put，Router::patch 简化成 patch，Router::delete 简化成 delete，Router::resource简化成 resource， 至此，RouteCollection大盒子就存放了所有要注册的路由； request 请求匹配流程首先，request请求会经过Foundation/Http/Kernel的handle方法，在这个方法中，请求会执行以下语句1$this-&gt;router-&gt;dispatch($request) 这里的$this-&gt;router，就是Router管理类；dispatch方法如下12345678910111213141516171819public function dispatch(Request $request) &#123; $this-&gt;currentRequest = $request; return $this-&gt;dispatchToRoute($request);&#125;public function dispatchToRoute(Request $request) &#123; // 根据请求的 url 找到匹配的路由 $route = $this-&gt;findRoute($request); // 将路由绑定到请求上 $request-&gt;setRouteResolver(function () use ($route) &#123; return $route; &#125; // 触发 RouteMatched 事件 $this-&gt;events-&gt;dispatch(new Events\RouteMatched($route, $request)); // 通过 Pipeline 流水线执行路由上绑定的中间件及对应的方法 $response = $this-&gt;runRouteWithinStack($route, $request); // 根据 request 请求设置 response 的响应头 return $this-&gt;prepareResponse($request, $response);&#125; 根据请求找匹配的路由 RouteCollection根据请求的http动作缩小要匹配的路由范围；在筛选出来的这些路由中依次遍历，找出第一个符合验证的路由（需要进行较验的验证在Route中的getValidators方法中声明）； 将路由绑定到请求上 触发RouteMatched事件 初始化的Laravel项目没有对RouteMatched路由匹配事件进行任何的监听器绑定，如有需要，可以自定义监听器，在模块的EventServiceProvider中注册该事件监听；这样一旦请求匹配上某个路由，就可以执行自定义方法了； 通过 Pipeline 流水线执行路由上绑定的中间件及对应的方法 在runRouteWithinStack方法中，系统会判断是否需要执行中间件，如果IOC容器中设置了middleware.disable的值为true，则需要执行的中间件数组为空；否则会找到所有的中间件，并按照middlewarePriority对必要的一些中间件进行排序调整；然后执行$route-&gt;run()方法； 根据 request 请求设置 response 的响应头 项目中会用到的一些方法 获取路由集合 app(&#39;router&#39;)-&gt;getRoutes() 获取当前的请求 $request = app(&#39;router&#39;)-&gt;getCurrentRequest() 获取当前请求所对应的路由 $route = $request-&gt;route() 或 $route = app(&#39;router&#39;)-&gt;getCurrentRoute() 获取当前路由需要执行的中间件 $middlewares = app(&#39;router&#39;)-&gt;gatherRouteMiddleware($route) Url 生成器Url 生成器是什么？举个例子，123456$url = new UrlGenerator( $routes = new RouteCollection, $request = Request::create('http://www.foo.com/'));$url-&gt;to('foo/bar'); // 输出 http://www.foo.com/foo/bar 像这种基于当前请求，生成指定路径的Url； 这部分功能由两个文件完成，一个是UrlGenerator.php，另一个是RouteUrlGenerator.php；UrlGenerator.php处理根据路径名生成Url，RouteUrlGenerator.php处理根据路由生成Url； 列一些常用的使用： 根据路径名生成使用to方法，第一个参数为路径，第二个参数是数组，implode后会接着路径名，第三个参数决定用不用https123456789// 路径名是 foo/bar，当前请求的根路径为 http://www.foo.com，所以输出是 http://www.foo.com/foo/bar$url-&gt;to('foo/bar')// 路径名是 foo/bar，当前请求的根路径为 http://www.foo.com，第三个参数决定 scheme 是 https，所以输出是 https://www.foo.com/foo/bar$url-&gt;to('foo/bar', [], true)// 路径名是 foo/bar，第二个参数 是补充路径名，implode 后是 /baz/boom// 第三个参数决定 scheme 是 https，所以输出是 https://www.foo.com/foo/bar/baz/boom$url-&gt;to('foo/bar', ['baz', 'boom'], true)// 路径名是 foo/bar，查询参数是 ?foo=bar ，补充路径是 /baz，所以输出是 https://www.foo.com/foo/bar/baz?foo=bar$url-&gt;to('foo/bar?foo=bar', ['baz'], true) 根据路由的 as 名生成使用route方法，第一个参数为指定路由的 as 名，第二个参数是参数数组，第三个参数决定是否显示根目录（默认为 true）123456789101112$route = new Route(['GET'], 'foo/bar', ['as' =&gt; 'foo']);$routes-&gt;add($route);// 输出 'http://www.foo.com/foo/bar$url-&gt;route('foo');// 第三个参数为 false，表示不显示根目录，于是输出 /foo/bar$url-&gt;route('foo', [], false)// 路由中的 url 本身不带参数，则第二参数中所有关联数组都将作为查询参数// 输出 /foo/bar?foo=bar$url-&gt;route('foo', ['foo' =&gt; 'bar'], false) 12345678910$route = new Route(['GET'], 'foo/bar/&#123;baz&#125;/breeze/&#123;boom&#125;', ['as' =&gt; 'bar']);$routes-&gt;add($route);// 路由上的 url 带参数，根据参数名找值；剩余多余的为查询参数；// 输出 http://www.foo.com/foo/bar/otwell/breeze/taylor?fly=wall$url-&gt;route('bar', ['boom' =&gt; 'taylor', 'baz' =&gt; 'otwell', 'fly' =&gt; 'wall']);// 路由上的 url 带参数，找不到对应的参数值，则按顺序作值；剩余多余的为查询参数；// 输出 http://www.foo.com/foo/bar/taylor/breeze/otwell?fly=wall$url-&gt;route('bar', ['taylor', 'otwell', 'fly' =&gt; 'wall']); 根据路由的 action 名生成使用action方法，第一个参数为指定路由的 action 名，第二个参数是参数数组，第三个参数决定是否显示根目录（默认为 true）12345$route = new Route(['GET'], 'foo/bam', ['controller' =&gt; 'foo@bar']);$routes-&gt;add($route);// 输出 http://www.foo.com/foo/bam$url-&gt;action('foo@bar'); 12345$route = new Route(['GET'], 'foo/invoke', ['controller' =&gt; 'InvokableActionStub']);$routes-&gt;add($route);// 输出 http://www.foo.com/foo/invoke$url-&gt;action('InvokableActionStub'); 设置全局默认参数123456$url-&gt;defaults(['locale' =&gt; 'en']);$route = new Route(['GET'], 'foo', ['as' =&gt; 'defaults', 'domain' =&gt; '&#123;locale&#125;.example.com', function() &#123;&#125;]);// 路由 url 有参数，但没有传参数值，则会找全局默认参数值；输出 http://en.example.com/foo$url-&gt;route('defaults'); 设置全局命名空间这样调用的时候，不用在 action 上省略这部分命名空间1234567891011121314151617181920// 设置全局命名空间$url-&gt;setRootControllerNamespace('namespace');// 配置添加路由$route = new Route(['GET'], 'foo/bar', ['controller' =&gt; 'namespace\foo@bar']);$routes-&gt;add($route);$route = new Route(['GET'], 'foo/invoke', ['controller' =&gt; 'namespace\InvokableActionStub']);$routes-&gt;add($route);// 输出 http://www.foo.com/foo/bar; action 的值省略 namespace 这个命名空间$url-&gt;action('foo@bar');// 输出 http://www.foo.com/foo/invoke; action 的值省略 namespace 这个命名空间$url-&gt;action('InvokableActionStub');// 配置添加路由$route = new Route(['GET'], 'something/else', ['controller' =&gt; 'something\foo@bar']);$routes-&gt;add($route);// 输出 http://www.foo.com/something/else； action 的最前面加了 `\`，全局命名空间下调用$url-&gt;action('\something\foo@bar')； 跳转器跳转器内部提供了以下跳转； home通过调用app(&#39;redirect&#39;)-&gt;home()会跳转至根目录下\；1public function home($status = 302) back通过调用app(&#39;redirect&#39;)-&gt;back()会跳转至上一次访问页面；或者全局帮助函数back()也可以；1public function back($status = 302, $headers = [], $fallback = false) 第三个参数表示，如果没有前一次访问请求，访问哪个页面，具体源码如下：1234567if ($url) &#123; return $url;&#125; elseif ($fallback) &#123; return $this-&gt;to($fallback);&#125; else &#123; return $this-&gt;to('/');&#125; refresh通过调用app(&#39;redirect&#39;)-&gt;refresh()会刷新当前访问页面；1public function refresh($status = 302, $headers = []) to通过调用app(&#39;redirect&#39;)-&gt;to(&#39;path&#39;)会跳转至指定路径页面；或者全局帮助函数redirect(&#39;path&#39;)也可以； 这里的 path 路径是不包含根目录的，例如（foo/bar）； 1public function to($path, $status = 302, $headers = [], $secure = null) 第四个参数表示是否使用https； away通过调用app(&#39;redirect&#39;)-&gt;away(&#39;path&#39;)会跳转至指定路径页面； 这里的 path 路径是包含根目录的，例如（http://xx.com/foo/bar）；1public function away($path, $status = 302, $headers = []) secure通过调用app(&#39;redirect&#39;)-&gt;secure(&#39;path&#39;)会跳转至指定路径页面；这里的path路径是不包含根目录的；1public function secure($path, $status = 302, $headers = []) 其本质是调用了to方法1return $this-&gt;to($path, $status, $headers, true); route通过调用app(&#39;redirect&#39;)-&gt;route(&#39;route_as_name&#39;)，根据路由的as名会跳转至与路由一致的url路径页；1public function route($route, $parameters = [], $status = 302, $headers = []) action通过调用app(&#39;redirect&#39;)-&gt;action(&#39;route_action&#39;)，根据路由的action名会跳转至与路由一致的url路径页；1public function action($action, $parameters = [], $status = 302, $headers = []) guest跳到指定的路径页的同时，将当前url存放至session中，键名为url.intended;1public function guest($path, $status = 302, $headers = [], $secure = null) intended跳转至session中键名为url.intended的值所对应的Url；如果不存在，则跳转至第一个参数所传的值；1public function intended($default = '/', $status = 302, $headers = [], $secure = null) 响应工厂（ResponseFactory）ResponseFactory文件提供了两部分 API，分别是与响应类型相关和与跳转相关； 响应response()会返回ResponseFactory实例； 视图响应1response()-&gt;view('hello', $data, 200); Jsop响应1response()-&gt;json(['name' =&gt; 'Abigail', 'state' =&gt; 'CA']); Jsonp响应1response()-&gt;json(['name' =&gt; 'Abigail', 'state' =&gt; 'CA'])-&gt;withCallback($request-&gt;input('callback')); 文件响应直接在浏览器显示文件，而不是下载，例如图片或PDF；file方法第一参数为文件路径，第二参数选填为头信息数组；1response()-&gt;file($pathToFile, $headers); 文件下载download方法第一参数为文件路径，第二参数选填为文件名，第三参数选填为头信息数组；1return response()-&gt;download($pathToFile, $name, $headers); 跳转这里的跳转方法，其实调用的还是跳转器中的方法，不过是在暴露更多的接口，方便调用与使用； 方法名 调用 实际调用的是跳转器中的哪个方法 redirectTo response()-&gt;redirectTo(…) to方法 redirectToRoute response()-&gt;redirectToRoute(…) route方法 redirectToAction response()-&gt;redirectToAction(…) action方法 redirectGuest response()-&gt;redirectGuest(…) guest方法 redirectToIntended response()-&gt;redirectToIntended(…) intended方法]]></content>
      <categories>
        <category>Laravel</category>
      </categories>
      <tags>
        <tag>Laravel-5.4</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel 大将之 本地化 模块]]></title>
    <url>%2F2017%2F08%2F01%2Flaravel-trans%2F</url>
    <content type="text"><![CDATA[本文是基于Laravel 5.4版本的本地化模块代码进行分析书写； 官方 API 地址 https://laravel.com/api/5.4/Illuminate/Translation.html 模块组成下图展示了本地化模块各个文件的关系，并进行简要说明； TranslationServiceProvider 本地化模块的服务提供者，既是一个模块的入口，也是与IOC容器交互的中心；注册翻译器实例translation.loader，注册翻译管理实例translator，并声明延迟加载服务； Translator 翻译管理类； MessageSelector 消息过滤器，通过判断复数值来选择合适的消息；比如消息内容是这样的{0}没有|[1,19]一些|[20,*]很多，我们传的数字是 18，那么最后选择的消息就是”一些”； LoaderInterface 翻译器接口；声明了三个方法load，addNamespace，namespaces； FileLoader 继承了LoaderInterface，从文件获取本地化资源数据； ArrayLoader 继承了LoaderInterface，在内存用数组维护本地化资源数据； 配置说明在config配置目录下和本模块有关的参数只有app.php文件中的locale和fallback_locale； locale表示默认本地化语言是什么，这样会优先从该语言资源目录中获取翻译（转换）内容；如果locale表示的语言不存在，则使用fallback_locale这个备用语言； 笔者的locale是zh_CN，fallback_locale是en； 功能介绍全局的语言资源目录在项目的resources/lang下，每个子目录分别以语言为名，比如en、zh_CN等； 另外一些子目录是命名空间为名，是对第三方加载库资源文件的补充替换； 有可能还存在en.json、zh_CN这类Json文件，项目有时候会从Json文件读取数据，这些数据均来自于这个已存在的Json文件； 翻译全局语言资源笔者的语言资源根目录resources/lang下有zh_CN/validation.php，内容如下1234567&lt;?phpreturn [ 'accepted' =&gt; ':attribute 必须接受。', 'active_url' =&gt; ':attribute 不是一个有效的网址。', 'after' =&gt; ':attribute 必须是一个在 :date 之后的日期。', ......]; 通过调用代码1app('translator')-&gt;trans('validation.accepted', ['attribute' =&gt; '用户名']) 或者全局帮助函数trans1trans('validation.accepted', ['attribute' =&gt; '用户名']) 输出 “用户名 必须接受。”； 调用过程如下： 解析键名：将键名进行解析成数组 ($namespace = &#39;*&#39;, $group = &#39;validation&#39;, $item = &#39;accepted&#39;)；namespace为*，表示在全局命名空间下；group，组，其实就是文件名，一个文件为一组；item是元素的意思； 获取语言数组： 这里的$locale为null，所以返回的是默认与备用语言组成的数组，也就是[&#39;zh_CN&#39;, &#39;en&#39;]；并进行for循环，进入语言资源目录中寻找需要的元素值，如果找到，即 break； 加载资源：因为命名空间为*，所以定位资源根目录为resources/lang；语言为zh_CN，所以子目录为zh_CN；group名为validation，这时就把resources/lang/zh_CN/validation.php文件中的所有内容都加载进内存中，并进行保存 $this-&gt;loaded[$namespace][$group][$locale] = $lines; 获取资源，并替换参数：通过Arr::get方法从$this-&gt;loaded[$namespace][$group][$locale]中获取元素值:attribute 必须接受。；此时，参数数组为不空，循环替换，得到结果”用户名 必须接受。”； 翻译带命名空间的语言资源笔者在语言资源根目录resource/lang下，创建vendor/Faker/Provider/zh_CN/Internet.php文件，内容如下：12345&lt;?phpreturn [ 'message' =&gt; 'hello, Faker/Provider', ......]; 同时，手动在Translator中注册第三方插件（也就是带命名空间）的资源根目录位置；1app('translator')-&gt;addNamespace('Faker/Provider', base_path('vendor/xx/resource/lang')) 现在，获取带命名空间的资源；1trans('Faker/Provider::Internet.message'); 输出 ‘hello, Faker/Provider’； 调用过程如下： 解析键名：将键名进行解析成数组 ($namespace = &#39;Faker/Provider&#39;, $group = &#39;Internet&#39;, $item = &#39;message&#39;)； 获取语言数组： 这里的$locale为null，所以返回的是默认与备用语言组成的数组，也就是[&#39;zh_CN&#39;, &#39;en&#39;]；并进行for循环，进入语言资源目录中寻找需要的元素值，如果找到，即 break； 加载资源：因为命名空间为Faker/Provider，此时会分两步；第一步读取第三方插件资源库下的信息，这时读取命名空间注册的根目录为base_path(&#39;vendor/xx/resource/lang&#39;)，就读取base_path(&#39;vendor/xx/resource/lang&#39;)/zh_CN/Internet.php内容，文件不存在，返回空数组；第二步读取全局语言资源，进行补充，也就是读取base_path(&#39;resource/lang/vendor/Faker/Provider&#39;)/zh_CN/Internet.php; 最后进行保存 $this-&gt;loaded[$namespace][$group][$locale] = $lines; 获取资源，并替换参数：通过Arr::get方法从$this-&gt;loaded[$namespace][$group][$locale]中获取元素值” hello, Faker/Provider”；此时，参数数组为空，直接返回结果 “hello, Faker/Provider”； 翻译Json文件中的资源笔者在语言资源根目录resource/lang下，创建zh_CN.json文件，内容如下：1234&#123; "name": "zh_CN.json", "place": "../resources/lang/zh_CN.json"&#125; 现在，获取Json文件中的name值；1trans('*.name') 输出 “zh_CN.json”； 调用过程如下： 解析键名：将键名进行解析成数组 ($namespace = &#39;*&#39;, $group = &#39;*&#39;, $item = &#39;name&#39;)； 获取语言数组： 这里的$locale为null，所以返回的是默认与备用语言组成的数组，也就是[&#39;zh_CN&#39;, &#39;en&#39;]；并进行for循环，进入语言资源目录中寻找需要的元素值，如果找到，即 break； 加载资源：因为命名空间为*，且组也为*，这时会读取语言根目录下，名字为语言值的Json文件；此时会读取resource/lang/zh_CN.json，将读取的内容，进行保存 $this-&gt;loaded[$namespace][$group][$locale] = $lines; 获取资源，并替换参数：通过Arr::get方法从$this-&gt;loaded[$namespace][$group][$locale]中获取元素值”zh_CN.json”；此时，参数数组为空，直接返回结果 “zh_CN.json”； 运行时绑定资源资源的内容除了放在文件中，用到的时候在读取，也可以在项目运行时，存放；以resources/lang/zh_CN/validation.php为例，现在想要在运行时，给这个组添加一个新的元素叫 extra，需要指定放在哪个语言下，可以这样写1app('translator')-&gt;addLines(array('validation.extra' =&gt; '测试添加额外数据'), 'zh_CN'); 现在可以获取这个新添加的元素值1trans('validation.extra') 复数资源过滤笔者通过 运行时绑定资源 添加一条翻译内容：1app('translator')-&gt;addLines(array('validation.extra' =&gt; '&#123;0&#125;没有|[1,19]一些|[20,*]很多'), 'zh_CN'); 如果通过trans(&#39;validation.extra&#39;)，获取的就是整条翻译内容，不是我们所期望的；用choice方法： app(&#39;translator&#39;)-&gt;choice(&#39;validation.extra&#39;, 0) 得到 没有；app(&#39;translator&#39;)-&gt;choice(&#39;validation.extra&#39;, 18) 得到 一些；app(&#39;translator&#39;)-&gt;choice(&#39;validation.extra&#39;, 20) 得到 很多； 可以将app(&#39;translator&#39;)-&gt;choice(...)简写成全局帮助函数trans_choice(...)；]]></content>
      <categories>
        <category>Laravel</category>
      </categories>
      <tags>
        <tag>Laravel-5.4</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[认识 Memcached]]></title>
    <url>%2F2017%2F07%2F24%2Fnosql-memcached%2F</url>
    <content type="text"><![CDATA[简介Memcached是一个开源、免费、高性能的分布式对象缓存系统，通过减少对数据库的读取以提高Web应用的性能；Memcached基于一个存储键/值对的hashmap。其守护进程（daemon ）是用 C 写的，但是客户端可以用任何语言来编写，并通过memcached协议与守护进程通信。当某个服务器停止运行或崩溃了，所有存放在该服务器上的键/值对都将丢失。 Memcached的服务器端没有提供分布式功能，各个Memcached应用不会互相通信以共享信息。想要实现分布式通过，可以多搭建几个Memcached应用，通过算法实现此效果； Memcached里有两个重要概念： slab：为了防止内存碎片化，Memcached服务器端会预先将数据空间划分为一系列slab；举个例子，现在有一个100立方米的房间，为了合理规划这个房间放置东西，会在这个房间里放置 30 个 1 立方米的盒子、20 个 1.25 立方米的盒子、15 个 1.5 立方米的盒子…这些盒子就是slab； LRU：最近最少使用算法；当同一个slat的格子满了，这时需要新加一个值时，不会考虑将这个新数据放到比当前slat更大的空闲slat，而是使用LRU移除旧数据，放入这个新数据； 部署Memcached能够在大多数 Linux 和 类 BSD 系统上运行；官方没有给出Windows上安装Memcached的支持； 对于Debian / Ubuntu系统：1apt-get install memcached 对于Redhat / Fedora / CentOs系统：1yum install memcached 通过memcached -h查看帮助，同时也算是测试是否安装成功；如果遇到错误，可参考官方上的FAQ； 使用服务器端启动一个Memcached应用，常见的启动方式是这样的：开启一个memcached应用作守护进程，TCP连接，端口号是 11211；-u参数是运行Memcached应用的用户（这个参数也只有 root用户才能使用）；1memcached -u root -p 11211 -d -vvv 其他常见的参数也有 -m &lt;num&gt;：分配给Memcached应用使用的内存大小，默认是 64M； -l &lt;ip_addr&gt;：设置能访问Memcached应用的IP(默认：所有都允许；无论内外网或者本机更换IP，有安全隐患；若设置为127.0.0.1就只能本机访问)； -c &lt;num&gt;：设置最大运行的并发连接数，默认是 1024； -f &lt;factor&gt;：设置slat大小增长因子；默认是 1.25；比如说 10号slab大小是752，那么11号slab大小就是 752 * 1.25； 客户端Memcached客户端与服务器端的通信比较简单，使用的基于文本的协议，而不是二进制协议；因此可以通过telnet进行交互；1telnet [host] [port] 按下Ctrl + ]，并回车，即可回显； Storage命令set存储数据。如果set的key已经存在，该命令可以更新该key所对应的原来的数据，也就是实现更新的作用。详细命令指南可参考菜鸟教程 - Memcached set 命令； add只有在set的key不存在的情况下，才会存储数据；详细命令指南可参考菜鸟教程 - Memcached add 命令； replace只有在set的key存在的情况下，才会替换数据；详细命令指南可参考菜鸟教程 - Memcached replace 命令； append向已存在的元素值后追加数据；详细命令指南可参考菜鸟教程 - Memcached append 命令； prepend向已存在的元素值的头部追加数据；详细命令指南可参考菜鸟教程 - Memcached prepend 命令； cas命令用于执行一个”检查并设置”的操作。它仅在当前客户端最后一次取值后，该key 对应的值没有被其他客户端修改的情况下，才能够将值写入。检查是通过cas_token参数进行的， 这个参数是Memcach指定给已经存在的元素的一个唯一的 64 位值。详细命令指南可参考菜鸟教程 - Memcached cas 命令； Retrive命令get根据元素的键名获取值；详细命令指南可参考菜鸟教程 - Memcached get 命令； gets获取带有CAS令牌的数据值；详细命令指南可参考菜鸟教程 - Memcached gets 命令； delete删除已存在的元素；详细命令指南可参考菜鸟教程 - Memcached delete 命令； incr/decr对于已存在的键值进行自增或自减操作；详细命令指南可参考菜鸟教程 - Memcached incr/decr 命令； Statistics命令stats查看memcached所有的统计信息；详细命令指南可参考菜鸟教程 - Memcached stats 命令； stats items显示各个slab中item的数目和存储时长等其它信息；详细命令指南可参考菜鸟教程 - Memcached stats items 命令； stats slabs显示各个slab的信息，包括chunk的大小、数目、使用情况等。详细命令指南可参考菜鸟教程 - Memcached stats slabs 命令； stats sizes用于显示所有item的大小和个数。该信息返回两列，第一列是 item 的大小，第二列是 item 的个数。详细命令指南可参考菜鸟教程 - Memcached stats sizes 命令； flush_all清除所有缓存数据；详细命令指南可参考菜鸟教程 - Memcached flush_all 命令； 分布式算法取余算法根据服务器节点数的余数来进行分散，就是通过hash函数求得的Key的整数哈希值再除以服务器节点数并取余数来选择服务器。这种算法取余计算简单，分散效果好，但是缺点是如果某一台机器宕机，那么应该落在该机器的请求就无法得到正确的处理，这时需要将当掉的服务器从算法从去除，此时候会有 (N-1) / N 的服务器的缓存数据需要重新进行计算；如果新增一台机器，会有N / (N+1)的服务器的缓存数据需要进行重新计算。对于系统而言，这通常是不可接受的颠簸（因为这意味着大量缓存的失效或者数据需要转移）。 【本段内容摘自大脸猫的博客】 一致性哈希表现为一个封闭的圆环，圆环上的点分别代表0 ~ 2^32。各个memcached节点根据hash算法，分别占据圆环上的一个点，当某key进行存储操作，会针对key进行hash操作，hash后也是圆环上的一个点，那么这个key将被存储在顺时针方向的第一个节点上。 如上图：分配不均的节点，此时key将会被存储到节点C上。 此时，我们新增节点D，如下图。受影响的部分只有节点A~节点D中间的部分，这边分数据不会再映射到节点B上，而是映射到新增节点D上。减掉一个节点同理，只影响顺时针后面一个节点。 优点：动态的增删节点，服务器down机，影响的只是顺时针的下一个节点缺点：当服务器进行hash后值较为接近会导致在圆环上分布不均匀，进而导致key的分布、服务器的压力不均匀。若中间某一权重较大的serverdown机，命中率下降明显； 在一致性哈希算法的基础上引入虚拟节点 引入虚拟节点的思想，解决一致性hash算法分布不均导致负载不均的问题。一个真实节点对应若干个虚拟节点，当key被映射到虚拟节点上时，则被认为映射到虚拟节点所对应的真实节点上。 优点：引入虚拟节点的思想，每个物理节点对应圆环上若干个虚拟节点（比如200~300个），当keyhash到虚拟节点，就会存储到实际的物理节点上，有效的实现了负载均衡； 【本段内容摘自鱼我所欲也的“memcached学习 - 分布式算法”文章】 工作中常见的问题缓存雪崩现象缓存雪崩一般是由某个缓存节点失效，导致其他节点的缓存命中率下降，缓存中缺失的数据去数据库查询，短时间内，造成数据库服务器崩溃； 重启DB，短期又被压垮，但缓存数据也多一些；DB反复多次启动多次，缓存重建完毕，DB才稳定运行；或者，是由于缓存周期性的失效，比如每 6 小时失效一次，那么每 6 小时，将有一个请求“峰值”，严重者甚至会令DB崩溃； 缓存的无底洞现象（multiget-hole）该问题由 facebook 的工作人员提出的, facebook 在 2010 年左右，memcached节点就已经达3000 个.缓存数千 G 内容。 他们发现了一个问题，memcached 连接频率，效率下降了，于是加 memcached 节点，添加了后，发现因为连接频率导致的问题，仍然存在，并没有好转，称之为“无底洞现象”。 问题分析以用户为例: user-133-age， user-133-name，user-133-height …..N 个 key，当服务器增多，133 号用户的信息，也被散落在更多的节点，所以，同样是访问个人主页，得到相同的个人信息， 节点越多，要连接的节点也越多。 对于 memcached 的连接数，并没有随着节点的增多，而降低。 于是问题出现。 multiget-hole 解决方案把某一组key，按其共同前缀，来分布。比如 user-133-age， user-133-name，user-133-height 这 3 个 key，在用分布式算法求其节点时，应该以 ‘user-133’来计算，而不是以 user-133-age/name/height 来计算。 这样，3 个关于个人信息的 key，都落在同 1 个节点上，访问个人主页时，只需要连接 1 个节点。 永久数据被踢现象网上有人反馈为”memcached 数据丢失”，明明设为永久有效，却莫名其妙的丢失了。 分析原因： 如果 slab 里的很多 chunk，已经过期，但过期后没有被 get 过， 系统不知他们已经过期。 永久数据很久没 get 了， 不活跃， 如果新增 item，则永久数据被踢了。 当然，如果那些非永久数据被 get，也会被标识为 expire，从而不会再踢掉永久数据； 解决方案：永久数据和非永久数据分开放；]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>Memcached</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel 大将之 分页 模块]]></title>
    <url>%2F2017%2F06%2F13%2Flaravel-paginate%2F</url>
    <content type="text"><![CDATA[简介官方 API 地址 https://laravel.com/api/5.4/Illuminate/Pagination.html 分页模块的基本使用有两种：一种是基于查询构建器或Eloquent模型，调用paginate方法；另一种是手动创建分页器； Laravel框架的分页器不仅实现了数据的分页，而且支持生成Bootstrap的分页框，如下图所示 使用基于查询构建器或Eloquent模型从User表获取数据，每页16条，可以这样写123$users = DB::table('user')-&gt;paginate(16);// 或$users = User::paginate(16); 这时的$user是Illuminate\Pagination\LengthAwarePaginator实例；这里没有传递当前页的原因是，如果不传递，会从$request请求获取当前页；paginate方法完整参数定义如下：1paginate($perPage = null, $columns = ['*'], $pageName = 'page', $page = null) 其中 $perPage 代表每页显示数目， $columns 代表查询字段， $pageName 代表页码名称， $page 代表第几页。 同理，也可以获取另一种分页，简单分页123$users = DB::table('user')-&gt;simplePaginate(16);// 或$users = User::simplePaginate(16); 这时的$user是Illuminate\Pagination\Paginator实例； 要想在页面呈现分页器的小方块， 只要在blade.php 中书写1&#123;!! $users-&gt;render() !!&#125; 手动创建通过看看Laravel的Database是怎么实现创建分页器，更好地学会使用手动创建；先看看paginate方法，1234567891011121314151617public function paginate($perPage = null, $columns = ['*'], $pageName = 'page', $page = null) &#123; // 获取当前页数 $page = $page ?: Paginator::resolveCurrentPage($pageName); // 获取每页的数量 $perPage = $perPage ?: $this-&gt;model-&gt;getPerPage(); // Collection类，存放当前页的数据记录 $results = ($total = $this-&gt;toBase()-&gt;getCountForPagination()) ? $this-&gt;forPage($page, $perPage)-&gt;get($columns) : $this-&gt;model-&gt;newCollection(); return new LengthAwarePaginator($results, $total, $perPage, $page, [ // 当前页面的 url 'path' =&gt; Paginator::resolveCurrentPath(), 'pageName' =&gt; $pageName, ]); &#125; 再看看simplePaginate方法1234567891011121314151617public function simplePaginate($perPage = null, $columns = ['*'], $pageName = 'page', $page = null)&#123; // 获取当前页数 $page = $page ?: Paginator::resolveCurrentPage($pageName); // 获取每页的数量 $perPage = $perPage ?: $this-&gt;model-&gt;getPerPage(); // 调用 Database 模块当前类的方法，获取当前页的数据； // 下面这个语句只是设置查询条件，get 方法调用时才是真正去获取 $this-&gt;skip(($page - 1) * $perPage)-&gt;take($perPage + 1); return new Paginator($this-&gt;get($columns), $perPage, $page, [ // 当前页面的 url 'path' =&gt; Paginator::resolveCurrentPath(), 'pageName' =&gt; $pageName, ]); &#125; 看看源代码服务提供者 ServiceProviderboot方法1234567891011121314public function boot()&#123; // 注册包视图 $this-&gt;loadViewsFrom(__DIR__.'/resources/views', 'pagination'); // 如果程序是在命令行下运行，则将模块内的`resources/views`文件夹下的文件 // 发布一份到项目的`views/vendor/pagination`文件夹； // publishes 方法的第二个参数是 group 组； if ($this-&gt;app-&gt;runningInConsole()) &#123; $this-&gt;publishes([ __DIR__.'/resources/views' =&gt; $this-&gt;app-&gt;resourcePath('views/vendor/pagination'), ], 'laravel-pagination'); &#125;&#125; register方法1234567891011121314151617181920212223public function register()&#123; // 绑定 view 视图解析器 Paginator::viewFactoryResolver(function () &#123; return $this-&gt;app['view']; &#125;); // 绑定 url 路径解析器，返回当前 url Paginator::currentPathResolver(function () &#123; return $this-&gt;app['request']-&gt;url(); &#125;); // 绑定 当前页 解析器，返回当前页 Paginator::currentPageResolver(function ($pageName = 'page') &#123; $page = $this-&gt;app['request']-&gt;input($pageName); if (filter_var($page, FILTER_VALIDATE_INT) !== false &amp;&amp; (int) $page &gt;= 1) &#123; return $page; &#125; return 1; &#125;);&#125; 分页器类有两个Paginator和LengthAwarePaginator，都继承了父类AbstractPaginator;两者的主要区别主要在于render方法，也就是呈现的bootstrap风格的分页器不一样； Paginator的分页器，只有上一页和下一页的图标 LengthAwarePaginator的分页器]]></content>
      <categories>
        <category>Laravel</category>
      </categories>
      <tags>
        <tag>Laravel-5.4</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel 大将之 Redis 模块]]></title>
    <url>%2F2017%2F06%2F07%2Flaravel-redis%2F</url>
    <content type="text"><![CDATA[简介官方 API 地址 https://laravel.com/api/5.4/Illuminate/Redis.html Redis模块负责与Redis数据库交互，并提供Redis的相关API支持； Redis模块提供redis与redis.connection这两个服务；redis.connection服务提供redis连接对象；redis服务提供Illuminate\Redis\RedisManager对象，负责与Redis打交道的这部分管理工作； 配置项以下是笔者的示例；default是默认的Redis连接对象名，值是连接对象的参数；app(&#39;redis.connection&#39;)返回的就是该默认连接对象； mydefine是笔者定义的Redis连接对象名；通过执行app(&#39;redis&#39;)-&gt;connection(&#39;mydefine&#39;)可以获取该连接对象； mycluster1是笔者定义的Redis集群对象名；通过执行app(&#39;redis&#39;)-&gt;connection(&#39;mycluster1&#39;)可以获取该集群对象； 12345678910111213141516171819202122232425262728293031323334353637'redis' =&gt; [ 'client' =&gt; 'predis', 'default' =&gt; [ 'host' =&gt; env('REDIS_HOST', '127.0.0.1'), 'password' =&gt; env('REDIS_PASSWORD', null), 'port' =&gt; env('REDIS_PORT', 6379), 'database' =&gt; 0, ], 'mydefine' =&gt; [ 'host' =&gt; env('REDIS_HOST', '127.0.0.1'), 'password' =&gt; env('REDIS_PASSWORD', null), 'port' =&gt; env('REDIS_PORT', 6379), 'database' =&gt; 4, ], 'clusters' =&gt; [ 'mycluster1' =&gt; [ [ 'host' =&gt; env('REDIS_HOST', '127.0.0.1'), 'password' =&gt; env('REDIS_PASSWORD', null), 'port' =&gt; env('REDIS_PORT', 6379), 'database' =&gt; 1, ], [ 'host' =&gt; env('REDIS_HOST', '127.0.0.1'), 'password' =&gt; env('REDIS_PASSWORD', null), 'port' =&gt; env('REDIS_PORT', 6379), 'database' =&gt; 2, ], [ 'host' =&gt; env('REDIS_HOST', '127.0.0.1'), 'password' =&gt; env('REDIS_PASSWORD', null), 'port' =&gt; env('REDIS_PORT', 6379), 'database' =&gt; 3, ], ], ], ], 使用简单入门级操作普通 set / get 操作； set操作，如果键名存在，则会覆盖原有的值；123$redis = app('redis.connection');$redis-&gt;set('library', 'predis'); // 存储 key 为 library， 值为 predis 的记录；$redis-&gt;get('library'); // 获取 key 为 library 的记录值 set / get多个 key-value1234567$mkv = array( 'usr:0001' =&gt; 'First user', 'usr:0002' =&gt; 'Second user', 'usr:0003' =&gt; 'Third user');$redis-&gt;mset($mkv); // 存储多个 key 对应的 value$retval = $redis -&gt; mget (array_keys( $mkv)); //获取多个key对应的value 存放带存储时效的记录1$redis-&gt;setex('library', 10, 'predis'); // 存储 key 为 library， 值为 predis 的记录, 有效时长为 10 秒 add操作,不会覆盖已有值12$redis-&gt;setnx('foo', 12) ; // 返回 true ， 添加成功$redis-&gt;setnx('foo', 34) ; // 返回 false， 添加失败，因为已经存在键名为 foo 的记录 set的变种，结果返回替换前的值1$redis-&gt;getset('foo', 56) ; // 返回 34； 如果之前不存在记录，则返回 null incrby/incr/decrby/decr 对值的递增和递减12$redis-&gt;incr('foo') ; // 返回 57，同时 foo 的值为 57$redis-&gt;incrby('foo', 2 ) ; // 返回 59，同时 foo 的值为 59 检测是否存在值1$redis-&gt;exists('foo'); 删除1$redis-&gt;del('foo'); // 成功删除返回 true, 失败则返回 false type类型检测，字符串返回 string，列表返回 list，set 表返回 set/zset，hash 表返回 hash；1$redis-&gt;type('foo'); append 连接到已存在字符串12$redis-&gt;get('str'); // 返回 test$redis-&gt;append('str', '_123'); // 返回累加后的字符串长度 8,此时 str 为 'test_123' setrange 部分替换操作, 并返回字符串长度12$redis-&gt;setrange('str', 0, 'abc'); // 返回 3, 第2个参数为 0 时等同于 set 操作$redis-&gt;setrange('str', 2, 'cd'); // 返回 4, 表示从第2个字符后替换，这时 'str' 为 'abcd' substr 部分获取操作1$redis-&gt;substr('str', 0, 2); // 返回'abc'; 表示从第 0 个起，取到第 2 个字符 strlen 获取字符串长度1$redis-&gt;strlen ('str'); // 返回 4; 此时 'str' 为 'abcd' setbit位存储1$redis-&gt;setbit('binary', 31, 1); //表示在第31位存入1,这边可能会有大小端问题?不过没关系, getbit 应该不会有问题 getbit位获取1$redis-&gt;getbit('binary', 31); //返回1 keys 模糊查找功能,支持 * 号以及 ? 号 (匹配一个字符)1234$redis-&gt;set('foo1', 123);$redis-&gt;set('foo2', 456);$redis-&gt;keys('foo*'); // 返回 foo1 和 foo2 的 array$redis-&gt;keys('f?o?'); // 同上 randomkey随机返回一个key1$redis-&gt;randomkey() ; // 可能是返回 'foo1' 或者是 'foo2' 及其它任何已存在的 key rename/renamenx方法对key进行改名，所不同的是renamenx不允许改成已存在的key1$redis-&gt;rename('str', 'str2'); // 把原先命名为'str'的 key 改成了 'str2' expire 设置 key-value 的时效性ttl 获取剩余有效期persist 重新设置为永久存储123$redis-&gt;expire('foo', 10); // 设置有效期为 10 秒$redis-&gt;ttl('foo'); // 返回剩余有效期值 10 秒$redis-&gt;persisit('foo'); // 取消 expire 行为 dbsize 返回redis当前数据库的记录总数1$redis-&gt;dbsize() ; 队列操作rpush/rpushx 有序列表操作,从队列后插入元素；lpush/lpushx 和 rpush/rpushx 的区别是插入到队列的头部,同上,’x’含义是只对已存在的 key 进行操作123$redis-&gt;rpush('fooList', 'bar1'); // 返回列表长度 1$redis-&gt;lpush('fooList', 'bar0'); // 返回列表长度 2$redis-&gt;rpushx('fooList', 'bar2'); // 返回 3, rpushx只对已存在的队列做添加,否则返回 0 llen返回当前列表长度1$redis-&gt;llen('fooList'); // 返回 3 lrange 返回队列中一个区间的元素12$redis-&gt;lrange ('fooList', 0, 1); // 返回数组包含第 0 个至第 1 个, 共2个元素$redis-&gt;lrange ('fooList', 0, -1); //返回第0个至倒数第一个, 相当于返回所有元素 lindex 返回指定顺序位置的 list 元素1$redis-&gt;lindex('fooList', 1) ; // 返回'bar1' lset 修改队列中指定位置的value1$redis-&gt;lset('fooList', 1, '123'); // 修改位置 1 的元素, 返回 true lrem 删除队列中左起指定数量的字符1$redis-&gt;lrem('fooList', 1, '_') ; // 删除队列中左起(右起使用-1) 1个 字符'_'(若有) lpop/rpop 类似栈结构地弹出(并删除)最左或最右的一个元素12$redis-&gt;lpop('fooList') ; // 返回 'bar0'$redis-&gt;rpop('fooList') ; // 返回 'bar2' ltrim队列修改，保留左边起若干元素，其余删除1$redis-&gt;ltrim('fooList', 0, 1) ; // 保留左边起第 0 个至第 1 个元素 rpoplpush 从一个队列中 pop 出元素并 push 到另一个队列123456$redis-&gt;rpush('list1', 'ab0');$redis-&gt;rpush('list1', 'ab1');$redis-&gt;rpush('list2', 'ab2');$redis-&gt;rpush('list2', 'ab3');$redis-&gt;rpoplpush('list1', 'list2'); // 结果list1 =&gt;array('ab0'), list2 =&gt;array('ab1','ab2','ab3')$redis-&gt;rpoplpush('list2', 'list2'); // 也适用于同一个队列, 把最后一个元素移到头部 list2 =&gt;array('ab3','ab1','ab2') linsert在队列的中间指定元素前或后插入元素12$redis-&gt;linsert('list2', 'before', 'ab1', '123'); //表示在元素 'ab1' 之前插入 '123'$redis-&gt;linsert('list2', 'after', 'ab1', '456'); //表示在元素 'ab1' 之后插入 '456' blpop/brpop 阻塞并等待一个列队不为空时，再pop出最左或最右的一个元素（这个功能在php以外可以说非常好用）1$redis-&gt;blpop('list3', 10) ; // 如果 list3 为空则一直等待,直到不为空时将第一元素弹出, 10 秒后超时 set 集合操作sadd增加set集合元素， 返回true， 重复返回false123$redis-&gt;sadd('set1', 'ab');$redis-&gt;sadd('set1', 'cd');$redis-&gt;sadd('set1', 'ef'); srem 移除指定元素1$redis-&gt;srem('set1', 'cd'); // 删除'cd'元素 spop 弹出首元素1$redis-&gt;spop('set1'); // 返回 'ab' smove 移动当前set集合的指定元素到另一个set集合12$redis-&gt;sadd('set2', '123');$redis-&gt;smove('set1', 'set2', 'ab'); // 移动'set1'中的'ab'到'set2', 返回true or false；此时 'set1'集合不存在 'ab' 这个值 scard 返回当前set表元素个数1$redis-&gt;scard('set2'); // 返回 2 sismember 判断元素是否属于当前set集合1$redis-&gt;sismember('set2', '123'); // 返回 true or false smembers 返回当前set集合的所有元素1$redis-&gt;smembers('set2'); // 返回 array('123','ab') sinter/sunion/sdiff 返回两个表中元素的交集/并集/补集12$redis-&gt;sadd('set1', 'ab') ;$redis-&gt;sinter('set2', 'set1') ; //返回array('ab') sinterstore/sunionstore/sdiffstore 将两个表交集/并集/补集元素 copy 到第三个表中123$redis-&gt;set('foo', 0);$redis-&gt;sinterstore('foo', 'set1'); // 等同于将'set1'的内容copy到'foo'中，并将'foo'转为set表$redis-&gt;sinterstore('foo', array('set1', 'set2')); // 将'set1'和'set2'中相同的元素 copy 到'foo'表中, 覆盖'foo'原有内容 srandmember 返回表中一个随机元素1$redis-&gt;srandmember('set1') ; 有序set表操作sadd 增加元素，并设置序号，成功返回true，重复返回false123$redis-&gt;zadd('zset1', 1, 'ab');$redis-&gt;zadd('zset1', 2, 'cd');$redis-&gt;zadd('zset1', 3, 'ef'); zincrby 对指定元素索引值的增减,改变元素排列次序1$redis -&gt; zincrby ( 'zset1' , 10 , 'ab' ) ; //返回11 zrem 移除指定元素1$redis-&gt;zrem('zset1', 'ef'); // 返回 true or false zrange 按位置次序返回表中指定区间的元素12$redis-&gt;zrange('zset1', 0, 1); // 返回位置 0 和 1 之间(两个)的元素$redis-&gt;zrange('zset1', 0, -1); // 返回位置 0 和倒数第一个元素之间的元素(相当于所有元素) zrevrange 同上,返回表中指定区间的元素,按次序倒排1$redis-&gt;zrevrange('zset1', 0, -1); // 元素顺序和zrange相反 zrangebyscore/zrevrangebyscore 按顺序/降序返回表中指定索引区间的元素12345$redis-&gt;zadd('zset1', 3, 'ef');$redis-&gt;zadd('zset1', 5, 'gh');$redis-&gt;zrangebyscore('zset1', 2, 9); //返回索引值2-9之间的元素 array('ef','gh')$redis-&gt;zrangebyscore('zset1', 2, 9, 'withscores'); // 返回索引值2-9之间的元素并包含索引值 array(array('ef',3),array('gh',5))$redis-&gt;zrangebyscore('zset1', 2, 9, array('withscores'=&gt;true, 'limit'=&gt;array(1, 2))); //返回索引值2-9之间的元素,'withscores' =&gt;true表示包含索引值; 'limit'=&gt;array(1, 2),表示偏移1条，返回2条,结果为array(array('ef',3),array('gh',5)) zunionstore/zinterstore 将多个表的并集/交集存入另一个表中123$redis-&gt;zunionstore('zset3', array('zset1', 'zset2', 'zset0')); //将'zset1','zset2','zset0'的并集存入'zset3'$redis-&gt;zunionstore('zset3', array('zset1', 'zset2'), array('weights' =&gt; array(2, 1))); //weights参数表示权重，其中表示并集后 zset1集合的分 * 2 后存储到 zset3 集合， zset2集合的分 * 1 后存储到 zset3 集合$redis-&gt;zunionstore('zset3', array('zset1', 'zset2'), array('aggregate' =&gt; 'max')); //'aggregate' =&gt; 'max'或'min'表示并集后相同的元素是取大值或是取小值 zcount 统计一个索引区间的元素个数12$redis-&gt;zcount('zset1', 3, 5); // 返回 2$redis-&gt;zcount('zset1', '(3', 5)); //'(3'表示索引值在3-5之间但不含3,同理也可以使用'(5'表示上限为5但不含5 zcard 统计元素个数1$redis-&gt;zcard('zset1'); // 返回 4 zscore 查询元素的索引1$redis-&gt;zscore('zset1', 'ef'); // 返回 3 zremrangebyscore 删除一个索引区间的元素1$redis-&gt;zremrangebyscore('zset1', 0, 2); // 删除索引在0-2之间的元素('ab','cd'), 返回删除元素个数2 zrank/zrevrank 返回元素所在表顺序/降序的位置(不是索引)1$redis-&gt;zrank('zset1', 'ef'); // 返回0,因为它是第一个元素；zrevrank则返回1(最后一个) zremrangebyrank 删除表中指定位置区间的元素1$redis-&gt;zremrangebyrank('zset1', 0, 10); //删除位置为0-10的元素,返回删除的元素个数2 Hash表操作hset/hget 存取hash表的数据123$redis-&gt;hset('hash1', 'key1', 'v1'); //将key为'key1' value为'v1'的元素存入hash1表$redis-&gt;hset('hash1', 'key2', 'v2');$redis-&gt;hget('hash1', 'key1'); //取出表'hash1'中的key 'key1'的值,返回'v1' hexists 返回hash表中的指定key是否存在1$redis-&gt;hexists('hash1', 'key1') ; //true or false hdel 删除hash表中指定key的元素1$redis-&gt;hdel('hash1', 'key2') ; //true or false hlen 返回hash表元素个数1$redis-&gt;hlen('hash1'); // 返回 1 hsetnx 增加一个元素,但不能重复12$redis-&gt;hsetnx('hash1', 'key1', 'v2') ; // false$redis-&gt;hsetnx('hash1', 'key2', 'v2') ; // true hmset/hmget 存取多个元素到hash表12$redis-&gt;hmset('hash1', array('key3' =&gt; 'v3', 'key4' =&gt; 'v4')); $redis-&gt;hmget('hash1', array('key3', 'key4')); // 返回相应的值 array('v3','v4') hincrby 对指定key进行累加12$redis-&gt;hincrby('hash1', 'key5', 3); // 不存在，则存储并返回 3；存在，即返回 原有值 + 3；$redis-&gt;hincrby('hash1', 'key5', 10); // 返回13 hkeys 返回hash表中的所有key1$redis-&gt;hkeys('hash1'); // 返回array('key1', 'key2', 'key3', 'key4', 'key5') hvals 返回hash表中的所有value1$redis-&gt;hvals('hash1'); // 返回 array('v1','v2','v3','v4',13) hgetall 返回整个hash表元素1$redis-&gt;hgetall('hash1'); // 返回 array('key1'=&gt;'v1','key2'=&gt;'v2','key3'=&gt;'v3','key4'=&gt;'v4','key5'=&gt;13) 排序操作sort 排序12345678$redis-&gt;rpush('tab', 3);$redis-&gt;rpush('tab', 2);$redis-&gt;rpush('tab', 17);$redis-&gt;sort('tab'); // 返回 array(2,3,17)// 使用参数,可组合使用 array('sort' =&gt; 'desc','limit' =&gt; array(1, 2))$redis-&gt;sort('tab', array('sort' =&gt; 'desc')); // 降序排列，返回 array(17,3,2)$redis-&gt;sort('tab', array('limit' =&gt; array(1, 2))); //返回顺序位置中1的元素2个(这里的2是指个数,而不是位置)，返回array(3,17) 123$redis-&gt;sort('tab', array('limit' =&gt; array('alpha' =&gt; true))); //按首字符排序返回array(17,2,3)，因为17的首字符是'1'所以排首位置$redis-&gt;sort('tab', array('limit' =&gt; array('store' =&gt; 'ordered'))); //表示永久性排序，返回元素个数$redis-&gt;sort('tab', array('limit' =&gt; array('get' =&gt; 'pre_*'))); //使用了通配符'*'过滤元素，表示只返回以'pre_'开头的元素 Redis管理操作info 显示服务当状态信息1$redis-&gt;info(); select 指定要操作的数据库1$redis-&gt;select(4); // 指定数据库的下标 flushdb 清空当前库1$redis-&gt;flushdb(); move 移动当库的元素到其它数据库12$redis-&gt;set('tomove', 'bar');$redis-&gt;move('tomove', 4); slaveof 配置从服务器12$redis-&gt;slaveof('127.0.0.1', 80); // 配置 127.0.0.1 端口 80 的服务器为从服务器$redis-&gt;slaveof(); // 清除从服务器 同步保存服务器数据到磁盘1$redis-&gt;save(); 异步保存服务器数据到磁盘1$redis-&gt;bgsave (); 返回最后更新磁盘的时间1$redis-&gt;lastsave(); 集群1// 等待探索 订阅可以阅读Laravel 的 Redis 使用指南中关于发布与订阅的章节，了解使用过程； 订阅和发布本质上是一种监听触发；订阅功能可以监听指定频道的消息，基于长连接的通信，完成信息接收；而发布则是触发监听的开始； 说明：上述涉及操作代码均来自利用predis操作redis方法大全文章；]]></content>
      <categories>
        <category>Laravel</category>
      </categories>
      <tags>
        <tag>Laravel-5.4</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel 大将之 配置 模块]]></title>
    <url>%2F2017%2F06%2F04%2Flaravel-config%2F</url>
    <content type="text"><![CDATA[简介官方 API 地址 https://laravel.com/api/5.4/Illuminate/Config.html Laravel的配置管理模块统一管理项目所需的配置，包括插件所需的配置，从而为容器服务提供支持； 根据src/Illuminate/Foundation/Bootstrap/LoadConfiguration.php文件,可以看出Lavavel的配置加载流程如下： 判断是否存在配置缓存文件（位于项目根目录下的bootstrap/cache/config.php）, 如果存在，则读取缓存文件内容，并生成Illuminate\Config\Repository实例，在服务容器绑定config服务； 如果不存在缓存文件，则先生成Illuminate\Config\Repository实例，在服务容器绑定config服务，再遍历项目根目录下的config文件，保存其配置数据内容； 使用 生成配置缓存文件；通过artisan命令，在项目根目录下执行 1php artisan config:cache 清空配置缓存文件 1php artisan config:clear 读取配置内容；比如读取config/app.php文件的locale参数;调用全局帮助函数，直接从Illuminate\Config\Repository实例中获取参数值； 1config('app.locale');]]></content>
      <categories>
        <category>Laravel</category>
      </categories>
      <tags>
        <tag>Laravel-5.4</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel 大将之 加密 模块]]></title>
    <url>%2F2017%2F06%2F03%2Flaravel-encrypt%2F</url>
    <content type="text"><![CDATA[简介加密模块包含两种加密方式，分别为Encrypt加密与Hash加密； Encrypt加密将目标文本转换成具有不同长度的、可逆的密文；Hash加密将目标文本转换成具有相同长度的、不可逆的杂凑字符串； 在应用程序中使用哪一种加密方式取决于业务需求，基本原则如下：如果被保护数据仅仅用作比较验证，在以后不需要还原成明文形式，则使用Hash加密；如果被保护数据在以后需要被还原成明文，则需要使用Encrypt加密。 官方 API 地址 https://laravel.com/api/5.4/Illuminate/Encryption.html https://laravel.com/api/5.4/Illuminate/Hashing.html 使用Encrypt加密创建实例 最方便的方式，从服务容器取Encrypt加密对象；Encrypt加密对象的key密钥及cipher加密算法参数均读取config/app.php配置文件中的key及cipher值； 1$encrypter = app('encrypter'); 手动创建；Encrypt加密构造函数的第一个参数是密钥，第二个参数是加密算法类型，默认是’AES-128-CBC’；密钥的长度与加密算法类型有关联，’AES-128-CBC’算法的密钥长度是16位，’AES-256-CBC’算法的密钥长度是32位； 123$encrypter = new Illuminate\Encryption\Encrypter(random_bytes(16));$encrypter = new Illuminate\Encryption\Encrypter(random_bytes(16), 'AES-128-CBC');$encrypter = new Illuminate\Encryption\Encrypter(random_bytes(32), 'AES-256-CBC'); 加密调用Encrypt加密实例的encrypt方法对指定对象进行加密；encrypt方法有两个参数，第一个参数是加密的目标对象，第二个参数是布尔值，表示是否对第一个参数进行序列化操作；1$encrypter-&gt;encrypt('foo'); 如果是加密字符串类型的对象，可以调用encryptString方法；encryptString方法只有一个参数，即字符串对象；1$encrypter-&gt;encryptString('foo'); 解密调用Encrypt加密实例的decrypt方法对指定对象进行解密；decrypt方法有两个参数，第一个参数是解密的目标对象，第二个参数是布尔值，表示是否对第一个参数进行序列化操作；1$encrypter-&gt;decrypt($encrypter-&gt;encrypt('foo')); 与encryptString方法对应的是decryptString方法；1$encrypter-&gt;decryptString($encrypter-&gt;encryptString('foo')); Hash加密创建实例 最方便的方式，从服务容器取Hash加密对象； 1$hasher = app('hash'); 手动创建； 1$hasher = new \Illuminate\Hashing\BcryptHasher; 加密调用Hash加密对象的make方法；1$hasher-&gt;make('password'); 也可以调用全局帮助函数bcrypt1bcrypt('password'); 较验因为哈希加密是不可逆的，所以要想判断是否值相等，可以调用check方法；check方法的本质是将传入值也进行哈希加密，判断加密后的字符串是否相同；1$hasher-&gt;check('password', $hasher-&gt;make('password'));]]></content>
      <categories>
        <category>Laravel</category>
      </categories>
      <tags>
        <tag>Laravel-5.4</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel 大将之 日志 模块]]></title>
    <url>%2F2017%2F06%2F01%2Flaravel-log%2F</url>
    <content type="text"><![CDATA[简介Laravel的日志模块位于Illuminate/Log文件夹下；通过封装Monolog插件提供日志服务； 官方 API 地址 https://laravel.com/api/5.4/Illuminate/Log.html 配置配置文件在config/app.php文件中关于日志模块的配置项有两个，分别如下： 1234 // 日志模式，可选择参数有 "single", "daily", "syslog", "errorlog"'log' =&gt; env('APP_LOG', 'single'), // 错误等级，为 "RFC 5424" 中定义的八种日志级'log_level' =&gt; env('APP_LOG_LEVEL', 'debug'), 日志模式不同的参数值有不同的含义： single所有日志信息都会输出到storage/log/laravel.log文件中 daily每天的日志信息都会输出到storage/log文件夹下的日志文件中，日志文件名会包含当天的年月日信息； syslog日志信息输出到系统的日志文件中；比如，笔者是centos系统，日志信息写到了/var/log/message文件中 errorlog相当于调用PHP的error_log语句，没有写入到文件 八种日志错误等级分别为： 错误等级 描述 整型值 应用场景 debug 代码引用为 “MonologLogger::DEBUG” 100 紧急，如系统挂掉 info 代码引用为 “MonologLogger::INFO” 200 需要立即采取行动，如数据库异常等 notice 代码引用为 “MonologLogger::NOTICE” 250 严重问题，如异常 warning 代码引用为 “MonologLogger::WARNING” 300 运行时错误，不需要立即处理但需要被记录和监控 error 代码引用为 “MonologLogger::ERROR” 400 警告但不是错误，比如使用了被废弃的API critical 代码引用为 “MonologLogger::CRITICAL” 500 普通但值得注意的事件 alert 代码引用为 “MonologLogger::ALERT” 550 感兴趣的事件，比如登录、退出 emergency 代码引用为 “MonologLogger::EMERGENCY” 600 详细的调试信息 如果log_level的值为critical, 则日志只会输出alert和emergency这两种错误等级的信息； 自定义配置如果你想要在应用中完全控制Monolog的配置，可以使用应用的configureMonologUsing方法；在bootstrap/app.php文件返回$app变量之前调用该方法;比如，使用daily日志模式，但日志文件名想自定义，可以如下：123456$app-&gt;configureMonologUsing(function(Monolog\Logger $log) &#123; $filename = storage_path('/logs/' . php_sapi_name() . '.log'); $handler = new Monolog\Handler\RotatingFileHandler($filename, 0, \Monolog\Logger::DEBUG, true, 0664); $handler-&gt;setFormatter(new \Monolog\Formatter\LineFormatter(null, null, true, true)); $log-&gt;pushHandler($handler); &#125;); 使用日志记录 创建日志器实例 直接创建Writer实例，日志器实例还需要设置日志模式与错误等级; 12$writer = new Illuminate\Log\Writer(new Monolog\Logger('channel_name'));$writer-&gt;useErrorLog('info'); 或者通过全局帮助函数，从服务容器获取实例;日志模式与错误等级已按照配置文件中的参数设置好了； 1$writer = app('log'); 还有一种直接通过门面模式\Log;比如要输出debug级信息，执行\Log::debug(&#39;xxxx&#39;); 输出各种类型信息 123456789101112$writer-&gt;emergency('消息内容', ['上下文环境，比如用户ID' =&gt; '这里显示用户ID的值，比如78']);$writer-&gt;alert('消息内容');$writer-&gt;critical('消息内容');$writer-&gt;error('消息内容');$writer-&gt;warning('消息内容');$writer-&gt;notice('消息内容');$writer-&gt;info('消息内容');$writer-&gt;debug('消息内容');$writer-&gt;log('emergency', '消息内容'， ['上下文' =&gt; '环境']);$writer-&gt;log('alert', '消息内容'， ['上下文' =&gt; '环境']);...... 事件监听每次执行日志输出信息时，如果日志器包含事件分发器（即event dispatcher），则会触发\Illuminate\Log\Events\MessageLogged::class这个事件； \Illuminate\Log\Events\MessageLogged::class这个事件的构造函数如下：12345public function __construct($level, $message, array $context = []) &#123; $this-&gt;level = $level; $this-&gt;message = $message; $this-&gt;context = $context;&#125; 首先如何为日志器设置事件分发器，有两处，第一处是构造函数的第二个参数，可以传入事件分发器实例；第二处是通过调用setEventDispatcher方法；Laravel在服务容器注册绑定的日志器，带有事件分发器； 现在，需要为日志写入事件安排一些监听器，通过调用listen方法，比如: 1234$dispatcher = $writer-&gt;getEventDispatcher();$dispatcher-&gt;listen(\Illuminate\Log\Events\MessageLogged::class, function ($event) &#123; // 监听器的内容&#125;);]]></content>
      <categories>
        <category>Laravel</category>
      </categories>
      <tags>
        <tag>Laravel-5.4</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[刨刨 Carbon API]]></title>
    <url>%2F2017%2F05%2F23%2Fphp-carbon%2F</url>
    <content type="text"><![CDATA[介绍Carbon是对PHP DateTime模块的二次扩展；提供时间格式化，时间计算的功能； 官方主页为 http://carbon.nesbot.com/; Github地址为 https://github.com/briannesbitt/Carbon; 文件结构 目录 描述 – src Carbon源文件 – src\Carbon Carbon源文件 – src\Carbon\CarbonInterval.php DateInterval类的二次扩展类CarbonInterval；主要用于时差计算； – src\Carbon\Carbon.php DateTime类的二次扩展类Carbon；提供时间计算，格式化输出的功能； – src\Carbon\Exceptions 自定义异常文件夹 – src\Carbon\Lang 语言本地化文件夹；Carbon类的diffForHumans方法会用到； – tests Carbon测试用例文件 – tests\AbstractTestCase.php 所有测试文件的父类；提供了执行前初始化和执行后清理的功能, 及其它公共的API； – tests\Carbon 针对src\\Carbon\\Carbon.php的测试用例组 – tests\CarbonInterval 针对src\\Carbon\\CarbonInterval.php的测试用例组 – tests\Localization 针对src\\Carbon\\Lang的测试用例组 API 细则本篇涉及 API 为 Carbon 1.22.1 版本； Carbon用途：生成Carbon实例 方法名 参数 描述 __construct $time(null), $tz(null) 根据格式化时间字符串和指定时区, 创建Carbon实例 instance（static） DateTime $dt 根据 DateTime实例创建Carbon实例 parse（static） $time(null), $tz(null) 根据格式化时间字符串和指定时区, 创建Carbon实例 create（static） $year(null), $month(null), $day(null), $hour(null), $minute(null), $second(null), $tz(null) 根据日期和时间创建Carbon实例 如果指定参数为null，会默认使用当前时间的对应值 createSafe（static） $year(null), $month(null), $day(null), $hour(null), $minute(null), $second(null), $tz(null) 根据日期和时间创建Carbon实例 如果指定参数为null，会默认使用当前时间的对应值; 指定参数不符合规范，会返回异常； createFromDate（static） $year(null), $month(null), $day(null), $tz(null) 根据日期创建Carbon实例如果指定参数为null，会默认使用当前时间的对应值 createFromTime（static） $hour(null), $minute(null), $minute(null), $tz(null) 根据时间创建Carbon实例如果指定参数为null，会默认使用当前时间的对应值 createFromFormat（static） $format, $time, $tz（null） 根据时间字符串及其对应的format字符串创建Carbon实例 createFromTimestamp（static） $timestamp, $tz(null) 根据时间戳和指定时区, 创建Carbon实例 createFromTimestampUTC（static） $timestamp 根据时间戳和utc时区, 创建Carbon实例 now（static） $tx(null) 根据当前时间创建Carbon实例 today（static） $tx(null) 根据当前时间创建Carbon实例，时间重置为 0时0分0秒 tomorrow（static） $tx(null) 根据当前时间，加一天，创建Carbon实例 yesterday（static） $tx(null) 根据当前时间， 减一天， 创建Carbon实例 minValue（static） 创建系统支持的最小时间，并返回Carbon实例 maxValue（static） 创建系统支持的最大时间，并返回Carbon实例 copy 复制当前Carbon实例 fromSerialized（static） $value 解析序列化字符串，创建Carbon实例 用途：修改Carbon实例 方法名 参数 描述 setDate $year, $month, $day 设置当前实例的年，月，日 setDateTime $year, $month, $day, $hour, $minute, $second(0) 设置当前实例的年，月，日，时，分，秒 setTimeFromTimeString $time 根据 H:i:s 字符串设置当前实例时间 timestamp $value 根据时间戳设置当前实例时间 second $value 设置当前实例时间指定秒 minute $value 设置当前实例时间指定分钟 hour $value 设置当前实例时间指定小时 day $value 设置当前实例时间指定天 month $value 设置当前实例时间指月份 year $value 设置当前实例时间指定年份 startOfDay 重置当前实例时间为 0时0分0秒 endOfDay 重置当前实例时间为 23时59分59秒 startOfWeek 重置当前实例时间为 本周的第一天，同时设置 0时0分0秒 endOfWeek 重置当前实例时间为 本周的最后一天，同时设置 23时59分59秒 startOfMonth 重置当前实例时间为 本月第一天，同时设置 0时0分0秒 endOfMonth 重置当前实例时间为 本月最后一天，同时设置 23时59分59秒 startOfQuarter 重置当前实例时间为 本季度第一天，同时设置 0时0分0秒 endOfQuarter 重置当前实例时间为 本季度最后一天，同时设置 23时59分59秒 startOfYear 重置当前实例时间为 本年第一天，同时设置 0时0分0秒 endOfYear 重置当前实例时间为 本年最后一天，同时设置 23时59分59秒 startOfDecade 重置当前实例时间为 所在十年的第一天，同时设置 0时0分0秒 endOfDecade 重置当前实例时间为 所在十年的最后一天，同时设置 23时59分59秒 startOfCentury 重置当前实例时间为 本世纪的第一天，同时设置 0时0分0秒 endOfCentury 重置当前实例时间为 本世纪的最后一天，同时设置 23时59分59秒 next $dayOfWeek(null) 重置当前实例时间为 下一个指定dayOfWeek，同时设置 0时0分0秒 previous $dayOfWeek(null) 重置当前实例时间为 上一个指定dayOfWeek，同时设置 0时0分0秒 nextWeekday 重置当前实例时间为 下一个工作日，同时设置 0时0分0秒 previousWeekday 重置当前实例时间为 上一个工作日，同时设置 0时0分0秒 nextWeekendDay 重置当前实例时间为 下一个双休日，同时设置 0时0分0秒 previousWeekendDay 重置当前实例时间为 上一个双休日，同时设置 0时0分0秒 firstOfMonth $dayOfWeek(null) 重置当前实例时间为 本月第一周的指定dayOfWeek，同时设置 0时0分0秒 nthOfMonth $nth, $dayOfWeek 重置当前实例时间为 本月第n周的指定dayOfWeek，同时设置 0时0分0秒 lastOfMonth $dayOfWeek(null) 重置当前实例时间为 本月最后一周的指定dayOfWeek，同时设置 0时0分0秒 firstOfQuarter $dayOfWeek(null) 重置当前实例时间为 当前季度第一周的指定dayOfWeek，同时设置 0时0分0秒 nthOfQuarter $nth, $dayOfWeek 重置当前实例时间为 当前季度第n周的指定dayOfWeek，同时设置 0时0分0秒 lastOfQuarter $dayOfWeek(null) 重置当前实例时间为 当前季度最后一周的指定dayOfWeek，同时设置 0时0分0秒 firstOfYear $dayOfWeek(null) 重置当前实例时间为 本年第一周的指定dayOfWeek，同时设置 0时0分0秒 nthOfYear $nth, $dayOfWeek 重置当前实例时间为 本年第n周的指定dayOfWeek，同时设置 0时0分0秒 lastOfYear $dayOfWeek(null) 重置当前实例时间为 本年最后一周的指定dayOfWeek，同时设置 0时0分0秒 average Carbon $dt 重置当前实例时间为 与指定Carbon对象的中间时刻 modify $modify 按modify字符串重置当前实例时间 用途：格式化时间 方法名 参数 描述 __toString 按变量$toStringFormat的格式输出 toDateString 日期格式化输出 toTimeString 时间格式化输出 toDateTimeString 日期时间格式化输出 toDayDateTimeString 格式化输出如 “Fri, Jan 3, 2013 10:50 PM” toAtomString 格式化输出如 “2012-10-20T14:12:26+00:00” toCookieString 格式化输出如 “Friday, 02-Jan-2012 14:20:39 UTC” toIso8601String 同 toAtomString toRfc822String 格式化输出如 “Mon, 15 Aug 05 15:52:01 +0000” toRfc850String 格式化输出如 “Monday, 15-Aug-05 15:52:01 UTC” toRfc1036String 格式化输出如 “2005-08-15T15:52:01+0000” toRfc1123String 格式化输出如 “Mon, 15 Aug 2005 15:52:01 +0000” toRfc2822String 格式化输出如 “Mon, 15 Aug 05 15:52:01 +0000” toRfc3339String 同 toAtomString toRssString 格式化输出如 “Mon, 15 Aug 2005 15:52:01 +0000” toW3cString 格式化输出如 “2005-08-15T15:52:01+00:00” toFormattedDateString 格式化输出如 “Jan 11, 1999” formatLocalized $format 指定格式本地化输出 用途：时间判断 方法名 参数 描述 eq Carbon $dt 判断当前Carbon实例与指定Carbon对象时间是否一样 equalTo Carbon $dt 同 eq 方法 ne Carbon $dt 判断当前Carbon实例与指定Carbon对象时间是否不相同 notEqualTo Carbon $dt 同 ne 方法 gt Carbon $dt 判断当前Carbon实例是否大于指定Carbon对象时间 greaterThan Carbon $dt 同 gt 方法 gte Carbon $dt 判断当前Carbon实例是否大于等于指定Carbon对象时间 greaterThanOrEqualTo Carbon $dt 同 gte 方法 lt Carbon $dt 判断当前Carbon实例是否小于指定Carbon对象时间 lessThan Carbon $dt 同 lt 方法 lte Carbon $dt 判断当前Carbon实例是否小于等于指定Carbon对象时间 lessThanOrEqualTo Carbon $dt 同 lte 方法 between Carbon $dt1, Carbon $dt2, $equal(true) 判断当前Carbon实例是否在指定Carbon对象时间之间， 第三个参数表示是否可以等于指定Carbon对象 min Carbon $dt 获取当前实例与指定Carbon对象中，最小的对象 minimum Carbon $dt 同min max Carbon $dt 获取当前实例与指定Carbon对象中，最大的对象 maximum Carbon $dt 同max closest Carbon $dt1, Carbon $dt2 获取最接近当前实例时间的Carbon对象 farthest Carbon $dt1, Carbon $dt2 获取最不接近当前实例时间的Carbon对象 isSameAs $format, Carbon $dt 判断当前实例与指定Carbon对象的format格式化结果是否相同 isSameDay Carbon $dt 判断当前实例与指定Carbon对象是否是同一天 isSameMonth Carbon $dt(null), $ofSameYear(false) 判断当前实例与指定Carbon对象月份是否相同 isBirthday Carbon $dt 判断当前实例与指定Carbon对象月日数是否相同 isSameYear Carbon $dt 判断当前实例与指定Carbon对象年份是否相同 isSunday 判断当前实例是否是周日 isMonday 判断当前实例是否是周一 isTuesday 判断当前实例是否是周二 isWednesday 判断当前实例是否是周三 isThursday 判断当前实例是否是周四 isFriday 判断当前实例是否是周五 isSaturday 判断当前实例是否是周六 isYesterday 判断当前实例是否是昨天 isToday 判断当前实例是否是今天 isTomorrow 判断当前实例是否是明天 isWeekday 判断当前实例是否属于工作日 isWeekend 判断当前实例是否属于周末双休 isLastWeek 判断当前实例是否属于上周 isNextWeek 判断当前实例是否属于下一周 isLastMonth 判断当前实例是否属于上一个月 isCurrentMonth 判断当前实例是否属于当前月 isNextMonth 判断当前实例是否属于下一个月 isLastYear 判断当前实例是否属于去年 isCurrentYear 判断当前实例是否属于当前年 isNextYear 判断当前实例是否属于下一年 isLeapYear 判断当前实例是否属于闰年 isLongYear 判断当前实例是否属于长年，即一年不只有52个星期 isPast 判断当前实例是否属于过去 isFuture 判断当前实例是否属于未来 用途：时间计算 方法名 参数 描述 addSecond $value(1) 当前实例添加指定数量的秒数，返回当前实例 subSecond $value(1) 当前实例减去指定数量的秒数，返回当前实例 addSeconds $value 同addSecond subSeconds $value 同subSecond addMinute $value(1) 当前实例添加指定数量的分钟数，返回当前实例 subMinute $value(1) 当前实例减去指定数量的分钟数，返回当前实例 addMinutes $value 同addMinute subMinutes $value 同subMinute addHour $value(1) 当前实例添加指定数量的小时数，返回当前实例 subHour $value(1) 当前实例减去指定数量的小时数，返回当前实例 addHours $value 同addHour subHours $value 同subHour addDay $value(1) 当前实例添加指定数量的天数，返回当前实例 subDay $value(1) 当前实例减去指定数量的天数，返回当前实例 addDays $value 同addDay subDays $value 同subDay addWeekday $value(1) 当前实例添加指定数量的工作日数，返回当前实例 subWeekday $value(1) 当前实例减去指定数量的工作日数，返回当前实例 addWeekdays $value 同addWeekday subWeekdays $value 同subWeekday addWeek $value(1) 当前实例添加指定数量的星期数，返回当前实例 subWeek $value(1) 当前实例减去指定数量的星期数，返回当前实例 addWeeks $value 同addWeek subWeeks $value 同subWeek addMonth $value(1) 当前实例添加指定数量的月数，返回当前实例 subMonth $value(1) 当前实例减去指定数量的月数，返回当前实例 addMonths $value 同addMonth subMonths $value 同subMonth addMonthWithOverflow $value(1) 当前实例添加指定数量的月数（可溢出），返回当前实例 subMonthWithOverflow $value(1) 当前实例添加指定数量的月数（可溢出），返回当前实例 addMonthsWithOverflow $value 同addMonthWithOverflow subMonthsWithOverflow $value 同subMonthWithOverflow addMonthNoOverflow $value(1) 当前实例添加指定数量的月数（不可溢出），返回当前实例 subMonthNoOverflow $value(1) 当前实例添加指定数量的月数（不可溢出），返回当前实例 addMonthsNoOverflow $value 同addMonthNoOverflow subMonthsNoOverflow $value 同subMonthNoOverflow addQuarter $value(1) 当前实例添加指定数量的季度数，返回当前实例 subQuarter $value(1) 当前实例减去指定数量的季度数，返回当前实例 addQuarters $value 同addQuarter subQuarters $value 同subQuarter addYear $value(1) 当前实例添加指定数量的年数，返回当前实例 subYear $value(1) 当前实例减去指定数量的年数，返回当前实例 addYears $value 同addYear subYears $value 同subYear addCentury $value(1) 当前实例添加指定数量的世纪数，返回当前实例 subCentury $value(1) 当前实例减去指定数量的世纪数，返回当前实例 addCenturies $value 同addCentury subCenturies $value 同subCentury 用途：时间差值比较 方法名 参数 描述 diffInSeconds Carbon $dt(null), $abs(true) 获取指定Carbon对象与当前实例时间的秒数差，前者 - 后者； abs表示是否返回绝对值 secondsSinceMidnight 获取当前实例时间的 0时0分0秒 与当前实例时间的秒差 secondsUntilEndOfDay 获取当前实例时间的 23时59分59秒 与当前实例时间的秒差 diffInMinutes Carbon $dt(null), $abs(true) 获取指定Carbon对象与当前实例时间的分钟差, 取整 diffInHours Carbon $dt(null), $abs(true) 获取指定Carbon对象与当前实例时间的小时差, 取整 diffInHoursFiltered Closure $callback, Carbon $dt(null), $abs(true) 获取指定Carbon对象与当前实例时间的(通过回调函数较验的)小时差, 取整 diffInDays Carbon $dt(null), $abs(true) 获取指定Carbon对象与当前实例时间的天数差, 取整 diffInDaysFiltered Closure $callback, Carbon $dt(null), $abs(true) 获取指定Carbon对象与当前实例时间的(通过回调函数较验的)天数差, 取整 diffInWeekdays Carbon $dt(null), $abs(true) 获取指定Carbon对象与当前实例时间的工作日数差, 取整 diffInWeekendDays Carbon $dt(null), $abs(true) 获取指定Carbon对象与当前实例时间的双休日数差, 取整 diffInWeeks Carbon $dt(null), $abs(true) 获取指定Carbon对象与当前实例时间的星期数差, 取整 diffInMonths Carbon $dt(null), $abs(true) 获取指定Carbon对象与当前实例时间的月数差, 取整 diffInYears Carbon $dt(null), $abs(true) 获取指定Carbon对象与当前实例时间的年数差, 取整 diffFiltered CarbonInterval $ci， Closure $callback, Carbon $dt(null), $abs(true) 获取指定Carbon对象与当前实例时间的(通过回调函数较验的)$ci差, 取整 diffForHumans Carbon $other(null), $absolute(false), $short(false) 获取指定Carbon对象与当前实例时间的时间差，以便于人类阅读的格式呈现 用途：Getter &amp; Setter 方法名 参数 描述 getDays（static） 获取days of the week getWeekStartsAt（static） 获取一周的第一天 setWeekStartsAt（static） $day 设置一周的第一天 getWeekEndsAt（static） 获取一周的最后一天 setWeekEndsAt（static） $day 设置一周的最后一天 getWeekendDays（static） 获取双休日（数组） setWeekendDays（static） $days 设置双休日 getTranslator（static） 获取translator实例 setTranslator（static） TranslatorInterface $translator 设置translator实例 getLocale（static） 获取当前本地化语言 setLocale（static） $locale 设置当前本地化语言 timezone $value 设置时区 tz $value 设置时区 setTimezone $value 设置时区 setToStringFormat（static） $format 设置变量$toStringFormat resetToStringFormat（static） 设置变量$toStringFormat为默认值 setTestNow（static） $testNow(null) 设置变量$testNow，测试专用，初始化时的$now getTestNow（static） 获取变量$testNow hasTestNow（static） 判断$testNow是否为空 用途：其它 方法名 参数 描述 setUtf8（static） $utf8 设置是否采用 utf8 编码方式 getLastErrors（static） 获取无效时间的错误格式模板 serialize 返回当前实例的序列化字符串 hasRelativeKeywords（static） $time 判断字符串中是否有指定的关键字 shouldOverflowMonths（static） 获取变量$monthsOverflow useMonthsOverflow（static） $monthsOverflow(true) 设置变量$monthsOverflow resetMonthsOverflow（static） 重置变量$monthsOverflow为 true __get $name 魔术方法 __isset $name 魔术方法 __set $name, $value 魔术方法 CarbonInterval用途：生成CarbonInterval实例 方法名 参数 描述 __construct $years(1), $months(null), $weeks(null), $days(null), $hours(null), $minutes(null), $seconds(null) 创建CarbonInterval实例 create（static） $years(1), $months(null), $weeks(null), $days(null), $hours(null), $minutes(null), $seconds(null) 创建CarbonInterval实例 second(static) $value 创建 CarbonInterval 实例 seconds(static) $value 创建 CarbonInterval 实例 minute(static) $value 创建 CarbonInterval 实例 minutes(static) $value 创建 CarbonInterval 实例 hour(static) $value 创建 CarbonInterval 实例 hours(static) $value 创建 CarbonInterval 实例 day(static) $value 创建 CarbonInterval 实例 days(static) $value 创建 CarbonInterval 实例 dayz(static) $value 创建 CarbonInterval 实例 week(static) $value 创建 CarbonInterval 实例 weeks(static) $value 创建 CarbonInterval 实例 month(static) $value 创建 CarbonInterval 实例 months(static) $value 创建 CarbonInterval 实例 year(static) $value 创建 CarbonInterval 实例 years(static) $value 创建 CarbonInterval 实例 instance(static) $value 创建 CarbonInterval 实例 用途：本地化 方法名 参数 描述 translator（static） 初始化translator实例 getTranslator（static 获取translator实例 setTranslator（static） TranslatorInterface $translator 设置translator实例 getLocale（static） 获取当前本地化语言 setLocale（static） $locale 设置当前本地化语言 用途：计算 方法名 参数 描述 add DateInterval $interval 将指定DateInterval的时间叠加到当前实例 用途：格式化 方法名 参数 描述 spec 获取规范的间隔描述字符串 forHumans 获取便于人类阅读的间隔描述字符串 __toString 同forHumans 用途：其它 方法名 参数 描述 __get 魔术方法；可操作变量有years/months/dayz/hours/minutes/seconds/weeks/daysExcludeWeeks/dayzExcludeWeeks __set 魔术方法；可操作变量有years/months/dayz/hours/minutes/seconds/weeks/daysExcludeWeeks/dayzExcludeWeeks __call 魔术方法；可操作方法有years/year/months/month/weeks/week/days/dayz/day/hours/hour/minutes/minute/seconds/second weeksAndDays $weeks, $days 为当前实例的dayz变量赋值为($weeks * Carbon::DAYS_PER_WEEK) + $days]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP-Plugin</tag>
      </tags>
  </entry>
</search>
